{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-bedrocks-documentation","title":"Welcome to Bedrock's documentation!","text":"<p>bedrock is the project behind www.mozilla.org. It is as shiny, awesome, and open-source as always. Perhaps even a little more.</p> <p>bedrock is a web application based on Django, a Python web application framework.</p> <p>Patches are welcome! Feel free to fork and contribute to this project on Github.</p>"},{"location":"abtest/","title":"A/B Testing","text":""},{"location":"abtest/#ab_testing","title":"A/B Testing","text":""},{"location":"abtest/#traffic-cop-experiments","title":"Traffic Cop experiments","text":"<p>More complex experiments, such as those that feature full page redesigns, or multi-page user flows, should be implemented using Traffic Cop. Traffic Cop small javascript library which will direct site traffic to different variants in a/b experiments and make sure a visitor always sees the same variation.</p> <p>It's possible to test more than 2 variants.</p> <p>Traffic Cop sends users to experiments and then we use Google Analytics (GA) to analyze which variation is more successful. (If the user has <code>DNT (Do Not Track)</code> or <code>GPC (Global Privacy Control)</code> enabled they do not participate in experiments.)</p> <p>All a/b tests should have a mana page detailing the experiment and recording the results.</p>"},{"location":"abtest/#coding-the-variants","title":"Coding the variants","text":"<p>Traffic cop supports two methods of a/b testing. Executing different on page javascript or redirecting to the same URL with a query string appended. We mostly use the redirect method in bedrock. This makes testing easier.</p> <p>Create a variation view for the a/b test.</p> <p>The view can handle the URL redirect in one of two ways:</p> <ol> <li>the same page, with some different content based on the <code>variation</code> variable</li> <li>a totally different page</li> </ol>"},{"location":"abtest/#content-variation","title":"Content variation","text":"<p>Useful for small focused tests.</p> <p>This is explained on the variation view page.</p>"},{"location":"abtest/#new-page","title":"New page","text":"<p>Useful for large page changes where content and assets are dramatically different.</p> <p>Create the variant page like you would a new page. Make sure it is <code>noindex</code> and does not have a <code>canonical</code> URL.</p> <pre><code>{% block canonical_urls %}&lt;meta name=\"robots\" content=\"noindex,follow\"&gt;{% endblock %}\n</code></pre> <p>Configure as explained on the variation view page.</p>"},{"location":"abtest/#traffic-cop","title":"Traffic Cop","text":"<p>Create a .js file where you initialize Traffic Cop and include that in the experiments block in the template that will be doing the redirection. Wrap the extra js include in a switch.</p> <pre><code>{% block experiments %}\n  {% if switch('experiment-berlin-video', ['de']) %}\n    {{ js_bundle('firefox_new_berlin_experiment') }}\n  {% endif %}\n{% endblock %}\n</code></pre>"},{"location":"abtest/#switches","title":"Switches","text":"<p>See the traffic cop section of the switch docs for instructions.</p>"},{"location":"abtest/#recording-the-data","title":"Recording the data","text":"<p>Note</p> <p>If you are measuring installs as part of your experiment be sure to configure custom stub attribution as well.</p> <p>Send the experiment view events to GA4 with the event name <code>experiment_view</code>. The <code>id</code> of all variants should be the same and all <code>variant</code> values should be unique.</p> <p>Make sure any buttons and interaction which are being compared as part of the test will report into <code>GA (Google Analytics)</code>.</p> <pre><code>if (href.indexOf('v=a') !== -1) {\n    // GA4\n    window.dataLayer.push({\n        event: 'experiment_view',\n        id: 'Berlin-Campaign-Landing-Page',\n        variant: 'de-page',\n    });\n} else if (href.indexOf('v=b') !== -1) {\n    // GA4\n    window.dataLayer.push({\n        event: 'experiment_view',\n        id: 'Berlin-Campaign-Landing-Page',\n        variant: 'campaign-page',\n    });\n}\n</code></pre>"},{"location":"abtest/#viewing-the-data","title":"Viewing the data","text":"<p>We have not figured this out for GA4 yet.</p>"},{"location":"abtest/#tests","title":"Tests","text":"<p>Write some tests for your a/b test. This could be simple or complex depending on the experiment.</p> <p>Some things to consider checking:</p> <ul> <li>Requests for the default (non variant) page call the correct template.</li> <li>Requests for a variant page call the correct template.</li> <li>Locales excluded from the test call the correct (default) template.</li> </ul>"},{"location":"abtest/#avoiding-experiment-collisions","title":"Avoiding experiment collisions","text":"<p>To ensure that Traffic Cop doesn't overwrite data from any other externally controlled experiments (for example Ad campaign tests, or in-product Firefox experiments), you can use the experiment-utils helper to decide whether or not Traffic Cop should initiate.</p> <pre><code>import TrafficCop = from '@mozmeao/trafficcop';\nimport { isApprovedToRun } from '../../base/experiment-utils.es6';\n\nif (isApprovedToRun()) {\n    const cop = new TrafficCop({\n        variations: {\n            'entrypoint_experiment=experiment-name&amp;entrypoint_variation=a': 10,\n            'entrypoint_experiment=experiment-name&amp;entrypoint_variation=b': 10\n        }\n    });\n\n    cop.init();\n}\n</code></pre> <p>The <code>isApprovedToRun()</code> function will check the page URL's query parameters against a list of well-known experimental params, and return <code>false</code> if any of those params are found. It will also check for some other cases where we do not want to run experiments, such as if the page is being opened in an automated testing environment.</p>"},{"location":"banners/","title":"Banners","text":""},{"location":"banners/#banners","title":"Banners","text":""},{"location":"banners/#creating-page-banners","title":"Creating page banners","text":"<p>Any page on bedrock can incorporate a top of page banner as a temporary feature. An example of such a banner is the <code>MOFO (Mozilla Foundation)</code> fundraising banner that gets shown on the home page several times a year.</p> <p>Banners can be inserted into any page template by using the <code>page_banner</code> block. Banners can also be toggled on and off using a switch:</p> <pre><code>{% block page_banner %}\n  {% if switch('fundraising-banner') %}\n    {% include 'includes/banners/fundraiser.html' %}\n  {% endif %}\n{% endblock %}\n</code></pre> <p>Banner templates should extend the basic banner template, which provides very unopinionated structure but includes several helpful features such as a close button with localized text and exclusion of banner content from search result snippets.</p> <p>Custom banner content can then be inserted using <code>banner_title</code> and <code>banner_content</code> blocks:</p> <pre><code>{% extends 'includes/banners/basic.html' %}\n\n{% block banner_title %}We all love the web. Join Mozilla in defending it.{% endblock %}\n\n{% block banner_content %}\n    &lt;!-- insert custom HTML here --&gt;\n{% endblock %}\n</code></pre> <p>To initiate a banner on a page, include <code>js/base/banners/mozilla-banner.js</code> in your page bundle and then initiate the banner using a unique ID. The ID will be used as a cookie identifier should someone dismiss a banner and not wish to see it again.</p> <pre><code>(function() {\n    'use strict';\n\n    function onLoad() {\n        window.Mozilla.Banner.init('fundraising-banner');\n    }\n\n    window.Mozilla.run(onLoad);\n\n})();\n</code></pre> <p>By default, page banners will be rendered directly underneath the primary page navigation. If you want to render a banner flush at the top of the page, you can pass a secondary <code>renderAtTopOfPage</code> parameter to the <code>init()</code> function with a boolean value:</p> <pre><code>(function() {\n    'use strict';\n\n    function onLoad() {\n        window.Mozilla.Banner.init('fundraising-banner', true);\n    }\n\n    window.Mozilla.run(onLoad);\n\n})();\n</code></pre>"},{"location":"banners/#l10n-for-page-banners","title":"L10n for page banners","text":"<p>Because banners can technically be shown on any page, they need to be broadly translated, or alternatively limited to the subset of locales that have translations. Each banner should have its own <code>.ftl</code> associated with it, and accessible to the template or view it gets used in.</p>"},{"location":"browser-support/","title":"Browser Support","text":""},{"location":"browser-support/#browser_support","title":"Browser Support","text":"<p>We seek to provide usable experiences of our most important web content to all user agents. But newer browsers are far more capable than older browsers, and the capabilities they provide are valuable to developers and site visitors. We will take advantage of modern browser capabilities. Older browsers will have a different experience of the website than newer browsers. We will strike this balance by generally adhering to the core principles of Progressive Enhancement:</p> <ul> <li>Basic content should be accessible to all web browsers</li> <li>Basic functionality should be accessible to all web browsers</li> <li>Sparse, semantic markup contains all content</li> <li>Enhanced layout is provided by externally linked CSS</li> <li>Enhanced behavior is provided by unobtrusive, externally linked JavaScript</li> <li>End-user web browser preferences are respected</li> </ul> <p>Some website experiences may require us to deviate from these principles -- imagine a marketing campaign page built under timeline pressure to deliver novel functionality to a particular locale for a short while -- but those will be exceptions and rare.</p>"},{"location":"browser-support/#browser-support-matrix","title":"Browser Support Matrix","text":"<p>Last updated: Updated July 19, 2023</p>"},{"location":"browser-support/#firefox","title":"Firefox","text":"<p>It is important for website visitors to be able to download Firefox on a very broad range of desktop operating systems. As such, we aim to deliver enhanced support to user agents in our browser support matrix below.</p> <p>Enhanced support:</p> <ul> <li> <p>Windows 11 and above</p> <ul> <li>All evergreen browsers<ul> <li>Firefox</li> <li>Firefox ESR</li> <li>Chrome</li> <li>Edge</li> <li>Brave</li> <li>Opera</li> </ul> </li> </ul> </li> <li> <p>Windows 10</p> <ul> <li>All evergreen browsers</li> </ul> </li> <li> <p>macOS 10.15 and above</p> <ul> <li>All evergreen browsers</li> <li>Safari</li> </ul> </li> <li> <p>Linux</p> <ul> <li>All evergreen browsers</li> </ul> </li> </ul> <p>Degraded support:</p> <p>Website visitors on slightly older browsers fall under degraded support, which means that the website should be fully readable and accessible, but they may not get enhanced CSS layout or JS features.</p> <ul> <li> <p>Windows 10</p> <ul> <li>Internet Explorer 11</li> </ul> </li> <li> <p>Windows 8.1 and below</p> <ul> <li>Firefox 115</li> <li>Chrome 109</li> <li>Internet Explorer 10</li> </ul> </li> <li> <p>macOS 10.14 and below</p> <ul> <li>Firefox 115</li> <li>Chrome 114</li> <li>Safari 12.1</li> </ul> </li> </ul> <p>Note</p> <p>As of Firefox 116 (released August 1<sup>st</sup> 2023), support for Firefox has been ended on Windows 8.1 and below, as well as on macOS 10.14 and below. Website visitors on these outdated operating systems now fall under degraded support, and we offer them to download Firefox ESR instead.</p> <p>Basic support:</p> <p>Website visitors on very old versions of Internet Explorer will get only a very basic universal CSS style sheet, and a basic no-JS experience.</p> <ul> <li> <p>Windows 7</p> <ul> <li>Internet Explorer 9</li> <li>Internet Explorer 8</li> </ul> </li> </ul> <p>Unsupported:</p> <p>Even older versions of Internet Explorer are now unsupported.</p> <ul> <li> <p>Windows XP / Vista</p> <ul> <li>Internet Explorer 7</li> <li>Internet Explorer 6</li> </ul> </li> </ul> <p>Note</p> <p>Firefox ended support for Windows XP and Vista in 2017 with Firefox 53. Since then, we have continued to serve those users Firefox ESR 52 instead. However, since then support for downloading has been discontinued. The SSL certificates on download.mozilla.org no longer support TLS 1.0.</p>"},{"location":"browser-support/#privacy-security-products","title":"Privacy &amp; security products","text":"<p>Browser support for our privacy and security products (such as VPN, Relay, Monitor etc) is thankfully a simpler story. Since all these product use a Firefox account for authentication, we can simply follow the Firefox Ecosystem Platform browser support documentation.</p> <p>The most notable thing here for bedrock is that Internet Explorer 11 does not need to be supported.</p>"},{"location":"browser-support/#delivering-basic-support","title":"Delivering basic support","text":"<p>On IE browsers that support conditional comments (IE9 and below), basic support consists of no page-specific CSS or JS. Instead, we deliver well formed semantic HTML, and a universal CSS stylesheet that gets applied to all pages. We do not serve these older browsers any JS, with the exception of the following scripts:</p> <ul> <li>Google Analytics / <code>GTM (Google Tag Manager)</code> snippet.</li> <li>HTML5shiv for parsing modern HTML semantic elements.</li> <li>Stub Attribution script (IE8 / IE9).</li> </ul> <p>Conditional comments should instead be used to handle content specific to IE. To hide non-relevant content from IE users who see the universal stylesheet, a <code>hide-from-legacy-ie</code> class name can also be applied directly to HTML:</p> <pre><code>&lt;p class=\"hide-from-legacy-ie\"&gt;See what Firefox has blocked for you&lt;/p&gt;\n</code></pre>"},{"location":"browser-support/#delivering-degraded-support","title":"Delivering degraded support","text":"<p>On other legacy browsers where conditional comments are not supported, developers should instead rely on feature detection to deliver a degraded experience where appropriate.</p> <p>Note</p> <p>The following feature detection helpers will return true for all browsers that get enhanced support, but will also return true for IE11 currently, even though that has now moved to degraded support. The reason for this is that whilst many of our newer products don't support IE at all (e.g. Mozilla VPN, Mozilla Monitor, Firefox Relay), we do still need to provide support so that IE users can easily download Firefox. We can decide to update the feature detect in the future, at a time when we think makes sense.</p>"},{"location":"browser-support/#feature-detection-using-css","title":"Feature detection using CSS","text":"<p>For CSS, enhanced experiences can be delivered using feature queries, whilst allowing older browsers to degrade gracefully using simpler layouts when needed.</p> <p>Additionally, there is also a universal CSS class hook available that gets delivered via a site-wide JS feature detection snippet:</p> <pre><code>.is-modern-browser {\n    /* Styles will only be applied to browsers that get enhanced support. */\n}\n</code></pre>"},{"location":"browser-support/#feature-detection-using-javascript","title":"Feature detection using JavaScript","text":"<p>For JS, enhanced support can be delivered using a helper that leverages the same feature detection snippet:</p> <pre><code>(function() {\n    'use strict';\n\n    function onLoad() {\n        // Code that will only be run on browsers that get enhanced support.\n    }\n\n    window.Mozilla.run(onLoad);\n})();\n</code></pre> <p>The <code>site.isModernBrowser</code> global property can also be used within conditionals like so:</p> <pre><code>if (window.site.isModernBrowser) {\n    // Code that will only be run on browsers that get enhanced support.\n}\n</code></pre>"},{"location":"browser-support/#exceptions-updated-2019-06-11","title":"Exceptions (Updated 2019-06-11)","text":"<p>Some pages of the website provide critical functionality to older browsers. In particular, the Firefox desktop download funnel enables users on older browsers to get a modern browser. To the extent possible, we try to deliver enhanced experiences to all user agents on these pages.</p> <p>The following pages get enhanced experiences for a longer list of user agents:</p> <ul> <li><code>/firefox/</code></li> <li><code>/firefox/new/</code></li> <li><code>/firefox/download/thanks/</code></li> </ul> <p>Note</p> <p>An enhanced experience can be defined as a step above basic support. This can be achieved by delivering extra page-specific CSS to legacy browsers, or allowing them to degrade gracefully. It does not mean everything needs to look the same in every browser.</p>"},{"location":"cms/","title":"Content Management System","text":""},{"location":"cms/#cms","title":"CMS","text":"<p>From 2024, Bedrock's CMS will be powered by Wagtail CMS.</p> <p>This page is currently a skeleton for documentation to be added as the work evolves.</p>"},{"location":"cms/#high-level-summary","title":"High-level summary","text":"<p>Wagtail CMS will be used to make either entire pages or portions of pages (let's call them 'surfaces') content-editable on www.mozilla.org. It is not a free-for-all add-any-page-you-like approach, but rather a careful rollout of surfaces with appropriate guard rails that helps ensure the integrity, quality and security of www.mozilla.org.</p> <p>Surfaces will be authored via a closed 'Editing' deployment and when those changes are published they will become visible on the main www.mozilla.org 'Web' deployment.</p> <p>If you are new to Wagtail, it is recommended that you read the official docs and/or complete an online course to get a better understanding of how Wagtail works.</p> <p>Useful resources:</p> <ul> <li>Wagtail Editor Guide.</li> <li>Wagtail Docs.</li> <li>The Ultimate Wagtail Developers Course.</li> </ul>"},{"location":"cms/#accessing-the-cms-on-your-local-machine","title":"Accessing the CMS on your local machine","text":""},{"location":"cms/#sso-authentication-setup","title":"SSO authentication setup","text":"<ol> <li>Become a member of <code>bedrock_cms_local_dev-access</code> on people.mozilla.org. Make sure you remember to accept the email invitation.</li> <li>Extend your <code>.env</code> file with the development OIDC credentials that have been supplied to you. (make sure your <code>.env</code> file is based on a recent copy of <code>.env-dist</code> as several new variables exist).</li> <li>In your <code>.env</code> file set the following variables:<ul> <li><code>USE_SSO_AUTH=True</code></li> <li><code>WAGTAIL_ENABLE_ADMIN=TRUE</code></li> <li><code>WAGTAIL_ADMIN_EMAIL=YOUR_MOZILLA_LDAP_EMAIL@mozilla.com</code></li> </ul> </li> <li>Run <code>make preflight</code> to update bedrock with the latest DB version. As part of this step, the make file will also create a local admin user for you, using the Mozilla LDAP email address you added in the previous step. If you do not want to overwrite your local database, run <code>make preflight -- --retain-db</code> instead.</li> <li>Start bedrock running via <code>npm start</code> (for local dev) or <code>make build run</code> (for Docker).</li> <li>Go to <code>http://localhost:8000/cms-admin/</code> and you should see a button to login with SSO. Click it and you should go through the OAuth flow and end up in the Wagtail admin.</li> </ol>"},{"location":"cms/#non-sso-authentication","title":"Non-SSO authentication","text":"<ol> <li>In your <code>.env</code> file set <code>USE_SSO_AUTH=False</code>, and <code>WAGTAIL_ENABLE_ADMIN=TRUE</code>.</li> <li>Run <code>make preflight</code> to update bedrock with the latest DB version. If you do not want to overwrite your local database, run <code>make preflight -- --retain-db</code> instead.</li> <li>Create a local admin user with <code>./manage.py createsuperuser</code>, setting both the username, email and password to whatever you choose (note: these details will only be stored locally on your device).</li> <li>Alternatively, if you define <code>WAGTAIL_ADMIN_EMAIL=YOUR_MOZILLA_LDAP_EMAIL@mozilla.com</code> and <code>WAGTAIL_ADMIN_PASSWORD=somepassword</code> in your <code>.env.</code> file, <code>make preflight</code> will automatically create a non-SSO superuser for you</li> <li>Start bedrock running via <code>npm start</code> (for local dev) or <code>make build run</code> (for Docker).</li> <li>Go to <code>http://localhost:8000/cms-admin/</code> and you should see a form for logging in with a username and password. Use the details you created in the previous step.</li> </ol>"},{"location":"cms/#fetching-the-latest-cms-data-for-local-work","title":"Fetching the latest CMS data for local work","text":"<p>Note</p> <p>TL;DR version:</p> <ol> <li>Get the DB with <code>make preflight</code></li> <li>If you need the images that the DB expects to exist, use <code>python manage.py download_media_to_local</code> ::::</li> </ol> <p>The CMS content exists in hosted cloud database and a trimmed-down version of this data is exported to a sqlite DB for use in local development and other processes. The exported database contains all the same content, but deliberately omits sensitive info like user accounts, unpublished drafts and outmoded versions of pages.</p> <p>The DB export is generated twice a day and is put into the same public cloud buckets we've used for years. Your local Bedrock install will just download the <code>bedrock-dev</code> one as part of <code>make preflight</code>.</p> <p>The DB will contain a table that knows the relative paths of the images uploaded to the CMS, but not the actual images. Those are in a cloud storage bucket, and if you want your local machine to have them available after you download the DB that expects them to be present, you can run <code>python manage.py download_media_to_local</code> which will sync down any images you don't already have.</p> <p>Note</p> <p>By default, <code>make preflight</code> and <code>./bin/run-db-download.py</code> will download a database file based on <code>bedrock-dev</code>. If you want to download from stage or prod, which are also available in sanitised form, you need to tell Bedrock which environment you want by prefixing the command with <code>AWS_DB_S3_BUCKET=bedrock-db-stage</code> or <code>AWS_DB_S3_BUCKET=bedrock-db-prod</code>.</p> <p><code>AWS_DB_S3_BUCKET=bedrock-db-stage make preflight</code></p> <p><code>python manage.py download_media_to_local --environment=stage</code> ::::</p>"},{"location":"cms/#editing-current-content-surfaces","title":"Editing current content surfaces","text":"<p>In terms of managing the content of an existing surface, please see the general Wagtail Editor Guide for now.</p> <p>If you want to change the code-defined behaviour of an existing surface, that's similar to adding a new content surface, covered below. You may also find the Wagtail Docs and The Ultimate Wagtail Developers Course useful if you don't have experience of building with Wagtail yet.</p>"},{"location":"cms/#adding-new-content-surfaces","title":"Adding new content surfaces","text":"<p>This is an introduction to creating new content surfaces in the CMS. It is not a comprehensive guide, but rather a starting point to get you up and running with the basics.</p> <p>The page types that you see in the CMS admin are defined as regular models in Django. As such, you can define new page types in the same way you would define any other Django model, using Wagtail's field types and panels to define the data that can be entered into the page.</p> <p>When it comes to structuring CMS page models, there are some general guidelines to try and follow:</p> <ul> <li>Models and templates should be defined in the same Django app that corresponds to where the URL exists in Bedrock's information architecture (IA) hierarchy, similar to what we do for regular Jinja templates already. For example, a Mozilla themed page should be defined in <code>/bedrock/mozorg/models.py</code>, and a Firefox themed page model should be in <code>/bedrock/firefox/models.py</code>.</li> <li>Global <code>Page</code> models and <code>StreamField</code> blocks that are shared across many pages throughout the site should be defined in <code>/bedrock/cms/</code>.</li> </ul> <p>Structuring code in this way should hopefully help to keep things organized and migrations in a manageable state.</p>"},{"location":"cms/#creating-a-new-page-model","title":"Creating a new page model","text":"<p>Let's start by creating a new Wagtail page model called <code>TestPage</code> in <code>bedrock/mozorg/models.py</code>.</p> <pre><code>from django.db import models\n\nfrom wagtail.admin.panels import FieldPanel\nfrom wagtail.fields import RichTextField\n\nfrom bedrock.cms.models.base import AbstractBedrockCMSPage\n\n\nclass TestPage(AbstractBedrockCMSPage):\n    heading = models.CharField(max_length=255, blank=True)\n    body = RichTextField(\n        blank=True,\n        features=settings.WAGTAIL_RICHTEXT_FEATURES_FULL,\n    )\n\n    content_panels = AbstractBedrockCMSPage.content_panels + [\n        FieldPanel(\"heading\"),\n        FieldPanel(\"body\"),\n    ]\n\n    template = \"mozorg/test_page.html\"\n</code></pre> <p>Some key things to note here:</p> <ul> <li><code>TestPage</code> is a subclass of <code>AbstractBedrockCMSPage</code>, which is a common base class for all Wagtail pages in bedrock. Inheriting from <code>AbstractBedrockCMSPage</code> allows CMS pages to use features that exist outside of Wagtail, such as rendering Fluent strings and other L10n methods.</li> <li>The <code>TestPage</code> model defines two database field called <code>heading</code> and <code>body</code>. The <code>heading</code> field is a <code>CharField</code> (the most simple text entry field type), and <code>body</code> is a <code>RichTextField</code>. The HTML tags and elements that a content editor can enter into a rich text field are defined in <code>settings.WAGTAIL_RICHTEXT_FEATURES_FULL</code>.</li> <li>There is also a <code>title</code> field on the page model, which from <code>AbstractBedrockCMSPage</code> (which in turn comes from <code>wagtail.models.Page</code>). This doesn't make <code>heading</code> redundant, but it's worth knowing where <code>title</code> comes from.</li> <li>Both fields are added to the CMS admin panel by adding each as a <code>FieldPanel</code> to <code>content_panels</code>. If you forget to do this, that's usually why you don't see the field in the CMS admin.</li> <li>Finally, the template used to render the page type can be found at <code>mozorg/test_page.html</code>.</li> <li>If you don't set a custom template name, Wagtail will infer it from the model's name: <code>&lt;app_label&gt;/&lt;model_name (in snake case)&gt;.html</code></li> <li>All new models must be added to the config for the DB exporter script. If you do not, the page will not be correctly exported for local development and will break for anyone using that DB export file. See <code>Add your new model to the DB export</code>, below.</li> </ul>"},{"location":"cms/#django-model-migrations","title":"Django model migrations","text":"<p>Once you have your model defined, it's then time to run create and run migrations to set up a database table for it:</p> <pre><code>./manage.py makemigrations\n</code></pre> <p>You can then run migrations using:</p> <pre><code>./manage.py migrate\n</code></pre> <p>Many times when you make changes to a model, it will also mean that the structure of the database table has changed. So as a general rule it's good to form a habit of running the above steps after making changes to your model. Each migration you make will add a new migration file to the <code>/migrations</code> directory. When doing local development for a new page you might find yourself doing this several times, so to help reduce the number of migration files you create you can also squash / merge them.</p> <ul> <li>Django migrations docs.</li> <li>Squashing migrations.</li> </ul>"},{"location":"cms/#rendering-data-in-templates","title":"Rendering data in templates","text":"<p>This is a good time to test out your page model by adding data to it to see how it renders in your template.</p> <p>The data can be rendered in <code>mozorg/test_page.html</code> as follows:</p> <pre><code>{% extends \"base-protocol-mozilla.html\" %}\n\n{% block page_title %}{{ page.title }}{% endblock %}\n\n{% block content %}\n    &lt;header&gt;\n    &lt;h1&gt;{{ page.heading }}&lt;/h1&gt;\n    &lt;div class=\"w-rich-text\"&gt;\n        {{ page.body|richtext }}\n    &lt;/div&gt;\n    &lt;/header&gt;\n{% endblock %}\n</code></pre> <p>Note the <code>|richtext</code> filter applied to the <code>page.body</code> field. This is a Wagtail-provided Jinja2 filter that will render the rich text field as HTML.</p>"},{"location":"cms/#previewing-pages-in-the-cms-admin","title":"Previewing pages in the CMS admin","text":"<p>Next, restart your local server and log in to the CMS admin. Browse to a page and use the <code>+</code> icon or similar to add a new \"child page\". You should now see your new page type in the list of available pages. Create a new page using the <code>TestPage</code> type, give the page a title of <code>Test Page</code> and a slug of <code>test</code>, and then enter some data for the fields you defined. When you click the preview icon in the top right of the CMS page, you should hopefully see your template and data rendered successfully!</p>"},{"location":"cms/#using-advanced-page-models-fields-and-blocks","title":"Using advanced page models, fields, and blocks","text":"<p>The example above was relatively simple in terms of data, but not very flexible. Now that you have the basics covered, the next step is to start thinking about your page requirements, and how to better structure your data models.</p> <p>At this point, deep diving into the Wagtail Docs is very much recommended. In particular, reading up on more advanced concepts such as Stream Fields and Custom Block types will make it possible to make much more advanced CMS page types.</p> <p>This is also a good time to start thinking about guardrails for your page and data. Some common things to consider:</p> <ul> <li>Are there rules around the type of content that should be allowed on the page, such as the minimum or maximum number of items in a block?</li> <li>Should there be a set order to content in a page, or can it be flexible?</li> <li>Are there rules that should be applied at the page level, such as where it should live in the site hierarchy?</li> <li>Should there be a limit to the number of instances of that page type? (e.g. it would be confusing to have more than one home page or contact page).</li> </ul>"},{"location":"cms/#writing-tests","title":"Writing tests","text":"<p>When it comes to testing CMS page models, wagtail_factories can be used to create mock data for tests to render. This can often be the trickiest part when testing more complex page models, so it takes some practice.</p> <p>Factories for your page models and blocks should be defined in a <code>factories.py</code> file for your tests to import:</p> <pre><code>import factory\nimport wagtail_factories\n\nfrom bedrock.mozorg import TestPage\n\n\nclass TestPageFactory(wagtail_factories.PageFactory):\n    title = \"Test Page\"\n    live = True\n    slug = \"test\"\n\n    heading = wagtail_factories.CharBlockFactory\n    body = wagtail_factories.CharBlockFactory\n\n    class Meta:\n        model = models.TestPage\n</code></pre> <p>In your <code>test_models.py</code> file, you can then import the factory for your test and give it some data to render:</p> <pre><code>import pytest\nfrom wagtail.rich_text import RichText\n\nfrom bedrock.cms.tests.conftest import minimal_site  # noqa\nfrom bedrock.mozorg.tests import factories\n\npytestmark = [\n    pytest.mark.django_db,\n]\n\n\n@pytest.mark.parametrize(\"serving_method\", (\"serve\", \"serve_preview\"))\ndef test_page(minimal_site, rf, serving_method):  # noqa\n    root_page = minimal_site.root_page\n\n    test_page = factories.TestPageFactory(\n        parent=root_page,\n        heading=\"Test Heading\",\n        body=RichText(\"Test Body\"),\n    )\n\n    test_page.save()\n\n    _relative_url = test_page.relative_url(minimal_site)\n    assert _relative_url == \"/en-US/test/\"\n    request = rf.get(_relative_url)\n\n    resp = getattr(test_page, serving_method)(request)\n    page_content = str(resp.content)\n    assert \"Test Heading\" in page_content\n    assert \"Test Body\" in page_content\n</code></pre>"},{"location":"cms/#add-your-new-model-to-the-db-export","title":"Add your new model to the DB export","text":"<p>When you add a new model, you must update the script that generates the sqlite DB export of our data, so that the model is included in the export. (It's an allowlist pattern, as requested by Mozilla Security).</p> <p>If you do not, the page will not be correctly exported for local development and will break for anyone using that DB export file.</p> <p>(It's down to Wagtail's multi-table inheritance pattern: if you don't specify your new model for export, Wagtail's core metadata <code>Page</code> is exported, but not the actual new data model that holds the content that's linked to that <code>Page</code>)</p> <p>The script is <code>bin/export-db-to-sqlite.sh</code> and you need to add your new model to the list of models being exported. Search for <code>MAIN LIST OF MODELS BEING EXPORTED</code> and add your model (in the format <code>appname.ModelName</code>) there.</p>"},{"location":"cms/#the-cms_allowed_page_models-setting","title":"The <code>CMS_ALLOWED_PAGE_MODELS</code> setting","text":"<p>When you add a new page to the CMS, it will be available to add as a new child page immediately if <code>DEV=True</code>. This means it'll be on Dev (www-dev), but not in Staging or Prod.</p> <p>So if you ship a page that needs to be used immediately in Production (which will generally be most cases), you must remember to add it to <code>CMS_ALLOWED_PAGE_MODELS</code> in Bedrock's settings. If you do not, it will not be selectable as a new Child Page in the CMS.</p>"},{"location":"cms/#why-do-we-have-this-behaviour","title":"Why do we have this behaviour?","text":"<p>Two reasons:</p> <ol> <li>This setting allows us to complete initial/eager work to add a new page type, but stop it being used in Production until we are ready for it (e.g. a special new campaign page type that we wanted to get ready in good time). While there will be guard rails and approval workflows around publishing, without this it could still be possible for part of the org to start using a new page without us realising it was off-limits, and possibly before it is allowed to be released.</li> <li>This approach allows us to gracefully deprecate pages: if a page is removed in <code>settings.CMS_ALLOWED_PAGE_MODELS</code>, that doesn't mean it disappears from Prod or can't be edited - it just stops a NEW one being added in Prod.</li> </ol>"},{"location":"cms/#migrating-django-pages-to-the-cms","title":"Migrating Django pages to the CMS","text":"<p>Note</p> <p>This is initial documentation, noting relevant things that exist already, but much fuller recommendations will follow</p> <p>Migrating a surface to Wagtail is very similar to adding a new one, but some extra thought needs to be given to the switchover between old hardcoded content and new CMS-backed content.</p>"},{"location":"cms/#the-prefer_cms-decorator","title":"The <code>@prefer_cms</code> decorator","text":"<p>If you have an existing Django-based page that you want to move to be a CMS-driven page, you are faced with a quandry.</p> <p>Let's say the page exists at <code>/some/path/</code>; you can create it in the CMS with a branch of pages that mirror the same slugs (a parent page with a slug of <code>some</code> and a child page with a slug of <code>path</code>). However, in order for anyone to see the published page, you would have to remove the reference to the Django view from the URLconf, so that Wagtail would get a chance to render it (because Wagtail's page-serving logic comes last in all URLConfs). BUT... how can you enter content into the CMS fast enough replace the just-removed Django page? (Note: we could use a data migraiton here, but that gets complicated when there are images involved)</p> <p>Equally, you may have a situation where the content for certain paths needs to be managed in the CMS for certain locales, while other locales (with rarely changing 'evergreen' content) may only exist as Django-rendered views drawing strings from Fluent.</p> <p>The answer here is to use the <code>bedrock.cms.decorators.prefer_cms</code> decorator/helper.</p> <p>A Django view decorated with <code>prefer_cms</code> will check if a live CMS page has been added that matches the same overall, relative path as the Django view. If it finds one, it will show the user <code>that</code> CMS page instead. If there is no match in the CMS, then the original Django view will be used.</p> <p>The result is a graceful handover flow that allows us to switch to the CMS page without needing to remove the Django view from the URLconf, or to maintain a hybrid approach to page management. It doesn't affect previews, so the review of draft pages before publishing can continue with no changes. Once the CMS is populated with a live version of the replacement page, that's when a later changeset can remove the deprecated Django view if it's no longer needed.</p> <p>The <code>prefer_cms</code> decorator can be used directly on function-based views, or can wrap views in the URLconf. It should not used with <code>bedrock.mozorg.util.page</code> due to the complexity of passing through what locales are involved, but instead the relevant URL route should be refactored as a regular Django view, and then decorated with <code>prefer_cms</code></p> <p>For more details, please see the docstring on <code>bedrock.cms.decorators.prefer_cms</code>.</p>"},{"location":"cms/#generating-urls-for-cms-pages-in-non-cms-templates","title":"Generating URLs for CMS pages in non-CMS templates","text":"<p>Pages in the CMS don't appear in the hard-coded URLConfs in Bedrock. Normally, this means there's no way to use <code>url()</code> to generate a path to it.</p> <p>However, if there's a page in the CMS you need to generate a URL for using the <code>url()</code> template tag, <code>and you know what its path will be</code>, Bedrock contains a solution.</p> <p><code>bedrock.cms.cms_only_urls</code> is a special URLConf that only gets loaded during the call to the <code>url()</code> helper. If you expand it with a named route definition that matches the path you know will/should exist in the CMS (and most of our CMS-backed pages <code>do</code> have carefully curated paths), the <code>url()</code> helper will give you a path that points to that page, even though it doesn't really exist as a static Django view.</p> <p>See the example in the <code>bedrock.cms.cms_only_urls.py</code> file.</p> <p>Note</p> <p>Moving a URL route to <code>cms_only_urls.py</code> is a natural next step after you've migrated a page to the CMS using the <code>@prefer_cms</code> decorator and now want to remove the old view without breaking all the calls to <code>url('some.view')</code> or <code>reverse('some.view')</code>.</p>"},{"location":"cms/#images","title":"Images","text":""},{"location":"cms/#using-editor-uploaded-images-in-templates","title":"Using editor-uploaded images in templates","text":"<p>Images may be uploaded into Wagtail's Image library and then included in content-managed surfaces that have fields/spaces for images.</p> <p>Images are stored in the same media bucket that fixed/hard-coded Bedrock images get put in, and coexist alongside them, being namespaced into a directory called <code>custom-media/</code>.</p> <p>If a surface uses an image, images use must be made explicit via template markup --- we need to state both where and how an image will be used in the template, including specifying the size the image will be. This is because --- by design and by default --- Wagtail can generate any size version that the template mentions by providing a \"filter spec\" e.g.</p> <pre><code>{% set the_image=image(page.product_image, \"width-1200\") %}\n&lt;img class=\"some-class\" src=\"{{ the_image.url }})\"/&gt;\n</code></pre> <p>(More examples are available in the Wagtail Images docs.)</p> <p>When including an image in a template we ONLY use filter specs between 2400px down to 200px in 200px steps, plus 100px.</p> <p>Laying them out, these are the only filter specs allowed. Using alternative ones will trigger an error in production.</p> <ul> <li><code>width-100</code></li> <li><code>width-200</code></li> <li><code>width-400</code></li> <li><code>width-600</code></li> <li><code>width-800</code></li> <li><code>width-1000</code></li> <li><code>width-1200</code></li> <li><code>width-1400</code></li> <li><code>width-1600</code></li> <li><code>width-1800</code></li> <li><code>width-2000</code></li> <li><code>width-2200</code></li> <li><code>width-2400</code></li> </ul>"},{"location":"cms/#why-are-we-limiting-filter-specs-to-that-set","title":"Why are we limiting filter-specs to that set?","text":"<p>In a line: to balance infrastructure security constraints with site flexiblity, we have to pre-generate a known set of renditions.</p> <p>Normally, if that <code>product_image</code> is not already available in <code>1024x1024</code>, Wagtail will resize the original image to suit, on the fly, and store this \"rendition\" (a resized version, basically) in the cloud bucket. It will also add a reference to the database so that Wagtail knows that the rendition already exists.</p> <p>In production, the \"Web\" deployment has read-only access to the DB and to the cloud storage, so it will not be able to generate new renditions on the fly. Instead, we pre-generate those renditions when the image is saved.</p> <p>This approach will not be a problem if we stick to image filter-specs from the 'approved' list. Note that extending the list of filter-specs is possible, if we need to.</p>"},{"location":"cms/#ive-downloaded-a-fresh-db-and-the-images-are-missing","title":"I've downloaded a fresh DB and the images are missing!","text":"<p>That's expected: the images don't live in the DB, only references to them live there. CMS images are destined for public consumption, and Dev, Stage and Prod all store their images in a publicly-accessible cloud bucket.</p> <p>We have a tool to help you sync down the images from the relevant bucket.</p> <p>By default, the sqlite DB you can download to run bedrock locally is based on the data in Bedrock Dev. To get images from the cloud bucket for dev, run:</p> <pre><code>./manage.py download_media_to_local\n</code></pre> <p>This will look at your local DB, find the image files that it says should be available locally, copy them down to your local machine, then trigger the versions/renditions of them that should also exist.</p> <p>The command will only download images you don't already have locally. You can use the <code>--redownload</code> option to force a redownload of all images.</p> <p>If you have a DB from Stage you can pass the <code>--environment=stage</code> option to get the images from the Stage bucket instead. Same goes for Production.</p>"},{"location":"cms/#l10n-and-translation-management","title":"L10N and Translation Management","text":"<p>:::: important</p> <p>Important</p> <p>Localization via Wagtail is something we are ramping up on, so please do not assume the following notes are final, or that the workflows are currently all rock-solid. We're learning as we go. ::::</p>"},{"location":"cms/#page-tree-concept","title":"Page-tree concept","text":"<p>Our Wagtail setup uses the official wagtail-localize package to manage localization of pages.</p> <p>This package supports page-level localization rather than field-level localization, which means that each locale has its own distinct tree of pages, rather than each page having a stack of duplicate fields, one per destination language.</p> <p>These language-specific trees can be \"synchronised\" with the default <code>en-US</code> page tree, so would have the same page structure, field by field) --- or they can not be synchronised, so can have their own extra pages, or some specific pages in the tree can be made not \"synchronised\", while others are.</p> <p>Basically, there is plenty of flexibility. The flipside of that flexibility is we may also create an edge-case situation that <code>wagtail-localize</code> won't work with, but we'll have to see and deal with it.</p> <p>Note</p> <p>It's worth investing 15 mins in watching the Wagtail Localize original demo to get a good feel of how it can work.</p>"},{"location":"cms/#locale-configuration-within-wagtail","title":"Locale configuration within Wagtail","text":"<p>While the list of available overall locales is defined in code in <code>settings.base.WAGTAIL_CONTENT_LANGUAGES</code>, any locale also needs enabling via the Wagtail Admin UI before it can be used.</p> <p>When you go to <code>Settings &gt; Locales</code> in the Wagtail fly-out menu, you will see which locales are currenly enabled. You can add new ones via the <code>+</code> icon.</p> <p>:::: warning</p> <p>Warning</p> <p>When you add/edit a Locale in this part of the admin, you will see an option to enable syncronisation between locales. Do not enable this. If it is enabled, for every new page added in <code>en-US</code>, it will auto-create page aliases in every other enabled locale and these will deliver the <code>en-US</code> content under locale-specific paths, which is not what we want. ::::</p>"},{"location":"cms/#localization-process","title":"Localization process","text":""},{"location":"cms/#manual-updates","title":"Manual updates","text":"<p>At its most basic, there's nothing stopping us using copy-and-paste to enter translations into lang-specific pages, which might work well if we have a page in just one non-en-US lang and an in-house colleague doing the translation.</p>"},{"location":"cms/#automated-via-smartling","title":"Automated via Smartling","text":"<p>However, we also have automation available to send source strings to translation vendor Smartling. This uses the <code>wagtail-localize-smartling</code> package.</p> <p>Here's the overall workflow:</p> <ol> <li> <p>CMS page \"MyPage\" is created in the default lang (<code>en-US</code>)</p> </li> <li> <p>The \"Translate this page\" option is triggered for MyPage, and relevant langs are selected from the configured langs that Smartling supports. (We don't have to translate into all of them)</p> </li> <li> <p>A translation Job is created in Smartling, awaiting authorization by our L10N team.</p> </li> <li> <p>A L10N team colleague authorizes the Job and selects the relevant translation workflow(s) for the relevant lang(s)</p> <ul> <li>\u26a0\ufe0f Note that one Wagtail Page (or one Wagtail Snippet) creates one single Job, so if you select mutiple target languages for that Job and submit it, you won't get it back from Smartling until <code>all</code> languages involved are submitted by translators. One way around this is to submit each language as a separate Job, but that creates more work for our L10N team to coordinate. (We are looking to refine that experience in the future and to make it better for everyone.)</li> </ul> </li> <li> <p>Once the job is completed, the localised strings flow back to Wagtail and populate a <code>draft</code> version of each language-specific page.</p> </li> <li> <p>A human reviews these draft pages and publishes them</p> <ul> <li>\u26a0\ufe0f When a translation flows back, by default the relevant pages are <code>not</code> automatically published. At the moment, CMS admins are emailed for each language in a Job when it is synced back from Smartling, reminding them of this. (We may well move this to in-dashboard Wagtail <code>Tasks</code> for better UX.)</li> <li>The CMS admin sidebar has a link to <code>Smartling Jobs</code>. You can use this to see what translations have landed, and also follow the link to the localized version of the page, which you can then Preview, visually check, then Publish like a regular page.</li> </ul> </li> </ol> <p>Notes:</p> <ul> <li>Smartling/<code>wagtail-localize-smartling</code> will only translate pages from the base lang (<code>en-US</code>) to another lang - it won't treat, say, a Page in <code>fr</code> as a source-language document.</li> <li>If a string is received from Smartling into the CMS and then manually edited on the CMS side, the change will <code>not</code> be overwritten by subsequent Smartling syncs and the manual edit needs to be added on the Smartling side for consistency and stability.</li> <li>If a page is translated from <code>en-US</code> once, then has new <code>en-US</code> content added that is sent for translation, that will trigger a new Smartling Job. When that job is complete, it <code>will</code> overwrite any manual edits made to a translation within the CMS. This is why it's important to make sure Smartling contains any manual tweaks done to translations in the CMS.</li> </ul>"},{"location":"cms/#automated-via-pontoon","title":"Automated via Pontoon","text":"<p>It should also be possible to use Pontoon with <code>wagtail-localize</code>. (There are notes on the Pontoon integration here, but we have not yet tried to enable this alongside <code>wagtail-localize-smartling</code>).</p> <p>Additionally using Pontoon would let us benefit from community translations across a broad range of languages. However, we have yet to try to set this up and would need to agree which parts of the site do and do not use Pontoon.</p>"},{"location":"cms/#infrastructure-notes","title":"Infrastructure notes","text":""},{"location":"cms/#sso-authentication-setup_1","title":"SSO authentication setup","text":"<p>When the env vars <code>OIDC_RP_CLIENT_ID</code> and <code>OIDC_RP_CLIENT_SECRET</code> are present and <code>USE_SSO_AUTH</code> is set to True in settings, Bedrock will use Mozilla SSO instead of Django's default username + password approach to sign in. The deployed sites will have these set, but we also have credentials available for using SSO locally if you need to develop something that needs it - see our password vault.</p> <p>Note that Bedrock in SSO mode will <code>not</code> support 'drive by' user creation even if they have an <code>@mozilla.com</code> identity. Only users who already exist in the Wagtail admin as a User will be allowed to log in. You can create new users using Django's createsuperuser command, setting both the username and email to be your <code>flast@mozilla.com</code> LDAP address</p>"},{"location":"cms/#non-sso-authentication-for-local-builds","title":"Non-SSO authentication for local builds","text":"<p>If you just want to use a username and password locally, you can - ensure those env vars above are not set, and use Django's createsuperuser command to make an admin user in your local build.</p>"},{"location":"coding/","title":"Developing on Bedrock","text":""},{"location":"coding/#coding","title":"Developing on Bedrock","text":""},{"location":"coding/#managing-dependencies","title":"Managing Dependencies","text":"<p>For Python we use <code>pip-compile</code> from pip-tools to manage dependencies expressed in our requirements files. <code>pip-compile</code> is wrapped up in Makefile commands, to ensure we use it consistently.</p> <p>If you add a new Python dependency (eg to <code>requirements/prod.in</code> or <code>requirements/dev.in</code>) you can generate a pinned and hash-marked addition to our requirements files just by running:</p> <pre><code>make compile-requirements\n</code></pre> <p>and committing any changes that are made. Please re-build your docker image and test it with <code>make build test</code> to be sure the dependency does not cause a regression.</p> <p>Similarly, if you upgrade a pinned dependency in an <code>*.in</code> file, run <code>make compile-requirements</code> then rebuild, test and commit the results</p> <p>To check for stale Python dependencies (basically <code>pip list -o</code> but in the Docker container):</p> <pre><code>make check-requirements\n</code></pre> <p>For Node packages we use NPM, which should already be installed alongside Node.js.</p>"},{"location":"coding/#front-end-dependencies","title":"Front-end Dependencies","text":"<p>Our team maintains a few dependencies that we serve on Bedrock's front-end.</p> <ul> <li>@mozilla-protocol/core: Bedrock's primary design system</li> <li>@mozmeao/cookie-helper: A complete cookies reader/writer framework</li> <li>@mozmeao/dnt-helper: Do Not Track (DNT) helper</li> <li>@mozmeao/trafficcop: Used for A/B testing page variants</li> </ul> <p>Because they are all published on NPM, install the packages and keep up-to-date with the latest version of each dependency by running an <code>npm install</code>. For further documentation on installing NPM packages, check out the official documentation.</p>"},{"location":"coding/#asset-management-and-bundling","title":"Asset Management and Bundling","text":"<p>Bedrock uses Webpack to manage front-end asset processing and bundling. This includes processing and minifying JavaScript and SCSS/CSS bundles, as well as managing static assets such as images, fonts, and other common file types.</p> <p>When developing on bedrock you can start Webpack by running <code>make run</code> when using Docker, or <code>npm start</code> when running bedrock locally.</p> <p>Once Webpack has finished compiling, a local development server will be available at localhost:8000. When Webpack detects changes to a JS/SCSS file, it will automatically recompile the bundle and then refresh any page running locally in the browser.</p>"},{"location":"coding/#webpack-configuration","title":"Webpack Configuration","text":"<p>We have two main Webpack config files in the root directory:</p> <p>The <code>webpack.static.config.js</code> file is responsible for copying static assets, such as images and fonts, from the <code>/media/</code> directory over to the <code>/assets/</code> directory. This is required so Django can serve them correctly.</p> <p>The <code>webpack.config.js</code> file is responsible for processing JS and SCSS files in the <code>/media/</code> directory and compiling them into the <code>/assets/</code> directory. This config file also starts a local development server and watches for file changes.</p> <p>We use two separate config files to keep responsibilities clearly defined, and to make the configs both shorter and easier to follow.</p> <p>Note</p> <p>Because of the large number of files used in bedrock, only JS and SCSS files managed by <code>webpack.config.js</code> are watched for changes when in development mode. This helps save on memory consumption. The implication of this is that files handled by <code>webpack.static.config.js</code> are only copied over when Webpack first runs. If you update an image for example, then you will need to stop and restart Webpack to pick up the change. This is not true for JS and SCSS files, which will be watched for change automatically.</p>"},{"location":"coding/#asset-bundling","title":"Asset Bundling","text":"<p>Asset bundles for both JS and SCSS are defined in <code>./media/static-bundles.json</code>. This is the file where you can define the bundle names that will get used in page templates. For example, a CSS bundle can be defined as:</p> <pre><code>\"css\": [\n    {\n        \"files\": [\n            \"css/firefox/new/basic/download.scss\"\n        ],\n        \"name\": \"firefox_new_download\"\n    }\n]\n</code></pre> <p>Which can then be referenced in a page template using:</p> <pre><code>{{ css_bundle('firefox_new_download') }}\n</code></pre> <p>A JS bundle can be defied as:</p> <pre><code>\"js\": [\n    {\n        \"files\": [\n            \"protocol/js/protocol-modal.js\",\n            \"js/firefox/new/basic/download.js\"\n        ],\n        \"name\": \"firefox_new_download\"\n    }\n]\n</code></pre> <p>Which can then be referenced in a page template using:</p> <pre><code>{{ js_bundle('firefox_new_download') }}\n</code></pre> <p>Once you define a bundle in <code>static-bundles.json</code>, the <code>webpack.config.js</code> file will use these as entrypoints for compiling JS and CSS and watching for changes.</p>"},{"location":"coding/#writing-javascript","title":"Writing JavaScript","text":"<p>Bedrock's Webpack configuration supports some different options for writing JavaScript:</p>"},{"location":"coding/#default-configuration","title":"Default Configuration","text":"<p>Write <code>example-script.js</code> using ES5 syntax and features. Webpack will bundle the JS as-is, without any additional pre-processing.</p>"},{"location":"coding/#babel-configuration","title":"Babel Configuration","text":"<p>Write <code>example-script.es6.js</code> using ES2015+ syntax. Webpack will transpile the code to ES5 using Babel. This is useful when you want to write modern syntax but still support older browsers.</p> <p>Important</p> <p>Whilst Babel will transpile most modern JS syntax to ES5 when suitable fallbacks exist, it won't automatically include custom polyfills for everything since these can start to greatly increase bundle size. If you want to use <code>Promise</code> or <code>async/await</code> functions for example, then you will need to load polyfills for those. This can be done either at the page level, or globally in <code>lib.js</code> if it's something that multiple pages would benefit from. But please pick and choose wisely, and be concious of performance.</p> <p>For pages that are served to Firefox browsers only, such as <code>/whatsnew</code>, it is also possible to write native modern JS syntax and serve that directly in production. Here there is no need to include the <code>.es6.js</code> file extension. Instead, you can simply use <code>.js</code>. The rules that define which files can do this can be found in our ESLint config.</p>"},{"location":"coding/#writing-url-patterns","title":"Writing URL Patterns","text":"<p>URL patterns should be the entire URL you desire, minus any prefixes from URLs files importing this one, and including a trailing slash. You should also give the URL a name so that other pages can reference it instead of hardcoding the URL. Example:</p> <pre><code>path(\"channel/\", channel, name=\"mozorg.channel\")\n</code></pre> <p>If you only want to render a template and don't need to do anything else in a custom view, Bedrock comes with a handy shortcut to automate all of this:</p> <pre><code>from bedrock.mozorg.util import page\n\npage(\"channel/\", \"mozorg/channel.html\")\n</code></pre> <p>You don't need to create a view. It will serve up the specified template at the given URL (the first parameter. see the Django docs for details). You can also pass template data as keyword arguments:</p> <pre><code>page(\n    \"channel/\",\n    \"mozorg/channel.html\",\n    latest_version=product_details.firefox_versions[\"LATEST_FIREFOX_VERSION\"],\n)\n</code></pre> <p>The variable <code>latest_version</code> will be available in the template.</p>"},{"location":"coding/#finding-templates-by-url","title":"Finding Templates by URL","text":""},{"location":"coding/#general-structure","title":"General Structure","text":"<p>Bedrock follows the Django app structure and most templates are easy to find by matching URL path segments to folders and files within the correct app.</p> <p>| URL: <code>https://www.mozilla.org/en-US/firefox/features/private-browsing/</code> | Template path: <code>bedrock/bedrock/firefox/templates/firefox/features/private-browsing.html</code></p> <p>To get from URL to template path:</p> <ul> <li>Ignore <code>https://www.mozilla.org</code> and the locale path segment <code>/en-US</code>. The next path segment is the app name <code>/firefox</code>.</li> <li>From the root folder of bedrock, find the app's template folder at <code>bedrock/{app}/templates/{app}</code></li> <li>Match remaining URL path segments (<code>/features/private-browsing</code>) to the template folder's structure (<code>/features/private-browsing.html</code>)</li> </ul> <p>Note</p> <p><code>mozorg</code> is the app name for the home page and child pages related to Mozilla Corporation (i.e. About, Contact, Diversity).</p>"},{"location":"coding/#whatsnew-and-firstrun","title":"Whatsnew and Firstrun","text":"<p>These pages are specific to Firefox browsers, and only appear when a user updates or installs and runs a Firefox browser for the first time. The URL and template depend on what Firefox browser and version are in use.</p> <p>Note</p> <p>There may be extra logic in the app's <code>views.py</code> file to change the template based on locale or geographic location as well.</p>"},{"location":"coding/#firefox-release","title":"Firefox release","text":"<p>Version number is digits only.</p> <p>| Whatsnew URL: https://www.mozilla.org/en-US/firefox/99.0/whatsnew/ | Template path: https://github.com/mozilla/bedrock/tree/main/bedrock/firefox/templates/firefox/whatsnew</p> <p>| Firstrun URL: https://www.mozilla.org/en-US/firefox/99.0/firstrun/ | Template path: https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/firstrun/firstrun.html</p>"},{"location":"coding/#firefox-nightly","title":"Firefox Nightly","text":"<p>Version number is digits and a1.</p> <p>| Whatsnew URL: https://www.mozilla.org/en-US/firefox/99.0a1/whatsnew/ | Template path: https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/nightly/whatsnew.html</p> <p>| Firstrun URL: https://www.mozilla.org/en-US/firefox/nightly/firstrun/ | Template path: https://github.com/mozilla/bedrock/tree/main/bedrock/firefox/templates/firefox/nightly</p>"},{"location":"coding/#firefox-developer","title":"Firefox Developer","text":"<p>Version number is digits and a2.</p> <p>| Whatsnew URL: https://www.mozilla.org/en-US/firefox/99.0a2/whatsnew/ | Template path: https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/developer/whatsnew.html</p> <p>| Firstrun URL: https://www.mozilla.org/en-US/firefox/99.0a2/firstrun/ | Template path: https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/developer/firstrun.html</p>"},{"location":"coding/#release-notes","title":"Release Notes","text":"<p>Release note templates live here: https://github.com/mozilla/bedrock/tree/main/bedrock/firefox/templates/firefox/releases</p> <p>Note</p> <p>Release note content is pulled in from an external data source.</p> <ul> <li>Firefox release: https://www.mozilla.org/en-US/firefox/99.0.1/releasenotes/</li> <li>Firefox Developer and Beta: https://www.mozilla.org/en-US/firefox/100.0beta/releasenotes/</li> <li>Firefox Nightly: https://www.mozilla.org/en-US/firefox/101.0a1/releasenotes/</li> <li>Firefox Android: https://www.mozilla.org/en-US/firefox/android/99.0/releasenotes/</li> <li>Firefox iOS: https://www.mozilla.org/en-US/firefox/ios/99.0/releasenotes/</li> </ul>"},{"location":"coding/#optimizing-images","title":"Optimizing Images","text":"<p>Images can take a long time to load and eat up a lot of bandwidth. Always take care to optimize images before uploading them to the site. There are a number of great online resources available to help with this:</p> <ul> <li>https://tinypng.com/</li> <li>https://jakearchibald.github.io/svgomg/</li> <li>https://squoosh.app/</li> </ul> <p>We also bundle the svgo package as a dev dependency, which can optimize SVGs on the command line.</p>"},{"location":"coding/#embedding-images","title":"Embedding Images","text":"<p>Images should be included on pages using one of the following helper functions.</p>"},{"location":"coding/#primary-image-helpers","title":"Primary image helpers","text":"<p>The following image helpers support the most common features and use cases you may encounter when coding pages:</p>"},{"location":"coding/#static","title":"static()","text":"<p>For a simple image, the <code>static()</code> function is used to generate the image URL. For example:</p> <pre><code>&lt;img src=\"{{ static('img/firefox/new/firefox-wordmark-logo.svg') }}\" alt=\"Firefox\"&gt;\n</code></pre> <p>will output an image:</p> <pre><code>&lt;img src=\"/media/img/firefox/new/firefox-wordmark-logo.svg\" alt=\"Firefox\"&gt;\n</code></pre>"},{"location":"coding/#resp_img","title":"resp_img()","text":"<p>For responsive images, where we want to specify multiple different image sizes and let the browser select which is best to use.</p> <p>The example below shows how to serve an appropriately sized, responsive red panda image:</p> <pre><code>resp_img(\n    url=\"img/panda-500.png\",\n    srcset={\n        \"img/panda-500.png\": \"500w\",\n        \"img/panda-750.png\": \"750w\",\n        \"img/panda-1000.png\": \"1000w\",\n    },\n    sizes={\n        \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n        \"default\": \"calc(100vw - 50px)\",\n    },\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;img src=\"/media/img/panda-500.png\"\n     srcset=\"/media/img/panda-500.png 500w,/media/img/panda-750.png 750w,/media/img/panda-1000.png 1000w\"\n     sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\" alt=\"\"&gt;'\n</code></pre> <p>In the above example we specified the available image sources using the <code>srcset</code> parameter. We then used <code>sizes</code> to say:</p> <ul> <li>When the viewport is greater than <code>1000px</code> wide, the panda image will take up roughly half of the page width.</li> <li>When the viewport is less than <code>1000px</code> wide, the panda image will take up roughly full page width.</li> </ul> <p>The default image <code>src</code> is what we specified using the <code>url</code> param. This is also what older browsers will fall back to using. Modern browsers will instead pick the best source option from <code>srcset</code> (based on both the estimated image size and screen resolution) to satisfy the condition met in <code>sizes</code>.</p> <p>Note</p> <p>The value <code>default</code> in the second <code>sizes</code> entry above should be used when you want to omit a media query. This makes it possible to provide a fallback size when no other media queries match.</p> <p>Another example might be to serve a high resolution alternative for a fixed size image:</p> <pre><code>resp_img(url=\"img/panda.png\", srcset={\"img/panda-high-res.png\": \"2x\"})\n</code></pre> <p>This would output:</p> <pre><code>&lt;img src=\"/media/img/panda.png\" srcset=\"/media/img/panda-high-res.png 2x\" alt=\"\"&gt;\n</code></pre> <p>Here we don't need a <code>sizes</code> attribute, since the panda image is fixed in size and small enough that it won't need to resize along with the browser window. Instead the <code>srcset</code> image includes an alternate high resolution source URL, along with a pixel density descriptor. This can then be used to say:</p> <ul> <li>When a browser specifies a device pixel ratio of <code>2x</code> or greater, use <code>panda-high-res.png</code>.</li> <li>When a browser specifies a device pixel ration of less than <code>2x</code>, use <code>panda.png</code>.</li> </ul> <p>The <code>resp_img()</code> helper also supports localized images by setting the <code>'l10n'</code> parameter to `True``:</p> <pre><code>resp_img(\n    url=\"img/panda-500.png\",\n    srcset={\n        \"img/panda-500.png\": \"500w\",\n        \"img/panda-750.png\": \"750w\",\n        \"img/panda-1000.png\": \"1000w\",\n    },\n    sizes={\n        \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n        \"default\": \"calc(100vw - 50px)\",\n    },\n    optional_attributes={\"l10n\": True},\n)\n</code></pre> <p>This would output (assuming <code>de</code> was your locale):</p> <pre><code>&lt;img src=\"/media/img/l10n/de/panda-500.png\"\n     srcset=\"/media/img/l10n/de/panda-500.png 500w,/media/img/l10n/de/panda-750.png 750w,/media/img/l10n/de/panda-1000.png 1000w\"\n     sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\" alt=\"\"&gt;'\n</code></pre> <p>Finally, you can also specify any other additional attributes you might need using <code>optional_attributes</code>:</p> <pre><code>resp_img(\n    url=\"img/panda-500.png\",\n    srcset={\n        \"img/panda-500.png\": \"500w\",\n        \"img/panda-750.png\": \"750w\",\n        \"img/panda-1000.png\": \"1000w\",\n    },\n    sizes={\n        \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n        \"default\": \"calc(100vw - 50px)\",\n    },\n    optional_attributes={\n        \"alt\": \"Red Panda\",\n        \"class\": \"panda-hero\",\n        \"height\": \"500\",\n        \"l10n\": True,\n        \"loading\": \"lazy\",\n        \"width\": \"500\",\n    },\n)\n</code></pre>"},{"location":"coding/#picture","title":"picture()","text":"<p>For responsive images, where we want to serve different images, or image types, to suit different display sizes.</p> <p>The example below shows how to serve a different image for desktop and mobile sizes screens:</p> <pre><code>picture(\n    url=\"img/panda-mobile.png\",\n    sources=[\n        {\"media\": \"(max-width: 799px)\", \"srcset\": {\"img/panda-mobile.png\": \"default\", 'width' : '160', 'height' : '320'}},\n        {\"media\": \"(min-width: 800px)\", \"srcset\": {\"img/panda-desktop.png\": \"default\", 'width' : '640', 'height' : '1280'}},\n    ],\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;picture&gt;\n    &lt;source media=\"(max-width: 799px)\" srcset=\"/media/img/panda-mobile.png\" width=\"160\" height=\"320\"&gt;\n    &lt;source media=\"(min-width: 800px)\" srcset=\"/media/img/panda-desktop.png\" width=\"640\" height=\"1280\"&gt;\n    &lt;img src=\"/media/img/panda-mobile.png\" alt=\"\"&gt;\n&lt;/picture&gt;\n</code></pre> <p>In the above example, the default image <code>src</code> is what we specified using the <code>url</code> param. This is also what older browsers will fall back to using. We then used the <code>sources</code> parameter to specify one or more alternate image <code>&lt;source&gt;</code> elements, which modern browsers can take advantage of. For each <code>&lt;source&gt;</code>, <code>media</code> lets us specify a media query as a condition for when to load an image, and <code>srcset</code> lets us specify one or more sizes for each image. Each <code>srcset</code> also takes optional parameters for <code>height</code> and <code>width</code>. Defining height and width helps the Browser reserve space for the image and avoid content shifting around on the page. If the image will not change dimensions, these can be defined in the <code>optional_attributes</code> for the entire element instead of separately like this.</p> <p>Note</p> <p>The value <code>default</code> in the <code>srcset</code> entry above should be used when you want to omit a descriptor. In this example we only have one entry in <code>srcset</code> (meaning it will be chosen immediately should the media query be satisfied), hence we omit a descriptor value.</p> <p>A more complex example might be when we want to load responsively sized, animated gifs, but also offer still images for users who set <code>(prefers-reduced-motion: reduce)</code>:</p> <pre><code>picture(\n    url=\"img/dancing-panda-500.gif\",\n    sources=[\n        {\n            \"media\": \"(prefers-reduced-motion: reduce)\",\n            \"srcset\": {\n                \"img/sleeping-panda-500.png\": \"500w\",\n                \"img/sleepinng-panda-750.png\": \"750w\",\n                \"img/sleeping-panda-1000.png\": \"1000w\",\n            },\n            \"sizes\": {\n                \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n                \"default\": \"calc(100vw - 50px)\",\n            },\n        },\n        {\n            \"media\": \"(prefers-reduced-motion: no-preference)\",\n            \"srcset\": {\n                \"img/dancing-panda-500.gif\": \"500w\",\n                \"img/dancing-panda-750.gif\": \"750w\",\n                \"img/dancing-panda-1000.gif\": \"1000w\",\n            },\n            \"sizes\": {\n                \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n                \"default\": \"calc(100vw - 50px)\",\n            },\n        },\n    ],\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;picture&gt;\n    &lt;source media=\"(prefers-reduced-motion: reduce)\"\n            srcset=\"/media/img/sleeping-panda-500.png 500w,/media/img/sleeping-panda-750.png 750w,/media/img/sleeping-panda-1000.png 1000w\"\n            sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\"&gt;\n    &lt;source media=\"(prefers-reduced-motion: no-preference)\"\n            srcset=\"/media/img/dancing-panda-500.gif 500w,/media/img/dancing-panda-750.gif 750w,/media/img/dancing-panda-1000.gif 1000w\"\n            sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\"&gt;\n    &lt;img src=\"/media/img/dancing-panda-500.gif\" alt=\"\"&gt;\n&lt;/picture&gt;\n</code></pre> <p>In the above example we would default to loading animated gifs, but if a user agent specified <code>(prefers-reduced-motion: reduce)</code> then the browser would load static png files instead. Multiple image sizes are also supported for each <code>&lt;source&gt;</code> using <code>srcset</code> and <code>sizes</code>.</p> <p>Another type of use case might be to serve different image formats, so capable browsers can take advantage of more efficient encoding:</p> <pre><code>picture(\n    url=\"img/red-panda.png\",\n    sources=[{\"type\": \"image/webp\", \"srcset\": {\"img/red-panda.webp\": \"default\"}}],\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;picture&gt;\n    &lt;source type=\"image/webp\" srcset=\"/media/img/red-panda.webp\"&gt;\n    &lt;img src=\"/media/img/red-panda.png\" alt=\"\"&gt;\n&lt;/picture&gt;\n</code></pre> <p>In the above example we use <code>sources</code> to specify an alternate image with a <code>type</code> attribute of <code>image/webp</code>. This lets browsers that support WebP to download <code>red-panda.webp</code>, whilst older browsers would download <code>red-panda.png</code>.</p> <p>Like <code>resp_img()</code>, the <code>picture()</code> helper also supports L10n images and other useful attributes via the <code>optional_attributes</code> parameter:</p> <pre><code>picture(\n    url=\"img/panda-mobile.png\",\n    sources=[\n        {\"media\": \"(max-width: 799px)\", \"srcset\": {\"img/panda-mobile.png\": \"default\"}},\n        {\"media\": \"(min-width: 800px)\", \"srcset\": {\"img/panda-desktop.png\": \"default\"}},\n    ],\n    optional_attributes={\n        \"alt\": \"Red Panda\",\n        \"class\": \"panda-hero\",\n        \"l10n\": True,\n        \"loading\": \"lazy\",\n    },\n)\n</code></pre>"},{"location":"coding/#which-image-helper-should-you-use","title":"Which image helper should you use?","text":"<p>This is a good question. The answer depends entirely on the image in question. A good rule of thumb is as follows:</p> <p>-</p> <pre><code>Is the image a vector format (e.g. `.svg`)?\n\n:   -   If yes, then for most cases you can simply use `static()`.\n</code></pre> <p>-</p> <pre><code>Is the image a raster format (e.g. `.png` or `.jpg`)?\n\n:   -   Is the same image displayed on both large and small viewports? Does the image need to scale as the browser resizes? If yes to both, then use `resp_img()` with both `srcset` and `sizes`.\n    -   Is the image fixed in size (non-responsive)? Do you need to serve a high resolution version? If yes to both, then use `resp_img()` with just `srcset`.\n</code></pre> <ul> <li> <p>Does the source image need to change depending on a media query (e.g serve a different image on both desktop and mobile)? If yes, then use <code>picture()</code> with <code>media</code> and <code>srcset</code>.</p> </li> <li> <p>Is the image format only supported in certain browsers? Do you need to provide a fallback? If yes to both, then use <code>picture()</code> with <code>type</code> and <code>srcset</code>.</p> </li> </ul>"},{"location":"coding/#secondary-image-helpers","title":"Secondary image helpers","text":"<p>The following image helpers are less commonly used, but exist to support more specific use cases. Some are also encapsulated as features inside inside of primary helpers, such as <code>l1n_img()</code>.</p>"},{"location":"coding/#l10n_img","title":"l10n_img()","text":"<p>Images that have translatable text can be handled with <code>l10n_img()</code>:</p> <pre><code>&lt;img src=\"{{ l10n_img('firefox/os/have-it-all/messages.jpg') }}\"&gt;\n</code></pre> <p>The images referenced by <code>l10n_img()</code> must exist in <code>media/img/l10n/</code>, so for above example, the images could include <code>media/img/l10n/en-US/firefox/os/have-it-all/messages.jpg</code> and <code>media/img/l10n/es-ES/firefox/os/have-it-all/messages.jpg</code>.</p>"},{"location":"coding/#qrcode","title":"qrcode()","text":"<p>This is a helper function that will output SVG data for a QR Code at the spot in the template where it is called. It caches the results to the <code>data/qrcode_cache</code> directory, so it only generates the SVG data one time per data and box_size combination.</p> <pre><code>qrcode(\"https://accounts.firefox.com\", 30)\n</code></pre> <p>The first argument is the data you'd like to encode in the QR Code (usually a URL), and the second is the \"box size\". It's a parameter that tells the generator how large to set the height and width parameters on the XML SVG tag, the units of which are \"mm\". This can be overriden with CSS so you may not need to use it at all. The <code>box_size</code> parameter is optional.</p>"},{"location":"coding/#using-large-assets","title":"Using Large Assets","text":"<p>We don't want to (and if large enough GitHub won't let us) commit large files to the bedrock repo. Files such as large PDFs or very-high-res JPG files (e.g. leadership team photos), or videos are not well-tracked in git and will make every checkout after they're added slower and this diffs less useful. So we have another domain at which we upload these files: assets.mozilla.net</p> <p>This domain is simply an AWS S3 bucket with a CloudFront <code>CDN (Content Delivery Network)</code> in front of it. It is highly available and fast. We've made adding files to this domain very simple using git-lfs. You simply install git-lfs, clone our assets.mozilla.net repo, and then add and commit files under the <code>assets</code> directory there as usual. Open a pull request, and once it's merged it will be automatically uploaded to the S3 bucket and be available on the domain.</p> <p>For example, if you add a file to the repo under <code>assets/pdf/the-dude-abides.pdf</code>, it will be available as https://assets.mozilla.net/pdf/the-dude-abides.pdf. Once that is done you can link to that URL from bedrock as you would any other URL.</p>"},{"location":"coding/#writing-migrations","title":"Writing Migrations","text":"<p>Bedrock uses Django's built-in Migrations framework for its database migrations, and has no custom database routing, etc. So, no big surprises here -- write things as you regularly would.</p> <p>However, as with any complex system, care needs to be taken with schema changes that drop or rename database columns. Due to the way the rollout process works (ask for details directly from the team), an absent column can cause some of the rollout to enter a crashloop.</p> <p>To avoid this, split your changes across releases, such as below.</p> <p>For column renames:</p> <ul> <li>Release 1: Add your new column</li> <li>Release 2: Amend the codebase to use it instead of the old column</li> <li>Release 3: Clean up - drop the old, deprecated column, which should not be referenced in code at this point.</li> </ul> <p>For column drops:</p> <ul> <li>Release 1: Update all code that uses the relevant column, so that nothing interacts with it any more.</li> <li>Release 2: Clean up - drop the old, deprecated column.</li> </ul> <p>With both paths, check for any custom schema or data migrations that might reference the deprecated column.</p>"},{"location":"coding/#writing-views","title":"Writing Views","text":"<p>You should rarely need to write a view for mozilla.org. Most pages are static and you should use the <code>page</code> function documented above.</p> <p>If you need to write a view and the page is translated or translatable then it should use the <code>l10n_utils.render()</code> function to render the template.</p> <pre><code>from lib import l10n_utils\n\nfrom django.views.decorators.http import require_safe\n\n\n@require_safe\ndef my_view(request):\n    # do your fancy things\n    ctx = {\"template_variable\": \"awesome data\"}\n    return l10n_utils.render(request, \"app/template.html\", ctx)\n</code></pre> <p>Make sure to namespace your templates by putting them in a directory named after your app, so instead of templates/template.html they would be in templates/blog/template.html if <code>blog</code> was the name of your app.</p> <p>The <code>require_safe</code> ensures that only <code>GET</code> or <code>HEAD</code> requests will make it through to your view.</p> <p>If you prefer to use Django's Generic View classes we have a convenient helper for that. You can use it either to create a custom view class of your own, or use it directly in a <code>urls.py</code> file.</p> <pre><code># app/views.py\nfrom lib.l10n_utils import L10nTemplateView\n\n\nclass FirefoxRoxView(L10nTemplateView):\n    template_name = \"app/firefox-rox.html\"\n\n\n# app/urls.py\nurlpatterns = [\n    # from views.py\n    path(\"firefox/rox/\", FirefoxRoxView.as_view()),\n    # directly\n    path(\n        \"firefox/sox/\", L10nTemplateView.as_view(template_name=\"app/firefox-sox.html\")\n    ),\n]\n</code></pre> <p>The <code>L10nTemplateView</code> functionality is mostly in a template mixin called <code>LangFilesMixin</code> which you can use with other generic Django view classes if you need one other than <code>TemplateView</code>. The <code>L10nTemplateView</code> already ensures that only <code>GET</code> or <code>HEAD</code> requests will be served.</p>"},{"location":"coding/#variation-views","title":"Variation Views","text":"<p>We have a generic view that allows you to easily create and use a/b testing templates. If you'd like to have either separate templates or just a template context variable for switching, this will help you out. For example.</p> <pre><code># urls.py\n\nfrom django.urls import path\n\nfrom bedrock.utils.views import VariationTemplateView\n\nurlpatterns = [\n    path(\n        \"testing/\",\n        VariationTemplateView.as_view(\n            template_name=\"testing.html\", template_context_variations=[\"a\", \"b\"]\n        ),\n        name=\"testing\",\n    ),\n]\n</code></pre> <p>This will give you a context variable called <code>variation</code> that will either be an empty string if no param is set, or <code>a</code> if <code>?v=a</code> is in the URL, or <code>b</code> if <code>?v=b</code> is in the URL. No other options will be valid for the <code>v</code> query parameter and <code>variation</code> will be empty if any other value is passed in for <code>v</code> via the URL. So in your template code you'd simply do the following:</p> <pre><code>{% if variation == 'b' %}&lt;p&gt;This is the B variation of our test. Enjoy!&lt;/p&gt;{% endif %}\n</code></pre> <p>If you'd rather have a fully separate template for your test, you can use the <code>template_name_variations</code> argument to the view instead of <code>template_context_variations</code>.</p> <pre><code># urls.py\n\nfrom django.urls import path\n\nfrom bedrock.utils.views import VariationTemplateView\n\nurlpatterns = [\n    path(\n        \"testing/\",\n        VariationTemplateView.as_view(\n            template_name=\"testing.html\", template_name_variations=[\"1\", \"2\"]\n        ),\n        name=\"testing\",\n    ),\n]\n</code></pre> <p>This will not provide any extra template context variables, but will instead look for alternate template names. If the URL is <code>testing/?v=1</code>, it will use a template named <code>testing-1.html</code>, if <code>v=2</code> it will use <code>testing-2.html</code>, and for everything else it will use the default. It simply puts a dash and the variation value between the template file name and file extension.</p> <p>It is theoretically possible to use the template name and template context versions of this view together, but that would be an odd situation and potentially inappropriate for this utility.</p> <p>You can also limit your variations to certain locales. By default the variations will work for any localization of the page, but if you supply a list of locales to the <code>variation_locales</code> argument to the view then it will only set the variation context variable or alter the template name (depending on the options explained above) when requested at one of said locales. For example, the template name example above could be modified to only work for English or German like so</p> <pre><code># urls.py\n\nfrom django.urls import path\n\nfrom bedrock.utils.views import VariationTemplateView\n\nurlpatterns = [\n    path(\n        \"testing/\",\n        VariationTemplateView.as_view(\n            template_name=\"testing.html\",\n            template_name_variations=[\"1\", \"2\"],\n            variation_locales=[\"en-US\", \"de\"],\n        ),\n        name=\"testing\",\n    ),\n]\n</code></pre> <p>Any request to the page in for example French would not use the alternate template even if a valid variation were given in the URL.</p> <p>Note</p> <p>If you'd like to add this functionality to an existing Class-Based View, there is a mixin that implements this pattern that should work with most views: <code>bedrock.utils.views.VariationMixin</code>.</p>"},{"location":"coding/#geo-location","title":"Geo Template View","text":"<p>Now that we have our <code>CDN (Content Delivery Network)</code> configured properly, we can also just swap out templates per request country. This is very similar to the above, but it will simply use the proper template for the country from which the request originated.</p> <pre><code>from bedrock.base.views import GeoTemplateView\n\n\nclass CanadaIsSpecialView(GeoTemplateView):\n    geo_template_names = {\n        \"CA\": \"mozorg/canada-is-special.html\",\n    }\n    template_name = \"mozorg/everywhere-else-is-also-good.html\"\n</code></pre>"},{"location":"coding/#testing-geo-views","title":"Testing Geo Views","text":"<p>For testing purposes while you're developing or on any deployment that is not accessed via the production domain (www.mozilla.org) you can append your URL with a <code>geo</code> query param (e.g. <code>/firefox/?geo=DE</code>) and that will take precedence over the country from the request header. Remember to use a valid ISO country code as param value.</p>"},{"location":"coding/#other-geo-stuff","title":"Other Geo Stuff","text":"<p>There are a couple of other tools at your disposal if you need to change things depending on the location of the user. You can use the <code>bedrock.base.geo.get_country_from_request</code> function in a view and it will return the country code for the request (either from the <code>CDN (Content Delivery Network)</code> or the query param, just like above).</p> <pre><code>from bedrock.base.geo import get_country_from_request\n\n\ndef dude_view(request):\n    country = get_country_from_request(request)\n    if country == \"US\":\n        ...  # do a thing for the US\n    else:\n        ...  # do the default thing\n</code></pre> <p>The other convenience available is that the country code, either from the <code>CDN (Content Delivery Network)</code> or the query param, is avilable in any template in the <code>country_code</code> variable. This allows you to change anything about how the template renders based on the location of the user.</p> <pre><code>{% if country_code == \"US\" %}\n    &lt;h1&gt;GO MURICA!&lt;/h1&gt;\n{% else %}\n    &lt;h1&gt;Yay World!&lt;/h1&gt;\n{% endif %}\n</code></pre> <p>Reference:</p> <ul> <li>Officially assigned list of ISO country codes.</li> </ul>"},{"location":"coding/#metrics-collection-with-markus","title":"Metrics Collection with Markus","text":"<p>Markus is a metrics library that we use in our project for collecting and reporting statistics about our code's operation. It provides a simple and consistent way to record custom metrics from your application, which can be crucial for monitoring and performance analysis.</p> <p>Markus supports a variety of backends, including Datadog, Statsd, and Logging. This means you can choose the backend that best fits your monitoring infrastructure and requirements. Each backend has its own set of features and capabilities, but Markus provides a unified interface to all of them.</p> <p>Once the metrics are collected by Markus they are then forwarded to Telegraf. Telegraf is an agent for collecting and reporting metrics, which we use to process and format the data before it's sent to Grafana.</p> <p>Grafana is a popular open-source platform for visualizing metrics. It allows us to create dashboards with panels representing the metrics we're interested in, making it easy to understand the data at a glance.</p> <p>Here's an example of how to use Markus to record a metric:</p> <pre><code>from bedrock.base import metrics\n\n# Counting events\nmetrics.incr(\"event_name\")\n\n# Timing events\nmetrics.timing(\"event_name\", 123)\n\n# Or timing events with context manager\nwith metrics.timer(\"event_name\"):\n    ...  # code to time goes here\n</code></pre> <p>In addition to recording the metric values, Markus also allows you to add tags to your metrics. Tags are key-value pairs that provide additional context about the metric, making it easier to filter and aggregate the data in Grafana. For example, you might tag a metric with the version of your application, the user's country, or the result of an operation. To add tags to a metric in Markus, you can pass them as a dictionary to the metric recording method. Here's an example:</p> <pre><code># Counting events with tags\nmetrics.incr(\"event_name\", tags=[f\"version:{version}\", f\"country:{country}\"])\n</code></pre> <p>For more information, refer to the Markus documentation.</p>"},{"location":"coding/#coding-style","title":"Coding Style","text":"<p>Bedrock uses the following open source tools to follow coding styles and conventions, as well as applying automatic code formatting:</p> <ul> <li>ruff for Python style, code quality rules, and import ordering.</li> <li>black for Python code formatting.</li> <li>Prettier for JavaScript code formatting.</li> <li>ESLint for JavaScript code quality rules.</li> <li>Stylelint for Sass/CSS style and code quality rules.</li> </ul> <p>For front-end HTML &amp; CSS conventions, bedrock uses Mozilla's Protocol design system for building components. You can read the Protocol documentation site for more information.</p> <p>Mozilla also has some more general coding styleguides available, although some of these are now rather outdated:</p> <ul> <li>Mozilla Python Style Guide</li> <li>Mozilla HTML Style Guide</li> <li>Mozilla JS Style Guide</li> <li>Mozilla CSS Style Guide</li> </ul>"},{"location":"coding/#test-coverage","title":"Test coverage","text":"<p>When the Python tests are run, a coverage report is generated, showing which lines of the codebase have tests that execute them, and which do not. You can view this report in your browser at <code>file:///path/to/your/checkout/of/bedrock/python_coverage/index.html</code>.</p> <p>When adding code, please aim to provide solid test coverage, using the coverage report as a guide. This doesn't necessarily mean every single line needs a test, and 100% coverage doesn't mean 0% defects.</p>"},{"location":"coding/#configuring-your-code-editor","title":"Configuring your Code Editor","text":"<p>Bedrock includes an <code>.editorconfig</code> file in the root directory that you can use with your code editor to help maintain consistent coding styles. Please see editorconfig.org. for a list of supported editors and available plugins.</p>"},{"location":"coding/#working-with-protocol-design-system","title":"Working with Protocol Design System","text":"<p>Bedrock uses the Protocol Design System to quickly produce consistent, stable components. There are different methods -- depending on the component -- to import a Protocol component into our codebase.</p> <p>One method involves two steps:</p> <ol> <li>Adding the correct markup or importing the appropriate macro to the page's HTML file.</li> <li>Importing the necessary Protocol styles to a page's SCSS file.</li> </ol> <p>The other method is to import CSS bundles onto the HTML file. However, this only works for certain components, which are listed below in the respective section.</p>"},{"location":"coding/#styles-and-components","title":"Styles and Components","text":"<p>The base templates in Bedrock have global styles from Protocol that apply to every page. When we need to extend these styles on a page-specific basis, we set up Protocol in a page-specific SCSS file.</p> <p>For example, on a Firefox product page, we might want to use Firefox logos or wordmarks that do not exist on every page.</p> <p>To do this, we add Protocol <code>mzp-</code> classes to the HTML:</p> <pre><code>// bedrock/bedrock/firefox/templates/firefox/{specific-page}.html\n\n&lt;div class=\"mzp-c-wordmark mzp-t-wordmark-md mzp-t-product-firefox\"&gt;\n    Firefox Browser\n&lt;/div&gt;\n</code></pre> <p>Then we need to include those Protocol styles in the page's SCSS file:</p> <pre><code>/* bedrock/media/css/firefox/{specific-page}.scss */\n\n/* if we need to use protocol images, we need to set the $image-path variable */\n$image-path: '/media/protocol/img';\n/* mozilla is the default theme, so if we want a different one, we need to set the $brand-theme variable */\n$brand-theme: 'firefox';\n\n/* the lib import is always essential: it provides access to tokens, functions, mixins, and theming */\n@import '~@mozilla-protocol/core/protocol/css/includes/lib';\n/* then you add whatever specific protocol styling you need */\n@import '~@mozilla-protocol/core/protocol/css/components/logos/wordmark';\n@import '~@mozilla-protocol/core/protocol/css/components/logos/wordmark-product-firefox';\n</code></pre> <p>Note</p> <p>If you create a new SCSS file for a page, you will have to include it in that page's CSS bundle by updating static-bundles.json file.</p>"},{"location":"coding/#macros","title":"Macros","text":"<p>The team has created several Jinja macros out of Protocol components to simplify the usage of components housing larger blocks of code (i.e. Billboard). The code housing the custom macros can be found in our protocol macros file. These Jinja macros include parameters that are simple to define and customize based on how the component should look like on a given page.</p> <p>To use these macros in files, we simply import a macro to the page's HTML code and call it with the desired arguments, instead of manually adding Protocol markup. We can import multiple macros in a comma-separated fashion, ending the import with <code>with context</code>:</p> <pre><code>// bedrock/bedrock/firefox/templates/firefox/{specific-page}.html\n\n{% from \"macros-protocol.html\" import billboard with context %}\n\n{{ billboard(\n    title='This is Firefox.',\n    ga_title='This is Firefox',\n    desc='Firefox is an awesome web browser.',\n    link_cta='Click here to install',\n    link_url=url('firefox.new')\n  )}}\n</code></pre> <p>Because not all component styles are global, we still have to import the page-specific Protocol styles in SCSS:</p> <pre><code>/* bedrock/media/css/firefox/{specific-page}.scss */\n\n$brand-theme: 'firefox';\n\n@import '~@mozilla-protocol/core/protocol/css/includes/lib';\n@import '~@mozilla-protocol/core/protocol/css/components/billboard';\n</code></pre>"},{"location":"coding/#import-css-bundles","title":"Import CSS Bundles","text":"<p>We created pre-built CSS bundles to be used for some components due to their frequency of use. This method only requires an import into the HTML template. Since it's a separate CSS bundle, we don't need to import that component in the respective page CSS. The CSS bundle import only works for the following components:</p> <ul> <li>Split</li> <li>Card</li> <li>Picto</li> <li>Callout</li> <li>Article</li> <li>Newsletter form</li> <li>Emphasis box</li> </ul> <p>Include a CSS bundle in the template's <code>page_css</code> block along with any other page-specific bundles, like so:</p> <pre><code>{% block page_css %}\n    {{ css_bundle('protocol-split') }}\n    {{ css_bundle('protocol-card') }}\n    {{ css_bundle('page-specific-bundle') }}\n{% endblock %}\n</code></pre>"},{"location":"content-cards/","title":"External Content Cards (deprecated)","text":""},{"location":"content-cards/#content-cards","title":"Using External Content Cards Data","text":"<p>The www-admin repo contains data files and images that are synced to bedrock and available for use on any page. The docs for updating said data is available via that repo, but this page will explain how to use the cards data once it's in the bedrock database.</p>"},{"location":"content-cards/#add-to-a-view","title":"Add to a View","text":"<p>The easiest way to make the data available to a page is to add the <code>page_content_cards</code> variable to the template context:</p> <pre><code>from bedrock.contentcards.models import get_page_content_cards\n\n\ndef view_with_cards(request):\n    locale = l10n_utils.get_locale(request)\n    ctx = {\"page_content_cards\": get_page_content_cards(\"home\", locale)}\n    return l10n_utils.render(request, \"sweet-words.html\", ctx)\n</code></pre> <p>The <code>get_page_content_cards</code> returns a dict of card data dicts for the given page (<code>home</code> in this case) and locale. The dict keys are the names of the cards (e.g. <code>card_1</code>). If the <code>page_content_cards</code> context variable is available in the template, then the <code>content_card()</code> macro will discover it automatically.</p> <p>Note</p> <p>The <code>get_page_content_cards</code> function is not all that clever as far as l10n is concerned. If you have translated the cards in the www-admin repo that is great, but you should have cards for every locale for which the page is active or the function will return an empty dict. This is especially tricky if you have multiple English locales enabled (en-US, en-CA, en-GB, etc.) and want the same cards to be used for all of them. You'd need to do something like <code>if locale.startswith('en-'):</code> then use <code>en-US</code> in the function call.</p> <p>Alternately you could just wrap the section of the template using cards to be optional in an <code>{% if page_content_cards %}</code> statement, and that way it will not show the section at all if the dict is empty if there are no cards for that page and locale combination.</p>"},{"location":"content-cards/#add-to-the-template","title":"Add to the Template","text":"<p>Once you have the data in the template context, using a card is simple:</p> <pre><code>{% from \"macros-protocol.html\" import content_card with context %}\n\n{{ content_card('card_1') }}\n</code></pre> <p>This will insert the data from the <code>card_1.en-US.md</code> file from the www-admin repo into the template via the <code>card()</code> macro normally used for protocol content cards.</p> <p>If you don't have the <code>page_content_cards</code> variable in the template context and you don't want to create or modify a view, you can fetch the cards via a helper function in the template itself, but you have to pass the result to the macro:</p> <pre><code>{% from \"macros-protocol.html\" import content_card with context %}\n{% set content_cards = get_page_content_cards('home', LANG) %}\n\n{{ content_card('card_1', content_cards) }}\n</code></pre>"},{"location":"contentful/","title":"Contentful (deprecated)","text":""},{"location":"contentful/#contentful","title":"Contentful <code>CMS (Content Management System)</code> Integration (Deprecated)","text":"<p>Important</p> <p>We are no longer syncing content from Contentful, but we still hold that content frozen in our database and use it to render pages.</p> <p>Pages previously managed with Contentful will be the first pages to be (re)implemented using our upcoming part-of-Bedrock CMS system. At that point, we will remove all Contentful-related code from the codebase.</p> <p>In the meantime, if content changes are needed to pages formerly managed via Contentful, we can do this via data migration -- just ask the backend team.</p> <p>Please do not add new pages to Bedrock using Contentful.</p>"},{"location":"contentful/#overview","title":"Overview","text":"<p>Contentful is a headless <code>CMS (Content Management System)</code>. It stores content for our website in a structured format. We request the content from Contentful using an API. Then the content gets made into Protocol components for display on the site.</p> <p>We define the structure Contentful uses to store the data in content models. The content models are used to create a form for editors to fill out when they want to enter new content. Each chunk of content is called an entry.</p> <p>For example: we have a content model for our \"card\" component. That model creates a form with fields like heading, link, blurb, and image. Each card that is created from the model is its own entry.</p> <p>We have created a few different types of content models. Most are components that correspond to components in our design system. The smallest create little bits of code like buttons. The larger ones group together several entries for the smaller components into a bigger component or an entire page.</p> <p>For example: The Page: General model allows editors to include a hero entry, body entry, and callout entry. The callout layout entry, in turn, includes a <code>CTA (Call To Action)</code> entry.</p> <p>One advantage of storing the content in small chunks like this is that is can be reused in many different pages. A callout which focuses on the privacy related reasons to download Firefox could end up on the Private Browsing, Ad Tracker Blocking, and Fingerprinter Blocking pages. If our privacy focused tagline changes from \"Keep it secret with Firefox\" to \"Keep it private with Firefox\" it only needs to be updated in one entry.</p> <p>So, when looking at a page on the website that comes from Contentful you are typically looking at several different entries combined together.</p> <p>On the bedrock side, the data for all entries is periodically requested from the API and stored in a database.</p> <p>When a Contentful page is requested the code in <code>api.py</code> transforms the information from the database into a group of Python dictionaries (these are like key/value pairs or an object in JS).</p> <p>This data is then passed to the page template (either Mozilla or for Firefox themed as appropriate). The page template includes some files which take the data and feed it into macros to create Protocol components. These are the same macros we use on non-Contentful pages. There are also includes which will import the appropriate JS and CSS files to support the components.</p> <p>Once rendered the pages get cached on the <code>CDN (Content Delivery Network)</code> as usual.</p>"},{"location":"contentful/#contentful-apps","title":"Contentful Apps","text":"<p>Important</p> <p>We are no longer syncing content from Contentful --\u00a0see the note at the top of this page.</p> <p>Please do not add new pages to Bedrock using Contentful.</p> <p>Installed on Environment level. Make sure you are in the environment you want to edit before accessing an app. Use Apps link in top navigation of Contentful Web App to find an environment's installed apps.</p>"},{"location":"contentful/#compose","title":"Compose","text":"<p>Compose provides a nicer editing experience. It creates a streamlined view of pages by combining multiple entries into a single edit screen and allowing field groups for better organization.</p> <p>Any changes made to Compose page entries in a specific environment are limited to that environment. If you are in a sandbox environment, you should see an <code>/environments/sandbox-name</code> path at the end of your Compose URL.</p>"},{"location":"contentful/#known-limitations","title":"Known Limitations","text":"<ul> <li>Comments are not available on Compose entries</li> <li>It is not possible to edit embedded entries in Rich Text fields in Compose app. Selecting the \"edit\" option in the dropdown opens the entry in the Contentful web app.</li> </ul>"},{"location":"contentful/#merge","title":"Merge","text":"<p>Merge provides a UI for comparing the state of Content Models across two environments. You can select what changes you would like to migrate to a new environment.</p>"},{"location":"contentful/#known-limitations_1","title":"Known Limitations","text":"<ul> <li>Does not migrate Help Text (under Appearance Tab)</li> <li>Does not migrate any apps used with those Content Models</li> <li>Does not migrate Content Entries or Assets</li> <li>It can identify when Content Models should be available in Compose, but it cannot migrate the field groups</li> </ul>"},{"location":"contentful/#others","title":"Others","text":"<ul> <li>Launch allows creation of \"releases\", which can help coordinate publishing of multiple entries</li> <li>Workflows standardizes process for a specific Content Model. You can specify steps and permissions to regulate how content moves from draft to published.</li> </ul>"},{"location":"contentful/#content-models","title":"Content Models","text":""},{"location":"contentful/#emoji-legend-for-content-models","title":"Emoji legend for content models","text":"<ul> <li>\ud83d\udcc4 this component is a page, it will include meta data for the page, a folder, and slug</li> <li>\ud83c\udf81 this is a layout wrapper for another component</li> <li>\u270f\ufe0f this component includes editable content, not just layout config</li> <li>\u265f this component is suitable for inclusion as an inline entry in a rich text field</li> <li>\u27a1\ufe0f this component can be embedded without a layout wrapper</li> </ul>"},{"location":"contentful/#naming-conventions-for-content-models","title":"Naming conventions for content models","text":"<p>Note</p> <p>For some fields it is important to be consistent because of how they are processed in bedrock. For all it is important to make the editor's jobs easier.</p> Name <p>This is for the internal name of the entry. It should be set as the Entry title, required, and unique.</p> Preview (and Preview Title, Preview Blurb, Preview Image) <p>These will be used in search results and social media sites. There's also the potential to use them for aggregate pages on our own sites. Copy configuration and validation from an existing page.</p> Heading (and Heading Level) <p>Text on a page which provides context for information that follows it. Usually made into a H1-H4 in bedrock. Not: header, title, or name.</p> Image (and Image Size, Image Width) <p>Not: picture, photo, logo, or icon (unless we are specifically talking about a logo or icon.)</p> Content <p>Multi-reference</p> Product Icon <p>Copy configuration and validation from an existing page.</p> Theme <p>Copy configuration and validation from an existing page.</p> Body (Body Width, Body Vertical Alignment, Body Horizontal Alignment) <p>Rich text field in a Component. Do not use this for multi reference fields, even if the only content on the page is other content entries. Do not use MarkDown for body fields, we can't restrict the markup. Copy configuration and validation from an existing page.</p> Rich Text Content <p>Rich text field in a Compose Page</p> <code>CTA (Call To Action)</code> <p>The button/link/dropdown that we want a user to interact with following some content. Most often appearing in Split and Callout components.</p>"},{"location":"contentful/#page","title":"\ud83d\udcc4 Page","text":"<p>Pages in bedrock are created from page entries in Contentful's Compose App.</p> Homepage <p>The homepage needs to be connected to bedrock using a Connect component (see Legacy) and page meta data like title, blurb, image, etc come from bedrock.</p> General <p>Includes hero, text, and callout. The simplified list and order of components is intended to make it easier for editors to put a page together.</p> Versatile <p>No pre-defined template. These pages can be constructed from any combination of layout and component entries.</p> Resource Center <p>Includes product, category, tags, and a rich text editor. These pages follow a recognizable format that will help orient users looking for more general product information (i.e. VPN).</p> <p>The versatile and general templates do not need bedrock configuration to be displayed. Instead, they should appear automatically at the folder and slug specified in the entry. These templates do include fields for meta data.</p>"},{"location":"contentful/#layout","title":"\ud83c\udf81 Layout","text":"<p>These entries bring a group of components together. For example: 3 picto blocks in a picto block layout. They also include layout and theme options which are applied to all of the components they bring together. For example: centering the icons in all 3 picto blocks.</p> <p>These correspond roughly to Protocol templates.</p> <p>The one exception to the above is the Layout: Large Card, which exists to attach a large display image to a regular card entry. The large card must still be included in the Layout: 5 Cards.</p>"},{"location":"contentful/#component","title":"\u270f\ufe0f Component","text":"<p>We're using this term pretty loosely. It corresponds roughly to a Protocol atom, molecule, or organism.</p> <p>These entries include the actual content, the bits that people write and the images that go with it.</p> <p>If they do not require a layout wrapper there may also be some layout and theme options. For example, the text components include options for width and alignment.</p>"},{"location":"contentful/#embed","title":"\u265f Embed","text":"<p>These pre-configured content pieces can go in rich text editors when allowed (picto, split, multi column text...).</p> <p>Embeds are things like logos, where we want tightly coupled style and content that will be consistent across entries. If a logo design changes, we only need to update it in one place, and all uses of that embed will be updated.</p>"},{"location":"contentful/#adding-a-new-page","title":"Adding a new \ud83d\udcc4 Page","text":"<ul> <li> <p>Create the content model</p> <ul> <li> <p>Ensure the content model name starts with page (i.e. pageProductJournalismStory)</p> </li> <li> <p>Add an SEO reference field which requires the SEO Metadata content type</p> </li> <li> <p>In Compose, go to Page Types and click \"Manage Page Types\" to make your new content model available to the Compose editor.</p> <ul> <li>If you have referenced components, you can choose whether they will be displayed as expanded by default.</li> <li>Select \"SEO\" field for \"Page Settings\" field</li> </ul> </li> <li> <p>If the page is meant to be localised, ensure all fields that need localisation have the \"Enable localization of this field\" checkbox checked in content model field settings</p> </li> </ul> </li> <li> <p>Update <code>bedrock/contentful/constants</code></p> <ul> <li>Add content type constant</li> <li>Add constant to default array</li> <li>If page is for a single locale only, add to SINGLE_LOCALE_CONTENT_TYPES</li> <li>If page is localised, add to LOCALISATION_COMPLETENESS_CHECK_CONFIG with an array of localised fields that need to be checked before the page's translation can be considered complete</li> </ul> </li> <li> <p>Update <code>bedrock/contentful/api.py</code></p> <ul> <li>If you're adding new embeddable content types, expand list of renderer helpers configured for the RichTextRenderer in the <code>ContentfulAPIWrapper</code></li> <li>Update <code>ContentfulAPIWrapper.get_content()</code> to have a clause to handle the new page type</li> </ul> </li> <li> <p>Create a custom view to pass the Contentful data to a template</p> </li> </ul>"},{"location":"contentful/#adding-a-new-component","title":"Adding a new \u270f\ufe0f Component","text":"<p>Example: Picto</p> <ol> <li>Create the content model in Contentful.<ul> <li>Follow the naming conventions.</li> <li>You may need two models if you are configuring layout separately.</li> </ul> </li> <li>Add the new content model to the list of allowed references in other content models (At the moment this is just the \"content\" reference field on pages).</li> <li>In bedrock create CSS and JS entries in static-bundles for the new component.</li> <li>In api.py write a def for the component.</li> <li>In api.py add the component name, def, and bundles to the CONTENT_TYPE_MAP.</li> <li>Find or add the macro to macros-protocol.</li> <li>Import the macro into all.html and add a call to it in the entries loop.</li> </ol> <p>Note</p> <p>Tips:</p> <ul> <li>can't define defaults in Contentful, so set those in your Python def.</li> <li>for any optional fields make sure you check the field exists before referencing the content.</li> </ul>"},{"location":"contentful/#adding-a-new-embed","title":"Adding a new \u265f Embed","text":"<p>Example: Wordmark.</p> <ol> <li>Create the content model in Contentful.<ul> <li>Follow the naming conventions.</li> </ul> </li> <li>Add the new content model to rich text fields (like split and text).</li> <li>In bedrock include the CSS in the Sass file for any component which may use it (yeah, this is not ideal, hopefully we will have better control in the future).</li> <li>Add a def to api.py to render the piece (like <code>_make_wordmark</code>).</li> </ol> <p>Note</p> <p>Tips:</p> <ul> <li>can't define defaults in Contentful, so set those in your Python def.</li> <li>for any optional fields make sure you check the field exists before referencing the content.</li> </ul>"},{"location":"contentful/#adding-a-rich-text-field-in-a-component","title":"Adding a rich text field in a component","text":"<p>Disable everything then enable: B, I, UL, OL, Link to URL, and Inline entry. You will want to enable some some Headings as well, H1 should be enabled very rarely. Enable H2-H4 using your best judgement.</p>"},{"location":"contentful/#adding-support-for-a-new-product-icon-size-folder","title":"Adding support for a new product icon, size, folder","text":"<p>Many content models have drop downs with identical content. For example: the Hero, Callout, and Wordmark models all include a \"product icon\". Other common fields are width and folder.</p> <p>There are two ways to keep these lists up to date to reflect Protocol updates:</p> <ol> <li>By opening and editing the content models individually in Contentful</li> <li>Scripting updates using the API</li> </ol> <p>At the moment it's not too time consuming to do by hand, just make sure you are copy and pasting to avoid introducing spelling errors.</p> <p>We have not tried scripting updates with the API yet. One thing to keep in mind if attempting this is that not all widths are available on all components. For example: the \"Text: Four columns\" component cannot be displayed in small content widths.</p>"},{"location":"contentful/#rich-text-rendering","title":"Rich Text Rendering","text":"<p>Contentful provides a helper library to transform the rich text fields in the API into HTML content.</p> <p>In places were we disagree with the rendering or want to enhance the rendering we can provide our own renderers on the bedrock side. They can be as simple as changing <code>&lt;b&gt;</code> tags to <code>&lt;strong&gt;</code> tags or as complex as inserting a component.</p> <p>A list of our custom renderers is passed to the <code>RichTextRenderer</code> helper at the start of the <code>ContentfulPage</code> class in api.py. The renderers themselves are also defined in api.py</p> <p>Note</p> <p>Built-in nodes cannot be extended or customized: Custom node types and marks are not allowed. Embed entry types are required to extend rich text functionality. (i.e. if you need more than one style of blockquote)</p>"},{"location":"contentful/#l10n","title":"L10N","text":"<p>Important</p> <p>We are no longer syncing content from Contentful --\u00a0see the note at the top of this page.</p> <p>Please do not add new pages to Bedrock using Contentful.</p>"},{"location":"contentful/#smartling-our-selected-approach","title":"Smartling - our selected approach","text":"<p>When setting up a content model in Contentful, fields can be designated as available for translation.</p> <p>Individual users can be associated with different languages, so when they edit entries they see duplicate fields for each language they can translate into. In addition - and in the most common case - these fields are automatically sent to Smartling to be translated there.</p> <p>Once text for translation lands in Smartling, it is batched up into jobs for human translation. When the work is complete, Smartling automatically updates the relevant Contentful entries with the translations, in the appropriate fields.</p> <p>Note that those translations are only visible in Contentful if you select to view that locale's fields, but if they are present in Contentful's datastore (and that locale is enabled in the API response) they will be synced down by Bedrock.</p> <p>On the Bedrock side, the translated content is pulled down the same way as the default locale's content is, and is stored in a locale-specific ContentfulEntry in the database.</p> <p>In terms of 'activation', or \"Do we have all the parts to show this Contentful content\"?, Contentful content is not evaluated in the same way as Fluent strings (where we will show a page in a given locale if 80% of its Fluent strings have been translated, falling back to en-US where not).</p> <p>Instead, we check that all of the required fields present in the translated Entry have non-null data, and if so, then the entire page is viable to show in the given locale. (ie, we look at fields, not strings. It's a coarser level of granularity compared to Fluent, because the data is organised differently -most of Contentful-sourced content will be rich text, not individual strings).</p> <p>The check about whether or not a Contentful entry is 'active' or 'localisation complete' happens during the main sync from Contentful. Note that there is no fallback locale for Contentful content other than a redirect to the en-US version of the page - either the page is definitely available in a locale, or it's not at all available in that locale.</p> <p>Note</p> <ul> <li>The batching of jobs in Smartling is still manual, even though the data flow is automated. We need to keep an eye on how onerous this is, plus what the cost exposure could be like if we fully automate it.</li> <li>The Smartling integration is currently only set to use Mozilla.org's 10 most popular locales, in addition to en-US.</li> <li>No localisation of Contentful content happens via Pontoon.</li> <li>The Smartling setup is most effectively leveraged with Compose-based pages rather than Connect-based components, and the latter may require some code tweaks.</li> <li>Our Compose: SEO field in Contentful is configured for translation (and in use on the VPN Resource Center). All Compose pages require this field. If a Compose page type is not meant to be localised, we need to stop these SEO-related fields from going on to Smartling.</li> </ul>"},{"location":"contentful/#fluent","title":"Fluent","text":"<p>NB: Not selected for use, but notes retained for reference</p> <p>Instead of using the language translation fields in Contentful to store translations we could designate one of the locales to contain a fluent string ID. Bedrock could then use the string IDs and the English content to create Fluent files for submission into our current translation system.</p> <p>Creation of the string IDs could be automated using Contentful's write API.</p> <p>To give us the ability to use fallback strings the Contentful field could accept a comma separated list of values.</p> <p>This approach requires significant integration code on the bedrock side but comes with the benefit of using our current translation system, including community contributions.</p>"},{"location":"contentful/#no-english-equivalent","title":"No English Equivalent","text":"<p>NB: Not selected for use, but notes retained for reference</p> <p>Components could be created in the language they are intended to display in. The localized content would be written in the English content fields.</p> <p>The down sides of this are that we do not know what language the components are written in and could accidentally display the wrong language on any page. It also means that localized content cannot be created automatically by English editors and translations would have to be manually associated with URLs.</p> <p>This is the approach that will likely be used for the German and French homepages since that content is not going to be used on English pages and creating a separate homepage with different components is valuable to the German and French teams.</p>"},{"location":"contentful/#assets","title":"Assets","text":"<p>Important</p> <p>We are no longer syncing content from Contentful --\u00a0see the note at the top of this page.</p> <p>Please do not add new pages to Bedrock using Contentful.</p> <p>Images that are uploaded in Contentful will be served to site visitors from the Contentful <code>CDN (Content Delivery Network)</code>. The cost of using the CDN are not by request so we don't have to worry about how many times an image will be requested.</p> <p>Using the Contentful <code>CDN (Content Delivery Network)</code> lets us use their Images API to format our images.</p> <p>In theory, a large high quality image is uploaded in Contentful and then bedrock inserts links to the <code>CDN (Content Delivery Network)</code> for images which are cropped to fit their component and resized to fit their place on the page.</p> <p>Because we cannot rely on the dimensions of the image uploaded to Contentful as a guide for displaying the image - bedrock needs to be opinionated about what size images it requests based on the component and its configuration. For example, hero images are fixed at 800px wide. In the future this could be a user configurable option.</p>"},{"location":"contentful/#preview","title":"Preview","text":"<p>Important</p> <p>We are no longer syncing content from Contentful --\u00a0see the note at the top of this page.</p> <p>Please do not add new pages to Bedrock using Contentful.</p> <p>Content previews are configured under Settings &gt; Content preview on a per-content model basis. At the moment previews are only configured for pages, and display on demo5.</p> <p>Once the code is merged into bedrock they should be updated to use the dev server.</p> <p>Specific URLs will only update every 5 minutes as the data is pulled from the API but pages can be previewed up to the second at the <code>contentful-preview</code> URL. This preview will include \"changed\" and \"draft\" changes (even if there is an error in the data) not just published changes.</p> <p>For previewing on localhost, see Development Practices, below.</p>"},{"location":"contentful/#rolespermissions","title":"Roles/Permissions","text":"<p>In general we are trusting people to check their work before publishing and very few guard rails have been installed. We have a few roles with different permissions.</p> Admin <p>Organization</p> <ul> <li>Define roles and permission</li> <li>Manage users</li> <li>Change master and sandbox environment aliases</li> <li>Create new environments</li> </ul> <p>Master environment</p> <ul> <li>Edit content model</li> <li>Create, Edit, Publish, Archive, Delete content</li> <li>Install/Uninstall apps</li> </ul> Developer <p>Organization</p> <ul> <li>Create new environments</li> </ul> <p>Master environment</p> <ul> <li>Create, Edit, Publish, Archive content</li> </ul> <p>Sandbox environments (any non-master environment)</p> <ul> <li>Edit content model</li> <li>Create, Edit, Publish, Archive, Delete content</li> <li>Install/Uninstall apps</li> </ul> Editor (WIP) <p>Master environment (through Compose)</p> <ul> <li>Create, Edit, Publish, Archive content</li> </ul>"},{"location":"contentful/#development-practices","title":"Development practices","text":"<p>Important</p> <p>We are no longer syncing content from Contentful --\u00a0see the note at the top of this page.</p> <p>Please do not add new pages to Bedrock using Contentful.</p> <p>This section outlines tasks generally required if developing features against Contentful.</p>"},{"location":"contentful/#get-bedrock-set-up-locally-to-work-with-contentful","title":"Get bedrock set up locally to work with Contentful","text":"<p>In your <code>.env</code> file for Bedrock, make sure you have the followign environment variables set up.</p> <ul> <li><code>CONTENTFUL_SPACE_ID</code> - this is the ID of our Contentful integration</li> <li><code>CONTENTFUL_SPACE_KEY</code> - this is the API key that allows you access to our space. Note that two types of key are available: a Preview key allows you to load in draft content; the Delivery key only loads published contnet. For local dev, you want a Preview key.</li> <li><code>SWITCH_CONTENTFUL_HOMEPAGE_DE</code> should be set to <code>True</code> if you are working on the German Contentful-powered homepage</li> <li><code>CONTENTFUL_ENVIRONMENT</code> Contentful has 'branches' which it calls environments. <code>master</code> is what we use in production, and <code>sandbox</code> is generally what we use in development. It's also possible to reference a specific environment - e.g. <code>CONTENTFUL_ENVIRONMENT=sandbox-2021-11-02</code></li> </ul> <p>To get values for these vars, please check with someone on the backend team.</p> <p>If you are working on the Contentful Sync backed by the message-queue (and if you don't know what this is, you don't need it for local dev), you will also need to set the following env vars:</p> <ul> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_URL</code></li> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_REGION</code></li> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_ACCESS_KEY_ID</code></li> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_SECRET_ACCESS_KEY</code></li> </ul>"},{"location":"contentful/#how-to-preview-your-changes-on-localhost","title":"How to preview your changes on localhost","text":"<p>When viewing a page in Contentful, it's possible to trigger a preview of the draft page. This is typically rendered on www-dev.allizom.org. However, that's only useful for code that's already in <code>main</code>. If you want to preview Contentful content on your local machine - e.g. you're working on a feature branch that isn't ready for merging - do the following:</p>"},{"location":"contentful/#existing-master-content-types","title":"Existing (master) Content Types","text":"<p>In the right-hand sidebar of the editor page in Contentful:</p> <ul> <li>Find the Preview section</li> <li>Select <code>Change</code> and pick <code>Localhost Preview</code></li> <li>Click <code>Open preview</code></li> </ul>"},{"location":"contentful/#new-non-master-content-types","title":"New (non-master) Content Types","text":"<p>In bedrock:</p> <ul> <li>Update <code>class ContentfulPreviewView(L10nTemplateView)</code> in Mozorg Views with a render case for your new content type</li> </ul> <p>In the right-hand sidebar of the editor page in Contentful:</p> <ul> <li>Click Info tab</li> <li>Find <code>Entry ID</code> section and copy the value</li> </ul> <p>Manually create preview URL in browser:</p> <ul> <li><code>http://localhost:8000/en-US/contentful-preview/{entry_id}/</code></li> </ul> <p>Note that previewing a page will require it to be pulled from Contentful's API, so you will need <code>CONTENTFUL_SPACE_ID</code> and <code>CONTENTFUL_SPACE_KEY</code> set in your <code>.env</code>. It may take a few seconds to get the data.</p> <p>Also note that when you select <code>Localhost preview</code>, the choice sticks, so you should set it back to <code>Preview on web</code> when you're done.</p>"},{"location":"contentful/#how-to-updaterefresh-the-sandbox-environment","title":"How to update/refresh the sandbox environment","text":"<p>It helps to think of Contentful 'environments' as simply branches of a git-like repo full of content. You can take a particular environment and branch off it to make a new environment for <code>WIP (Work in Progress)</code> or experimental content, using the original one as your starting point. On top of this, Contentful has the concept of aliases for environments and we use two aliases in our setup:</p> <ul> <li><code>master</code> is used for production and is an alias currently pointing to the <code>V1</code> environment. It is pretty stable and access to it is limited.</li> <li><code>sandbox</code> is used for development and more team members have access to edit content. Again, it's an alias and is pointed at an environment (think, branch) with a name in the format <code>sandbox-YYYY-MM-DD</code>.</li> </ul> <p>While updating <code>master</code> is something that we generally don't do (at the moment only a product owner and/or admin would do this), updating the sandbox happens more often, typically to populate it with data more recently added to master. To do this:</p> <ul> <li>Go to <code>Settings &gt; Environments</code></li> <li>Ensure we have at least one spare environment slot. If we don't delete the oldest <code>sandbox-XXXX-XX-XX</code> environment.</li> <li>Click the blue Add Environment button, to the right. Name it using the <code>sandbox-YYYY-MM-DD</code> pattern and base it on whatever environment is aliased to <code>master</code> - this will basically create a new 'branch' with the content currently in master.</li> <li>In the Environment Aliases section of the main page, find <code>sandbox</code> and click Change alias target, then select the <code>sandbox-XXXX-XX-XX</code> environment you just made.</li> </ul>"},{"location":"contentful/#which-environment-is-connected-to-where","title":"Which environment is connected to where?","text":"<p><code>master</code> is the environment used in Bedrock production, stage, dev and test <code>sandbox</code> may, in the future, be made the default environment for dev. It's also the one we should use for local development.</p> <p>If you develop a new feature that adds to Contentful (e.g. page or component) and you author it in the sandbox, you will need to re-create it in master before the corresponding bedrock changes hit production.</p>"},{"location":"contentful/#troubleshooting","title":"Troubleshooting","text":"<p>If you run into trouble on an issue, be sure to check in these places first and include the relevant information in requests for help (i.e. environment).</p>"},{"location":"contentful/#contentful-content-model-entries","title":"Contentful Content Model &amp; Entries","text":"<ul> <li>What environment are you using?</li> <li>Do you have the necessary permissions to make changes?</li> <li>Do you see all the entry fields you need? Do those fields have the correct value options?</li> </ul>"},{"location":"contentful/#bedrock-api-apipy","title":"Bedrock API (api.py)","text":"<ul> <li>What environment are you using?</li> <li>Can you find a Python function definition for the content type you need?</li> <li>Does it structure data as expected?</li> </ul> <pre><code># example content type def\n\n\ndef get_section_data(self, entry_obj):\n    fields = entry_obj.fields()\n    # run `print(fields)` here to verify field values from Contentful\n\n    data = {\n        \"component\": \"sectionHeading\",\n        \"heading\": fields.get(\"heading\"),\n    }\n\n    # run `print(data)` here to verify data values from Bedrock API\n    return data\n</code></pre>"},{"location":"contentful/#bedrock-render-allhtml","title":"Bedrock Render (all.html)","text":"<ul> <li>Can you find a render condition for the component you need?</li> </ul> <pre><code>/* example component condition */\n\n{% elif entry.component == 'sectionHeading' %}\n</code></pre> <p>-</p> <pre><code>If the component calls a macro:\n\n:   -   Does it have all the necessary parameters?\n    -   Is it passing the expected values as arguments?\n</code></pre> <p>-</p> <pre><code>If the component is custom HTML:\n\n:   -   Is the HTML structure correct?\n    -   Are Protocol-specific class names spelled correctly?\n</code></pre> <ul> <li> <p>Is the component CSS available?</p> </li> <li> <p>Is the component JS available?</p> </li> </ul> <p>Note</p> <p>Component CSS and JS are defined in a <code>CONTENT_TYPE_MAP</code> from the Bedrock API (<code>api.py</code>).</p>"},{"location":"contentful/#bedrock-database","title":"Bedrock Database","text":"<p>Once content is synced into your local database, it can be found in the contentful_contentfulentry table. All the dependencies to explore the data are installed by default for local development.</p> <p>Using sqlite (with an example query to get some info about en-US pages):</p> <pre><code>./manage.py dbshell\n</code></pre> <pre><code>select id, slug, data from contentful_contentfulentry where locale='en-US';\n</code></pre> <p>Close the sqlite shell with <code>.exit</code></p> <p>Using Django shell (with an example query to get data from first entry of \"pageProductJournalismStory\" type):</p> <pre><code>./manage.py shell\n</code></pre> <pre><code>from bedrock.contentful.models import ContentfulEntry\n\nproduct_stories = ContentfulEntry.objects.filter(\n    content_type=\"pageProductJournalismStory\",\n    localisation_complete=True,\n    locale=\"en-US\",\n)\n\nproduct_stories[0].data  # to see the data stored for the first story in the results\n</code></pre> <p>Close the Djanjo shell with <code>exit()</code> or <code>CTRL+D</code></p>"},{"location":"contentful/#useful-contentful-docs","title":"Useful Contentful Docs","text":"<p>Important</p> <p>We are no longer syncing content from Contentful --\u00a0see the note at the top of this page.</p> <p>Please do not add new pages to Bedrock using Contentful.</p> <p>https://www.contentful.com/developers/docs/references/images-api/#/reference/resizing-&amp;-cropping/specify-focus-area</p> <p>https://www.contentful.com/developers/docs/references/content-delivery-api/</p> <p>https://contentful.github.io/contentful.py/#filtering-options</p> <p>https://github.com/contentful/rich-text-renderer.py https://github.com/contentful/rich-text-renderer.py/blob/a1274a11e65f3f728c278de5d2bac89213b7470e/rich_text_renderer/block_renderers.py</p>"},{"location":"contentful/#assumptions-we-still-need-to-deal-with","title":"Assumptions we still need to deal with","text":"<ul> <li>image sizes</li> </ul>"},{"location":"contentful/#legacy","title":"Legacy","text":"<p>Since we decided to move forward the the Compose App, we no longer need the Connect content model. The EN-US homepage is currently still using Connect. Documentation is here for reference.</p> <ul> <li>\ud83d\udd17 this component is referenced by ID in bedrock (at the moment that is just the homepage but could be used to connect single components for display on non-contentful pages. For example: the latest feature box on /new)</li> </ul>"},{"location":"contentful/#connect","title":"\ud83d\udd17 Connect","text":"<p>These are the highest level component. They should be just a name and entry reference.</p> <p>The purpose of the connect is to create a stable ID that can be referenced in bedrock to be included in a jinja template. Right now we only do this for the homepage. This is because the homepage has some conditional content above and below the Contentful content.</p> <p>Using a connect component to create the link between jinja template and the Contentful Page entry means an entire new page can be created and proofed in Contentful before the bedrock homepage begins pulling that content in.</p> <p>In other contexts a connect content model could be created to link to entries where the ID may change. For example: the \"Latest Firefox Features: section of /new could be moved to Contentful using a connect component which references 3 picto blocks.</p> <p>Because the ID must be added to a bedrock by a dev, only devs should be able to make new connect entries.</p>"},{"location":"contribute/","title":"How to Contribute","text":""},{"location":"contribute/#contribute","title":"How to contribute","text":"<p>Before diving into code it might be worth reading through the <code>Developing on Bedrock&lt;coding&gt;</code> documentation, which contains useful information and links to our coding guidelines for Python, Django, JavaScript and CSS.</p>"},{"location":"contribute/#git-workflow","title":"Git workflow","text":"<p>When you want to start contributing, you should create a branch from main. This allows you to work on different project at the same time:</p> <pre><code>$ git switch main\n</code></pre> <pre><code>$ git switch -c topic-branch\n</code></pre> <p>To keep your branch up-to-date, assuming the mozilla repository is the remote called mozilla:</p> <pre><code>$ git switch main\n</code></pre> <pre><code>$ git pull --ff-only\n</code></pre> <p>More on Why you should use --ff-only. To make this the default update your Git config as described in the article.</p> <pre><code>$ git switch topic-branch\n</code></pre> <pre><code>$ git rebase main\n</code></pre> <p>If you need more Git expertise, a good resource is the Git book.</p> <p>Once you're done with your changes, you'll need to describe those changes in the commit message.</p>"},{"location":"contribute/#git-commit-messages","title":"Git commit messages","text":"<p>Commit messages are important when you need to understand why something was done.</p> <ul> <li>First, learn how to write good git commit messages.</li> <li>All commit messages must include a bug number. You can put the bug number on any line, not only the first one.</li> <li>If you use the syntax <code>bug xxx</code>, Github will reference the commit into Bugzilla. With <code>fix bug xxx</code>, it will even close the bug once it goes into main.</li> </ul> <p>If you're asked to change your commit message, you can use these commands:</p> <pre><code>$ git commit --amend\n</code></pre> <p>-f is doing a force push because you modified the history</p> <pre><code>$ git push -f my-remote topic-branch\n</code></pre>"},{"location":"contribute/#submitting-your-work","title":"Submitting your work","text":"<p>In general, you should submit your work with a pull request to main. If you are working with other people or you want to put your work on a demo server, then you should be working on a common topic branch.</p> <p>Once your code has been positively reviewed, it will be deployed shortly after. So if you want feedback on your code but it's not ready to be deployed, you should note it in the pull request, or use a Draft PR. Also make use of an appropriate label, such as <code>Do Not Merge</code>.</p>"},{"location":"contribute/#squashing-your-commits","title":"Squashing your commits","text":"<p>Should your pull request contain more than one commit, sometimes we may ask you to squash them into a single commit before merging. You can do this with <code>git rebase</code>.</p> <p>As an example, let's say your pull request contains two commits. To squash them into a single commit, you can follow these instructions:</p> <pre><code>$ git rebase -i HEAD~2\n</code></pre> <p>You will then get an editor with your two commits listed. Change the second commit from <code>pick</code> to <code>fixup</code>, then save and close. You should then be able to verify that you only have one commit now with <code>git log</code>.</p> <p>To push to GitHub again, because you \"altered the history\" of the repo by merging the two commits into one, you'll have to <code>git push -f</code> instead of just <code>git push</code>.</p>"},{"location":"contribute/#deploying-your-code","title":"Deploying your code","text":"<p>These are the websites that Bedrock is usually deployed to as part of development.</p>"},{"location":"contribute/#demo-sites","title":"Demo sites","text":"<ul> <li>Branch <code>mozorg-demo-1</code> -&gt; https://www-demo1.allizom.org/</li> <li>Branch <code>mozorg-demo-2</code> -&gt; https://www-demo2.allizom.org/</li> <li>Branch <code>mozorg-demo-3</code> -&gt; https://www-demo3.allizom.org/</li> <li>Branch <code>mozorg-demo-4</code> -&gt; https://www-demo4.allizom.org/</li> <li>Branch <code>mozorg-demo-5</code> -&gt; https://www-demo5.allizom.org/</li> <li>Branch <code>mozorg-demo-6</code> -&gt; https://www-demo6.allizom.org/</li> <li>Branch <code>mozorg-demo-7</code> -&gt; https://www-demo7.allizom.org/</li> <li>Branch <code>mozorg-demo-8</code> -&gt; https://www-demo8.allizom.org/</li> <li>Branch <code>mozorg-demo-9</code> -&gt; https://www-demo9.allizom.org/</li> </ul> <p>For example:</p> <pre><code>$ git push -f mozilla my-demo-branch:mozorg-demo-2\n</code></pre> <p>Deployment notification and logs</p> <p>At the moment, there is no way to view logs for the deployment unless you have access to Google Cloud Platform.</p> <p>If you do have access, the Cloud Build dashboard shows the latest builds, and Cloud Run will link off to the relevant logs.</p> <p>There are Mozilla Slack notifications in <code>#www-notify</code> that show the status of demo builds. (Work is ticketed to make those notifications richer in data.)</p> <p>Env vars</p> <p>Rather than tweak env vars via a web UI, they are set in config files. We have specific demo-use-only env var files, which are only used by our GCP demo setup. They are:</p> <ul> <li><code>bedrock/gcp/bedrock-demos/cloudrun/mozorg-demo.env.yaml</code></li> </ul> <p>If you need to set/add/remove an env var, you can edit the relevant file on your feature branch, commit it and push it along with the rest of the code, as above. There is a small risk of clashes, but these can be best avoided if you keep up to date with <code>bedrock/main</code> and can be resolved easily.</p> <p>Secret values</p> <p>Remember that the env vars files are public because they are in the Bedrock codebase, so sensitive values should not be added there, even temporarily.</p> <p>If you need to add a secret value, this currently needs to be added at the GCP level by someone with appropriate permissions to edit and apply the Terraform configuration, and to edit the trigger YAML spec to pass through the new secret. Currently Web-SRE and the backend team have appropriate GCP access and adding a secret is relatively quick. (We can make this easier in the future if there's sufficient need, of course.)</p> <p>Note</p> <p>Always-on vs auto-sleep demo servers</p> <p>The demo servers are on GCP Cloud Run, and by default they will be turned off if there is no traffic for 15 minutes. After this time, the demo app will be woken up if it receives a request.</p> <p>Normally, a 'cold start' will not be a problem. However, if the branch you are demoing does things that alter the database (i.e contains migrations), then you may find the restarted demo app crashes because the new migrations have not been applied after a cold start.</p> <p>The best current way to avoid that happening is:</p> <ul> <li> <p>In your branch's demo-env-vars YAML file, set <code>LOCAL_DB_UPDATE=True</code> so that the Dev DB is not pulled down to the demo app</p> </li> <li> <p>Ask one of the backend team to set the Demo app to always be awake by setting 'Minimum instances' to 1 for the relevant Cloud Run service and restarting it. The app will always be on and will not sleep, so won't need a cold start. Once you have completed the feature work, please ask the backenders to restore the default sleepy behaviour. As an example with <code>mozorg-demo-1</code>:</p> <ul> <li>To make it always-on: <code>gcloud run services update mozorg-demo-1 --min-instances 1</code></li> <li>To revert it to auto-sleeping: <code>gcloud run services update mozorg-demo-1 --min-instances 0</code></li> </ul> </li> </ul> <p>(We'll try to make this a self-serve thing as soon as we can).</p>"},{"location":"contribute/#deprecated-heroku-demo-servers","title":"DEPRECATED: Heroku Demo Servers","text":"<p>Demos are now powered by Google Cloud Platform (GCP), and no longer by Heroku.</p> <p>However, the Github Action we used to push code to Heroku may still be enabled. Pushing a branch to one of the <code>demo/*</code> branches of the <code>mozilla/bedrock</code> repo will trigger this. However, note that URLs that historically used to point to Heroku will be pointed to the new GCP demos services instead, so you will have to look at Heroku's web UI to see what the URL of the relevant Heroku app is.</p> <p>To push to launch a demo on Heroku:</p> <pre><code>$ git push -f mozilla my-demo-branch:demo/1\n</code></pre>"},{"location":"contribute/#pushing-to-production","title":"Pushing to production","text":"<p>We're doing pushes as soon as new work is ready to go out.</p> <p>Code flows automatically to Dev, amd manually to Stage and to Production. See Continuous Integration &amp; Deployment for details.</p> <p>After doing a push, those who are responsible for implementing changes need to update the bugs that have been pushed with a quick message stating that the code was deployed.</p> <p>If you'd like to see the commits that will be deployed before the push run the following command:</p> <pre><code>$ ./bin/open-compare.py\n</code></pre> <p>This will discover the currently deployed git hash, and open a compare URL at github to the latest main. Look at <code>open-compare.py -h</code> for more options.</p> <p>We automate pushing to production via tagged commits (see Continuous Integration &amp; Deployment)</p>"},{"location":"download-buttons/","title":"Firefox Download Buttons","text":""},{"location":"download-buttons/#download-buttons","title":"Firefox Download Buttons","text":"<p>There are two Firefox download button helpers in bedrock to choose from. The first is a lightweight button that links directly to the <code>/firefox/download/thanks/</code> page. Its sole purpose is to facilitate downloading the main release version of Firefox.</p> <pre><code>{{ download_firefox_thanks() }}\n</code></pre> <p>The second type of button is more heavy weight, and can be configured to download any build of Firefox (e.g. Release, Beta, Developer Edition, Nightly). It can also offer functionality such as direct (in-page) download links, so it comes with a lot more complexity and in-page markup.</p> <pre><code>{{ download_firefox() }}\n</code></pre>"},{"location":"download-buttons/#which-button-should-i-use","title":"Which button should I use?","text":"<p>A good rule of thumb is to always use <code>download_firefox_thanks()</code> for regular landing pages (such as <code>/firefox/new/</code>) where the main release version of Firefox is the product being offered. For pages pages that require direct download links, or promote pre-release products (such as <code>/firefox/channel/</code>) then <code>download_firefox()</code> should be used instead.</p>"},{"location":"download-buttons/#documentation","title":"Documentation","text":"<p>See helpers.py for documentation and supported parameters for both buttons.</p>"},{"location":"install/","title":"Install","text":""},{"location":"install/#install","title":"Installing Bedrock","text":""},{"location":"install/#installation-methods","title":"Installation Methods","text":"<p>There are two primary methods of installing bedrock: Docker and Local. Whichever you choose, you'll start by getting the source.</p> <p>The codebase lives at https://github.com/mozilla/bedrock/</p> <p>Only Mozilla staff have write access to that repository; community contributors do not, so should instead make a fork of the repo to work from. You will still be able to make pull requests from your fork into <code>mozilla/bedrock</code>.</p> <p>Get the source code:</p> <pre><code># If you're a Mozilla staff member with write access to the repo\n$ git clone https://github.com/mozilla/bedrock.git\n\n# Or if you lack write access to the repo\n$ git clone https://github.com/YOUR_GITHUB_USERNAME_HERE/bedrock.git\n</code></pre> <p>Once the codebase is cloned, switch into it:</p> <pre><code>$ cd bedrock\n</code></pre> <p>After these basic steps you can choose your install method below.</p> <p>Docker is the easiest and recommended way, but local installation directly onto your machine is also possible and may be preferred, particularly if you're doing frontend work, which is currently slower when using Docker.</p> <p>Note</p> <p>You should also install our git pre-commit hooks. These are checks that automatically run before a git commit is allowed. You don't have to do this in order to get bedrock running locally, but it's recommended to do before you start making contributions.</p> <p>The Bedrock project uses the pre-commit framework that makes managing git hooks easier across all contributors by ensuring everyone has the same ones set up.</p> <p>Install the framework by running <code>pip install pre-commit</code>, then - ensuring you are in your <code>bedrock</code> directory -run <code>pre-commit install</code> in your terminal, followed by <code>pre-commit install-hooks</code>. This will set up the hooks that are specified in <code>bedrock/.precommit.yaml</code></p> <p>After that setup, whenever you try to make a commit, the 'hooks' will check/lint your Python, JS, and CSS files beforehand and report on problems that need to be fixed before the commit can be made. This will save you time waiting for the tests to run in our <code>CI (Continuous Integration)</code> before noticing a linting error.</p>"},{"location":"install/#docker-installation","title":"Docker Installation","text":"<p>Note</p> <p>This method assumes you have Docker installed for your platform. If not please do that now or skip to the <code>Local Installation</code> section.</p> <p>This is the simplest way to get started developing for bedrock. If you're on Linux or Mac (and possibly Windows 10 with the Linux subsystem) you can run a script that will pull our production and development docker images and start them:</p> <pre><code>$ make clean run\n</code></pre> <p>Note</p> <p>You can start the server any other time with:</p> <pre><code>$ make run\n</code></pre> <p>You should see a number of things happening, but when it's done it will output something saying that the server is running at localhost:8000. Go to that URL in a browser and you should see the mozilla.org home page. In this mode the site will refresh itself when you make changes to any template or media file. Simply open your editor of choice and modify things and you should see those changes reflected in your browser.</p> <p>Note</p> <p>It's a good idea to run <code>make pull</code> from time to time. This will pull down the latest Docker images from our repository ensuring that you have the latest dependencies installed among other things. If you see any strange errors after a <code>git pull</code> then <code>make pull</code> is a good thing to try for a quick fix.</p> <p>If you don't have or want to use Make you can call the docker and compose commands directly</p> <pre><code>$ docker compose pull\n</code></pre> <pre><code>$ [[ ! -f .env ]] &amp;&amp; cp .env-dist .env\n</code></pre> <p>Then starting it all is simply</p> <pre><code>$ docker compose up app assets\n</code></pre> <p>All of this is handled by the <code>Makefile</code> script and called by Make if you follow the above directions. You DO NOT need to do both.</p> <p>These directions pull and use the pre-built images that our deployment process has pushed to the Docker Hub. If you need to add or change any dependencies for Python or Node then you'll need to build new images for local testing. You can do this by updating the requirements files and/or package.json file then simply running:</p> <pre><code>$ make build\n</code></pre> <p>Note</p> <p>For Apple Silicon / M1 users</p> <p>If you find that when you're building you hit issues compiling assets, try unchecking <code>Use Rosetta for x86_64/amd64 emulation on Apple Silicon</code> in the Docker Desktop settings.</p> <p>Asset bundles</p> <p>If you make a change to <code>media/static-bundles.json</code>, you'll need to restart Docker.</p> <p>Note</p> <p>Sometimes stopping Docker doesn't actually kill the images. To be safe, after stopping docker, run <code>docker ps</code> to ensure the containers were actually stopped. If they have not been stopped, you can force them by running <code>docker compose kill</code> to stop all containers, or <code>docker kill &lt;container_name&gt;</code> to stop a single container, e.g. <code>docker kill bedrock_app_1</code>.</p>"},{"location":"install/#local-installation","title":"Local Installation","text":"<p>These instructions assume you have Python, pip, and NodeJS installed. If you don't have <code>pip</code> installed (you probably do) you can install it with the instructions in the pip docs.</p> <p>Bedrock currently uses Python 3.12.x. The recommended way to install and use that version is with pyenv and to create a virtualenv using pyenv-virtualenv that will isolate Bedrock's dependencies from other things installed on the system.</p> <p>The following assumes you are on MacOS, using <code>zsh</code> as your shell and Homebrew as your package manager. If you are not, there are installation instructions for a variety of platforms and shells in the READMEs for the two pyenv projects.</p> <p>Install Python 3.12.x with pyenv</p> <ol> <li>Install <code>pyenv</code> itself :<pre><code>$ brew install pyenv\n</code></pre> </li> </ol> <p>2. Configure your shell to init <code>pyenv</code> on start - this is noted in the project's own docs, in more detail, but omits that setting <code>PYENV_ROOT</code> and adding it to the path is needed:</p> <pre><code>$ echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.zshrc\n$ echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.zshrc\n$ echo 'eval \"$(pyenv init -)\"' &gt;&gt; ~/.zshrc\n</code></pre> <p>3. Restart your login session for the changes to profile files to take effect - if you're not using <code>zsh</code>, the <code>pyenv</code> docs have other routes :</p> <pre><code>$ zsh -l\n</code></pre> <ol> <li> <p>Install the latest Python 3.12.x (e.g. 3.12.6), then test it's there:</p> <pre><code>$ pyenv install 3.12.6\n</code></pre> <p>If you'd like to make Python 3.12 your default globally, you can do so with:</p> <pre><code>$ pyenv global 3.12.6\n</code></pre> <p>If you only want to make Python 3.12 available in the current shell, while you set up the Python virtualenv (below), you can do so with:</p> <pre><code>$ pyenv shell 3.12.6\n</code></pre> </li> <li> <p>Verify that you have the correct version of Python installed:</p> <pre><code>$ python --version\nPython 3.12.6\n</code></pre> </li> </ol> <p>Install a plugin to manage virtualenvs via pyenv and create a virtualenv for Bedrock's dependencies</p> <ol> <li>Install <code>pyenv-virtualenv</code> :<pre><code>$ brew install pyenv-virtualenv\n</code></pre> </li> </ol> <p>2. Configure your shell to init <code>pyenv-virtualenv</code> on start - again, this is noted in the <code>pyenv-virtualenv</code> project's own documentation, in more detail. The following will slot in a command that will work as long as you have pyenv-virtualenv installed:</p> <pre><code>$ echo 'eval \"$(pyenv virtualenv-init -)\"' &gt;&gt; ~/.zshrc\n</code></pre> <ol> <li> <p>Restart your login session for the changes to profile files to take effect :</p> <pre><code>$ zsh -l\n</code></pre> </li> <li> <p>Make a virtualenv we can use - in this example we'll call it <code>bedrock</code> but use whatever you want :</p> <pre><code>$ pyenv virtualenv 3.12.6 bedrock\n</code></pre> </li> </ol> <p>Use the virtualenv</p> <ol> <li>Switch to the virtualenv - this is the command you will use any time you need this virtualenv :<pre><code>$ pyenv activate bedrock\n</code></pre> </li> </ol> <p>2. If you'd like to auto activate the virtualenv when you cd into the bedrock directory, and deactivate it when you exit the directory, you can do so with:</p> <pre><code>$ echo 'bedrock' &gt; .python-version\n</code></pre> <ol> <li> <p>Securely upgrade pip :</p> <pre><code>$ pip install --upgrade pip\n</code></pre> </li> <li> <p>Install / update Python dependencies :</p> <pre><code>$ make install-local-python-deps\n</code></pre> </li> </ol> <p>Note</p> <p>If you are on OSX and some of the compiled dependencies fails to compile, try explicitly setting the arch flags and try again. The following are relevant to Intel Macs only. If you're on Apple Silicon, 3.12.6 should 'just work':</p> <pre><code>$ export ARCHFLAGS=\"-arch i386 -arch x86_64\"\n</code></pre> <pre><code>$ make install-local-python-deps\n</code></pre> <p>If you are on Linux, you may need at least the following packages or their equivalent for your distro:</p> <pre><code>python3-dev libxslt-dev\n</code></pre> <p>Download a fresh copy of the sqlite database that Bedrock uses locally This contains product-details, security-advisories, credits, release notes, localizations, legal-docs etc. We also download the latest translations of site content in many languages:</p> <pre><code>$ bin/bootstrap.sh\n</code></pre> <p>Install the node dependencies to run the site. This will only work if you already have Node.js and npm installed:</p> <pre><code>$ npm install\n</code></pre> <p>Note</p> <p>Bedrock uses npm to ensure that Node.js packages that get installed are the exact ones we meant (similar to pip hash checking mode for python). Refer to the npm documentation for adding or upgrading Node.js dependencies.</p> <p>Note</p> <p>As a convenience, there is a <code>make preflight</code> command which calls some of the commands above to bring your installed Python and NPM dependencies up to date and also fetches the latest DB containing the latest site content. This is a good thing to run after pulling in latest changes from the <code>main</code> branch.</p> <p>IMPORTANT: if you do not want to replace your local DB with a fresher one, use <code>make preflight -- --retain-db</code> instead.</p> <p>We also have an optional git hook that will alert you if <code>make preflight</code> needs to be run. You can install that with <code>make install-custom-git-hooks</code>.</p>"},{"location":"install/#run-python-tests","title":"Run the tests","text":"<p>Now that we have everything installed, let's make sure all of our tests pass. This will be important during development so that you can easily know when you've broken something with a change.</p>"},{"location":"install/#docker","title":"Docker","text":"<p>We manage our local docker environment with docker compose and Make. All you need to do here is run:</p> <pre><code>$ make test\n</code></pre> <p>If you don't have Make you can simply run <code>docker compose run test</code>.</p> <p>If you'd like to run only a subset of the tests or only one of the test commands you can accomplish that with a command like the following:</p> <pre><code>$ docker compose run test pytest bedrock/firefox\n</code></pre> <p>This example will run only the unit tests for the <code>firefox</code> app in bedrock. You can substitute <code>pytest bedrock/firefox</code> with most any shell command you'd like and it will run in the Docker container and show you the output. You can also just run <code>bash</code> to get an interactive shell in the container which you can then use to run any commands you'd like and inspect the file system:</p> <pre><code>$ docker compose run test bash\n</code></pre>"},{"location":"install/#local","title":"Local","text":"<p>From the local install instructions above you should still have your virtualenv activated, so running the tests is as simple as:</p> <pre><code>$ pytest lib bedrock\n</code></pre> <p>To test a single app, specify the app by name in the command above. e.g.:</p> <pre><code>$ pytest bedrock/firefox\n</code></pre>"},{"location":"install/#run-a-local-server","title":"Run a local server","text":"<p>Info</p> <p>Regardless of whether you run Bedrock via Docker or directly on your machine, the URL of the site is <code>http://localhost:8000</code> - <code>not</code> <code>8080</code></p>"},{"location":"install/#docker_1","title":"Docker","text":"<p>You can simply run the <code>make run</code> script mentioned above, or use docker compose directly:</p> <pre><code>$ docker compose up app assets\n</code></pre>"},{"location":"install/#local_1","title":"Local","text":"<p>To make the server run, make sure your virtualenv is activated with <code>pyenv activate bedrock</code>, and then run the server:</p> <pre><code>$ npm start\n</code></pre> <p>Wait for the server to start up and then browse to http://localhost:8000</p> <p>Congratulations, you should now have your own copy of www.mozilla.org running locally!</p>"},{"location":"install/#prod-mode","title":"Prod Mode","text":"<p>There are certain things about the site that behave differently when running locally in dev mode using Django's development server than they do when running in the way it runs in production. Static assets that work fine locally can be a problem in production if referenced improperly, and the normal error pages won't work unless <code>DEBUG=False</code> and doing that will make the site throw errors since the Django server doesn't have access to all of the built static assets. So we have a couple of extra Docker commands (via make) that you can use to run the site locally in a more prod-like way.</p> <p>First you should ensure that your <code>.env</code> file is setup the way you need. This usually means adding <code>DEBUG=False</code> and <code>DEV=False</code>, though you may want <code>DEV=True</code> if you want the site to act more like www-dev.allizom.org in that all feature switches are <code>On</code> and all locales are active for every page. After that you can run the following:</p> <pre><code>$ make run-prod\n</code></pre> <p>This will run the latest bedrock image using your local bedrock files and templates, but not your local static assets. If you need an updated image just run <code>make pull</code>.</p> <p>If you need to include the changes you've made to your local static files (images, css, js, etc.) then you have to build the image first:</p> <pre><code>$ make build-prod run-prod\n</code></pre>"},{"location":"install/#documentation","title":"Documentation","text":"<p>This is a great place for coders and non-coders alike to contribute! Please note most of the documentation is currently in reStructuredText but we also support Markdown files.</p> <p>If you see a typo or similarly small change, you can use the \"Edit in GitHub\" link to propose a fix through GitHub. Note: you will not see your change directly committed to the main branch. You will commit the change to a separate branch so it can be reviewed by a staff member before merging to main.</p> <p>If you want to make a bigger change or find a Documentation issue on the repo, it is best to edit and preview locally before submitting a pull request. You can do this with Docker or Local installations. Run the commands from your root folder. They will build documentation and start a live server to auto-update any changes you make to a documentation file.</p> <p>Docker:</p> <pre><code>$ make docs\n</code></pre> <p>Local:</p> <pre><code>$ pip install -r requirements/docs.txt\n</code></pre> <pre><code>$ make livedocs\n</code></pre>"},{"location":"install/#localization","title":"Localization","text":"<p>Localization (or L10n) files were fetched by the <code>bootstrap.sh</code> command your ran earlier and are included in the docker images. If you need to update them or switch to a different repo or branch after changing settings you can run the following command:</p> <pre><code>$ ./manage.py l10n_update\n</code></pre> <p>You can read more details about how to localize content here.</p>"},{"location":"install/#feature-flipping-aka-switches-or-waffle-switches","title":"Feature Flipping (aka Switches, or waffle switches)","text":"<p>Switches are managed using django-waffle and are stored in the database. These switches control behavior and/or features of select pages on Bedrock, and their state (active or inactive) is based on an <code>active</code> boolean field in the database.</p>"},{"location":"install/#defining-and-using-switches","title":"Defining and Using Switches","text":"<p>The <code>switch()</code> template helper function allows you to check whether a specific switch is active. You pass a name to the function (using only letters, numbers, and dashes), which is automatically converted to uppercase and with dashes replaced by underscores for the lookup in the database. For example, <code>switch('the-dude')</code> will look for a switch named <code>THE_DUDE</code> in the database.</p>"},{"location":"install/#locale-specific-switches","title":"Locale-Specific Switches","text":"<p>You can provide a list of locale codes to limit the switch's activation to specific locales. If the page is viewed in a locale not included in the list, the switch will return False. You can also use \"Locale Groups,\" which apply to all locales with a common prefix (e.g., \"en-US, en-GB\" or \"zh-CN, zh-TW\"). To use these groups, pass the prefix. For example, <code>switch('the-dude', ['en', 'de'])</code> will activate the switch for German and any English locale supported by the site.</p>"},{"location":"install/#managing-switches","title":"Managing Switches","text":"<p>Switches are managed through the Django Admin interface, where you can add, edit, or remove switches from the database directly. This interface allows for easy management of feature toggles without modifying environment variables or code. There is also a Django management command to toggle switches from the command line, as detailed below.</p>"},{"location":"install/#deploy-switches-with-code","title":"Deploy switches with code","text":"<p>You can deploy switches directly through code by creating a data migration. This approach ensures switches are consistently created or updated during deployment, rather than requiring manual configuration through the Django Admin interface.</p> <p>To implement a switch via data migration, create an empty migration file:</p> <pre><code>./manage.py makemigrations base --empty\n</code></pre> <p>Then add the following code to the generated migration file, which can be found in the <code>bedrock/base/migrations</code> directory:</p> <pre><code>from django.db import migrations\n\nfrom waffle.models import Switch\n\n# The name of the switch must be unique.\nSWITCH_NAME = \"RELEASE_THE_KRAKEN\"\n\n\ndef create_switch(apps, schema_editor):\n    Switch.objects.get_or_create(\n        name=SWITCH_NAME,\n        defaults={\"active\": True},  # Set initial state, True or False.\n    )\n\n\ndef remove_switch(apps, schema_editor):\n    Switch.objects.filter(name=SWITCH_NAME).delete()\n\n\nclass Migration(migrations.Migration):\n    dependencies = [\n        (\n            \"base\",\n            \"0001_initial\",\n        ),  # Keep whatever the makemigrations command generated here.\n    ]\n\n    operations = [\n        migrations.RunPython(create_switch, remove_switch),\n    ]\n</code></pre> <p>The migration will run during deployment and ensure the switch exists in the database. The <code>remove_switch</code> function allows the migration to be reversed if needed.</p> <p>To test this locally, run the following command:</p> <pre><code>./manage.py migrate base\n</code></pre> <p>Verify the switch exists in the database by running:</p> <pre><code>./manage.py waffle_switch -l\n</code></pre> <p>You should see the switch listed in the output.</p> <p>To test reversing the migration, run the following command but replace <code>0001</code> with whatever the previous migration number is:</p> <pre><code>./manage.py migrate base 0001\n</code></pre>"},{"location":"install/#example-usage-in-templates","title":"Example Usage in Templates","text":"<p>You can use the <code>switch()</code> helper function in your templates as follows:</p> <pre><code>{% if switch('the-dude') %}\n    &lt;!-- Feature-specific HTML goes here --&gt;\n{% endif %}\n</code></pre>"},{"location":"install/#example-usage-in-python","title":"Example Usage in Python","text":"<p>You may also use switches in Python code (though locale support is unavailable in this context):</p> <p>Note</p> <p>Avoid using switch() outside the request/response cycle (e.g., during module-level imports or in a urls.py file), as the switch's state is managed in the database and can be changed via the admin interface. Using it outside the request cycle would prevent the switch value from reflecting real-time updates.</p> <pre><code>from bedrock.base.waffle import switch\n\n\ndef home_view(request):\n    title = \"Staging Home\" if switch(\"staging-site\") else \"Prod Home\"\n    ...\n</code></pre>"},{"location":"install/#testing","title":"Testing","text":"<p>If the environment variable <code>DEV</code> is set to a \"true\" value, then all switches will be considered active unless they are explicitly set as not active in the database. <code>DEV</code> defaults to \"true\" in local development and demo servers.</p> <p>To test switches locally, add the switch to the database. This can be done in one of two ways.</p> <ol> <li> <p>Add the switch via the Django management command:</p> <pre><code>./manage.py waffle_switch --create SWITCH_NAME on\n</code></pre> <p>If the switch already exists, you can toggle it using:</p> <pre><code>./manage.py waffle_switch SWITCH_NAME on ./manage.py waffle_switch SWITCH_NAME off\n</code></pre> <p>And you can view all the switches via:</p> <pre><code>./manage.py waffle_switch -l\n</code></pre> <p>To delete a switch, run:</p> <pre><code>./manage.py waffle_delete --switches SWITCH_NAME\n</code></pre> </li> <li> <p>Add the switch in the Django admin at <code>/django-admin/</code>. There you will see the \"Django-Waffle\" module with the \"Switches\" table. Click through to view the switches and add/edit/delete as needed.</p> </li> </ol>"},{"location":"install/#traffic-cop","title":"Traffic Cop","text":"<p>Currently, these switches are used to enable/disable Traffic Cop experiments on many pages of the site. We only add the Traffic Cop JavaScript snippet to a page when there is an active test.</p> <p>To work with/test these experiment switches locally, you must add the switches to your local database.</p>"},{"location":"install/#notes","title":"Notes","text":"<p>A shortcut for activating virtual envs in zsh or bash is <code>. venv/bin/activate</code>. The dot is the same as <code>source</code>.</p> <p>There's a project called pew that provides a better interface for managing/activating virtual envs, so you can use that if you want. Also if you need help managing various versions of Python on your system, the pyenv project can help.</p>"},{"location":"l10n/","title":"Localization","text":""},{"location":"l10n/#l10n","title":"Localization","text":"<p>Note</p> <p>This document focuses on localization of hard-coded content. For localization of CMS-based content please see the CMS-specific L10N docs.</p> <p>The site is fully localizable. Localization files are not shipped with the code distribution, but are available in separate GitHub repositories. The proper repos can be cloned and kept up-to-date using the <code>l10n_update</code> management command:</p> <pre><code>$ ./manage.py l10n_update\n</code></pre> <p>If you don't already have a <code>data/www-l10n</code> directory, this command will clone the git repo containing the .ftl translation files (either the dev or prod files depending on your <code>DEV</code> setting). If the folder is already present, it will update the repository to the latest version.</p>"},{"location":"l10n/#fluent","title":"Fluent","text":"<p>Bedrock's Localization (l10n) system is based on Project Fluent. This is a departure from a standard Django project that relies on a gettext work flow of string extraction from template and code files, in that it relies on developers directly editing the default language (English in our case) Fluent files and using the string IDs created there in their templates and views.</p> <p>The default files for the Fluent system live in the <code>l10n</code> directory in the root of the bedrock project. This directory houses directories for each locale the developers directly implement (mostly simplified English \"en\", and \"en-US\"). The simplified English files are the default fallback for every string ID on the site and should be strings that are plain and easy to understand English, as free from colloquialisms as possible. The translators are able to easily understand the meaning of the string, and can then add their own local flair to the ideas.</p>"},{"location":"l10n/#ftl-files","title":".ftl files","text":"<p>When adding translatable strings to the site you start by putting them all into an .ftl file in the <code>l10n/en/</code> directory with a path that matches or is somehow meaningful for the expected location of the template or view in which they'll be used. For example, strings for the <code>mozorg/mission.html</code> template would go into the <code>l10n/en/mozorg/mission.ftl</code> file. Locales are activated for a particular .ftl file, not template or URL, so you should use a unique file for most URLs, unless they're meant to be translated and activated for new locales simultaneously.</p> <p>You can have shared .ftl files that you can load into any template render, but only the first .ftl file in the list of the ones for a page render will determine whether the page is active for a locale.</p> <p>Activation of a locale happens automatically once certain rules are met. A developer can mark some string IDs as being \"Required\", which means that the file won't be activated for a locale until that locale has translated all of those required strings. The other rule is a percentage completion rule: a certain percentage (configurable) of the strings IDs in the \"en\" file must be translated in the file for a locale before it will be marked as active. We'll get into how exactly this works later.</p>"},{"location":"l10n/#translating-with-ftl-files","title":"Translating with .ftl files","text":"<p>The Fluent file syntax is well documented on the Fluent Project's site. We use \"double hash\" or \"group\" comments to indicate strings required for activation. A group comment only ends when another group comment starts however, so you should either group your required strings at the bottom of a file, or also have a \"not required\" group comment. Here's an example:</p> <pre><code>### File for example.html\n\n## Required\nexample-page-title = The Page Title\n# this is a note the applies only to example-page-desc\nexample-page-desc = This page is a test.\n\n##\nexample-footer = This string isn't as important\n</code></pre> <p>Any group comment (a comment that starts with \"##\") that starts with \"Required\" (case does not matter) will start a required strings block, and any other group comment will end it.</p> <p>Once you have your strings in your .ftl file you can place them in your template. We'll use the above .ftl file for a simple Jinja template example:</p> <pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{{ ftl('example-page-title') }}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;{{ ftl('example-page-title') }}&lt;/h1&gt;\n    &lt;p&gt;{{ ftl('example-page-desc') }}&lt;/p&gt;\n    &lt;footer&gt;\n        &lt;p&gt;{{ ftl('example-footer') }}&lt;/p&gt;\n    &lt;/footer&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"l10n/#ftl-fluent-translation-list-string-ids","title":"<code>FTL (Fluent Translation List)</code> String IDs","text":"<p>Our convention for string ID creation is the following:</p> <ol> <li>String IDs should be all lower-case alphanumeric characters.</li> <li>Words should be separated with hyphens.</li> <li>IDs should be prefixed with the name of the template file (e.g. <code>firefox-new-skyline</code> for <code>firefox-new-skyline.html</code>)</li> <li>If you need to create a new string for the same place on a page and to transition to it as it is translated, you can add a version suffix to the string ID: e.g. <code>firefox-new-skyline-main-page-title-v2</code>.</li> <li>The ID should be as descriptive as possible to make sense to the developer, but could be anything as long as it adheres to the rules above.</li> </ol>"},{"location":"l10n/#using-brand-names","title":"Using brand names","text":"<p>Common Mozilla brand names are stored in a global brands.ftl file, in the form of terms. Terms are useful for keeping brand names separated from the rest of the translations, so that they can be managed in a consistent way across all translated files, and also updated easily in a global context. In general the brand names in this file remain in English and should not be translated, however locales still have the choice and control to make adjustments should it suit their particular language.</p> <p>Only our own brands should be managed this way, brands from other companies should not. If you are concerned that the brand is a common word and may be translated, leave a comment for the translators.</p> <p>Note</p> <p>We are trying to phase out use of <code>{ -brand-name-firefox-browser }</code> please use <code>{ -brand-name-firefox } browser</code>.</p> <pre><code>-brand-name = Firefox\n\nexample-about = About { -brand-name }.\nexample-update-successful = { -brand-name } has been updated.\n# \"Safari\" here refers to the competing web browser\nexample-compare = How does { -brand-name } compare to Safari?\n</code></pre> <p>Important</p> <p>When adding a new term to <code>brands.ftl</code>, the new term should also be manually added to the mozilla-l10n/www-l10n repo for all locales. The reason for this is that if a term does not exist for a particular locale, then it does not fall back to English like a regular string does. Instead, the term variable name is displayed on the page.</p>"},{"location":"l10n/#variables","title":"Variables","text":"<p>Single hash comments are applied only to the string immediately following them. They should be used to provide additional context for the translators including:</p> <ol> <li>What the values of variables are.</li> <li>Context about where string appears on the page if it is not visible or references other elements on the page.</li> <li>Explanations of English idioms and jargon that may be confusing to non-native speakers.</li> </ol> <pre><code># Variables:\n#   $savings (string) - the percentage saved from the regular price, not including the % Examples: 50, 70\nexample-bundle-savings = Buy now for { $savings }% off.\n\n# Context: Used as an accessible text alternative for an image\nexample-bookmark-manager-alt = The bookmark manager window in { -brand-name-firefox }.\n# Context: This lists the various websites and magazines who have mentioned Firefox Relay.\n# Example: \"As seen in: FORBES magainze and LifeHacker\"\nexample-social-proof = As seen in:\n\nexample-privacy-on-every = Want privacy on every device?\n# \"You got it\" here is a casual answer to the previous question, \"Want privacy on every device?\"\nexample-you-got-it = You got it. Get { -brand-name-firefox } for mobile.\n</code></pre>"},{"location":"l10n/#html-with-attributes","title":"HTML with attributes","text":"<p>When passing HTML tags with attributes into strings for translation, remove as much room for error as possible by putting all the attributes and their values in a single variable. (This is most common with links and their href attributes but we do occasionally pass classes with other tags.)</p> <pre><code># Variables:\n#   $attrs (attrs) - link to https://www.mozilla.org/about/\nexample-created = { -brand-name-firefox } was created by &lt;a {$attrs}&gt;{ -brand-name-mozilla }&lt;/a&gt;.\n\n# Variables:\n#   $class (string) - CSS class used to replace brand name with wordmark logo\nexample-firefox-relay = Add &lt;span { $class }\"&gt;{ -brand-name-firefox-relay }&lt;/span&gt;\n</code></pre> <pre><code>{% set created_attrs = 'href=\"%s\" data-cta-text=\"created by Mozilla\"'|safe|format(url('mozorg.about.index')) %}\n&lt;p&gt;{{ ftl('example-created', attrs=created_attrs) }}&lt;/p&gt;\n\n{{ ftl('example-firefox-relay', class_name='class=\"mzp-c-wordmark mzp-t-wordmark-md mzp-t-product-relay\"') }}\n</code></pre>"},{"location":"l10n/#obsolete-strings","title":"Obsolete strings","text":"<p>When new strings are added to a page sometimes they update or replace old strings. Obsolete strings &amp; IDs should be removed from ftl files immediately if they are not being used as a fallback. If they are being kept as a fallback they should be removed after 2 months.</p> <p>When you add a comment marking a string as obsolete, add the date when it can be removed to the comment.</p> <pre><code># Obsolete string (expires: 2024-03-18)\nexample-old-string = Fifty thousand year old twisted bark threads.\n</code></pre>"},{"location":"l10n/#fallback","title":"Fallback","text":"<p>If you need to create a new string for the same place on a page and would like to keep the old one as a fallback, you can add a version suffix to the new string ID: e.g. <code>firefox-new-skyline-main-page-title-v2</code>.</p> <pre><code>example-block-title-v2 = Security, reliability and speed \u2014 on every device, anywhere you go.\n# Obsolete string (expires: 2024-03-18)\nexample-block-title = Security, reliability and speed \u2014 from name you can trust.\n</code></pre> <p>The <code>ftl</code> helper function has the ability to accept a fallback string ID and is described in the next section.</p>"},{"location":"l10n/#remove","title":"Remove","text":"<p>If the new string is fundamentally different a new string ID should be created and the old one deleted.</p> <p>For example, if the page is going from talking about the Google Translate extension to promoting our own Firefox Translate feature the old strings are not appropriate fall backs.</p> <p>The old strings and IDs should be deleted:</p> <pre><code>example-translate-title = The To Google Translate extension makes translating the page you\u2019re on easier than ever.\nexample-translate-content = Google Translate, with over 100 languages* at the ready, is used by millions of people around the world.\n</code></pre> <p>The new strings should have different IDs and not be versioned:</p> <pre><code>example-translate-integrated-title = { -brand-name-firefox } now comes with an integrated translation tool.\nexample-translate-integrated-content =  Unlike some cloud-based alternatives, { -brand-name-firefox } translates text locally, so the content you\u2019re translating doesn\u2019t leave your machine.\n</code></pre> <p>The <code>ftl_has_messages</code> jinja helper would be useful here and is described in the next section.</p>"},{"location":"l10n/#the-ftl-helper-function","title":"The <code>ftl</code> helper function","text":"<p>The <code>ftl()</code> function takes a string ID and returns the string in the current language, or simplified english if the string isn't translated. If you'd like to use a different string ID in the case that the primary one isn't translated you can specify that like this:</p> <pre><code>ftl(\"primary-string-id\", fallback=\"fallback-string-id\")\n</code></pre> <p>When a fallback is specified it will be used only if the primary isn't translated in the current locale. English locales (e.g. en-US, en-GB) will never use the fallback and will print the simplified english version of the primary string if not overridden in the more specific locale.</p> <p>You can also pass in replacement variables into the <code>ftl()</code> function for use with fluent variables. If you had a variable in your fluent file like this:</p> <pre><code>welcome = Welcome, { $user }!\n</code></pre> <p>You could use that in a template like this:</p> <pre><code>&lt;h2&gt;{{ ftl('welcome', user='Dude') }}&lt;h2&gt;\n</code></pre> <p>For our purposes these are mostly useful for things that can change, but which shouldn't involve retranslation of a string (e.g. URLs or email addresses).</p> <p>You may also request any other translation of the string (or the original English string of course) regardless of the current locale.</p> <pre><code>&lt;h2&gt;{{ ftl('welcome', locale='en', user='Dude') }}&lt;h2&gt;\n</code></pre> <p>This helper is available in Jinja templates and Python code in views. For use in a view you should always call it in the view itself:</p> <pre><code># views.py\nfrom lib.l10n_utils import render\nfrom lib.l10n_utils.fluent import ftl\n\n\ndef about_view(request):\n    ftl_files = \"mozorg/about\"\n    hello_string = ftl(\"about-hello\", ftl_files=ftl_files)\n    render(request, \"about.html\", {\"hello\": hello_string}, ftl_files=ftl_files)\n</code></pre> <p>If you need to use this string in a view, but define it outside of the view itself, you can use the <code>ftl_lazy</code> variant which will delay evaluation until render time. This is mostly useful for defining messages shared among several views in constants in a <code>views.py</code> or <code>models.py</code> file.</p> <p>Whether you use this function in a Python view or a Jinja template it will always use the default list of Fluent files defined in the <code>FLUENT_DEFAULT_FILES</code> setting. If you don't specify any additional Fluent files via the <code>fluent_files</code> keyword argument, then only those default files will be used.</p>"},{"location":"l10n/#the-ftl_has_messages-helper-function","title":"The <code>ftl_has_messages</code> helper function","text":"<p>Another useful template tool is the <code>ftl_has_messages()</code> function. You pass it any number of string IDs and it will return <code>True</code> only if all of those message IDs exist in the current translation. This is useful when you want to add a new block of HTML to a page that is already translated, but don't want it to appear untranslated on any page.</p> <pre><code>{% if ftl_has_messages('new-title', 'new-description') %}\n  &lt;h3&gt;{{ ftl('new-title') }}&lt;/h3&gt;\n  &lt;p&gt;{{ ftl('new-description') }}&lt;/p&gt;\n{% else %}\n  &lt;h3&gt;{{ ftl('title') }}&lt;/h3&gt;\n  &lt;p&gt;{{ ftl('description') }}&lt;/p&gt;\n{% endif %}\n</code></pre> <p>If you'd like to have it return true when any of the given message IDs exist in the translation instead of requiring all of them, you can pass the optional <code>require_all=False</code> parameter and it will do just that.</p> <p>There is a version of this function for use in views called <code>has_messages</code>. It works exactly the same way but is meant to be used in the view Python code.</p> <pre><code># views.py\nfrom lib.l10n_utils import render\nfrom lib.l10n_utils.fluent import ftl, has_messages\n\n\ndef about_view(request):\n    ftl_files = \"mozorg/about\"\n    if has_messages(\"about-hello-v2\", \"about-title-v2\", ftl_files=ftl_files):\n        hello_string = ftl(\"about-hello-v2\", ftl_files=ftl_files)\n        title_string = ftl(\"about-title-v2\", ftl_files=ftl_files)\n    else:\n        hello_string = ftl(\"about-hello\", ftl_files=ftl_files)\n        title_string = ftl(\"about-title\", ftl_files=ftl_files)\n\n    render(\n        request,\n        \"about.html\",\n        {\"hello\": hello_string, \"title\": title_string},\n        ftl_files=ftl_files,\n    )\n</code></pre>"},{"location":"l10n/#specifying_fluent_files","title":"Specifying Fluent files","text":"<p>You have to tell the system which Fluent files to use for a particular template or view. This is done in either the <code>page()</code> helper in a <code>urls.py</code> file, or in the call to <code>l10n_utils.render()</code> in a view.</p>"},{"location":"l10n/#using-the-page-function","title":"Using the <code>page()</code> function","text":"<p>If you just need to render a template, which is quite common for bedrock, you will probably just add a line like the following to your <code>urls.py</code> file:</p> <pre><code>urlpatterns = [\n    page(\"about\", \"about.html\"),\n    page(\"about/contact\", \"about/contact.html\"),\n]\n</code></pre> <p>To tell this page to use the Fluent framework for l10n you just need to tell it which file(s) to use:</p> <pre><code>urlpatterns = [\n    page(\"about\", \"about.html\", ftl_files=\"mozorg/about\"),\n    page(\n        \"about/contact\",\n        \"about/contact.html\",\n        ftl_files=[\"mozorg/about/contact\", \"mozorg/about\"],\n    ),\n]\n</code></pre> <p>The system uses the first (or only) file in the list to determine which locales are active for that URL. You can pass a string or list of strings to the <code>ftl_files</code> argument. The files you specify can include the <code>.ftl</code> extension or not, and they will be combined with the list of default files which contain strings for global elements like navigation and footer. There will also be files for reusable widgets like the newsletter form, but those should always come last in the list.</p>"},{"location":"l10n/#using-the-class-based-view","title":"Using the class-based view","text":"<p>Bedrock includes a generic class-based view (CBV) that sets up l10n for you. If you need to do anything fancier than just render the page, then you can use this:</p> <pre><code>from lib.l10n_utils import L10nTemplateView\n\n\nclass AboutView(L10nTemplateView):\n    template_name = \"about.html\"\n    ftl_files = \"mozorg/about\"\n</code></pre> <p>Using that CBV will do the right things for l10n, and then you can override other useful methods (e.g. <code>get_context_data</code>) to do what you need. Also, if you do need to do anything fancy with the context, and you find that you need to dynamically set the fluent files list, you can easily do so by setting <code>ftl_files</code> in the context instead of the class attribute.</p> <pre><code>from lib.l10n_utils import L10nTemplateView\n\n\nclass AboutView(L10nTemplateView):\n    template_name = \"about.html\"\n\n    def get_context_data(self, **kwargs):\n        ctx = super().get_context_data(**kwargs)\n        ftl_files = [\"mozorg/about\"]\n        if request.GET.get(\"fancy\"):\n            ftl_files.append(\"fancy\")\n\n        ctx[\"ftl_files\"] = ftl_files\n        return ctx\n</code></pre> <p>A common case is needing to use <code>FTL (Fluent Translation List)</code> files when one template is used, but not with another. In this case you would have some logic to decide which template to use in the <code>get_template_names()</code> method. You can set the <code>ftl_files_map</code> class variable to a dict containing a map of template names to the list of FTL files for that template (or a single file name if that's all you need).</p> <pre><code># views.py\nfrom lib.l10n_utils import L10nTemplateView\n\n\n# class-based view example\nclass AboutView(L10nTemplateView):\n    ftl_files_map = {\"about_es.html\": [\"about_es\"], \"about_new.html\": [\"about\"]}\n\n    def get_template_names(self):\n        if self.request.locale.startswith(\"en\"):\n            template_name = \"about_new.html\"\n        elif self.request.locale.startswith(\"es\"):\n            template_name = \"about_es.html\"\n        else:\n            # FTL system not used\n            template_name = \"about.html\"\n\n        return [template_name]\n</code></pre> <p>If you need for your URL to use multiple Fluent files to determine the full list of active locales, for example when you are redesigning a page and have multiple templates in use for a single URL depending on locale, you can use the <code>activation_files</code> parameter. This should be a list of <code>FTL (Fluent Translation List)</code> filenames that should all be used when determining the full list of translations for the URL. Bedrock will gather the full list for each file and combine them into a single list so that the footer language switcher works properly.</p> <p>Another common case is that you want to keep using an old template for locales that haven't yet translated the strings for a new one. In that case you can provide an <code>old_template_name</code> to the class and include both that template and <code>template_name</code> in the <code>ftl_files_map</code>. Once you do this the view will use the template in <code>template_name</code> only for requests for an active locale for the FTL files you provided in the map.</p> <pre><code>from lib.l10n_utils import L10nTemplateView\n\n\nclass AboutView(L10nTemplateView):\n    template_name = \"about_new.html\"\n    old_template_name = \"about.html\"\n    ftl_files_map = {\n        \"about_new.html\": [\"about_new\", \"about_shared\"],\n        \"about.html\": [\"about\", \"about_shared\"],\n    }\n</code></pre> <p>In this example when the <code>about_new</code> FTL file is active for a locale, the <code>about_new.html</code> template will be rendered. Otherwise the <code>about.html</code> template would be used.</p>"},{"location":"l10n/#using-in-a-view-function","title":"Using in a view function","text":"<p>Lastly there's the good old function views. These should use <code>l10n_utils.render</code> directly to render the template with the context. You can use the <code>ftl_files</code> argument with this function as well.</p> <pre><code>from lib.l10n_utils import render\n\n\ndef about_view(request):\n    render(request, \"about.html\", {\"name\": \"Duder\"}, ftl_files=\"mozorg/about\")\n</code></pre>"},{"location":"l10n/#fluent-file-configuration","title":"Fluent File Configuration","text":"<p>In order for a Fluent file to be extracted through automation and sent out for localization, it must first be configured to go through one or more distinct pipelines. This is controlled via a set of configuration files:</p> <ul> <li>Vendor, locales translated by an agency, and paid for by Marketing (locales covered by staff are also included in this group).</li> <li>Pontoon, locales translated by Mozilla contributors.</li> <li>Special templates, for locales with dedicated templates that don't go through the localization process (not currently used).</li> </ul> <p>Each configuration file consists of a pre-defined set of locales for which each group is responsible for translating. The locales defined in each file should not be changed without first consulting the with L10n team, and such changes should not be a regular occurrence.</p> <p>To establish a localization strategy for a Fluent file, it needs to be included as a path in one or more configuration files. For example:</p> <pre><code>[[paths]]\n    reference = \"en/mozorg/mission.ftl\"\n    l10n = \"{locale}/mozorg/mission.ftl\"\n</code></pre> <p>You can read more about configuration files in the L10n Project Configuration docs.</p> <p>Important</p> <p>Path definitions in Fluent configuration files are not source order dependent. A broad definition using a wild card can invalidate all previous path definitions for example. Paths should be defined carefully to avoid exposing .ftl files to unintended locales.</p> <p>Using a combination of vendor and pontoon configuration offers a flexible but specific set of options to choose from when it comes to defining an l10n strategy for a page. The available choices are:</p> <ol> <li>Staff locales.</li> <li>Staff + select vendor locales.</li> <li>Staff + all vendor locales.</li> <li>Staff + vendor + pontoon.</li> <li>All pontoon locales (for non-marketing content only).</li> </ol> <p>When choosing an option, it's important to consider that vendor locales have a cost associated with them, and pontoon leans on the goodwill of our volunteer community. Typically, only non-marketing content should go through Pontoon for all locales. Everything that is marketing related should feature one of the staff/vendor/pontoon configurations.</p>"},{"location":"l10n/#fluent-file-activation","title":"Fluent File Activation","text":"<p>Fluent files are activated automatically when processed from the l10n team's repo into our own based on a couple of rules.</p> <ol> <li>If a fluent file has a group of required strings, all of those strings must be present in the translation in order for it to be activated.</li> <li>A translation must contain a minimum percent of the string IDs from the English file to be activated.</li> </ol> <p>If both of these conditions are met the locale is activated for that particular Fluent file. Any view using that file as its primary (first in the list) file will be available in that locale.</p>"},{"location":"l10n/#deactivation","title":"Deactivation","text":"<p>If the automated system activates a locale but we for some reason need to ensure that this page remains unavailable in that locale, we can add this locale to a list of deactivated locales in the metadata file for that <code>FTL (Fluent Translation List)</code> file. For example, say we needed to make sure that the <code>mozorg/mission.ftl</code> file remained inactive for German, even though the translation is already done. We would add <code>de</code> to the <code>inactive_locales</code> list in the <code>metadata/mozorg/mission.json</code> file:</p> <pre><code>{\n  \"active_locales\": [\n    \"de\",\n    \"fr\",\n    \"en-GB\",\n    \"en-US\",\n  ],\n  \"inactive_locales\": [\n    \"de\"\n  ],\n  \"percent_required\": 85\n}\n</code></pre> <p>This would ensure that even though <code>de</code> appears in both lists, it will remain deactivated on the site. We could just remove it from the active list, but automation would keep attempting to add it back, so for now this is the best solution we have, and is an indication of the full list of locales that have satisfied the rules.</p>"},{"location":"l10n/#alternate-rules","title":"Alternate Rules","text":"<p>It's also possible to change the percentage of string completion required for activation on a per-file basis. In the same metadata file as above, if a <code>percent_required</code> key exists in the JSON data (see above) it will be used as the minimum percent of string completion required for that file in order to activate new locales.</p> <p>Note</p> <p>Once a locale is activated for a Fluent file it will NOT be automatically deactivated, even if the rules change. If you need to deactivate a locale you should follow the Deactivation instructions.</p>"},{"location":"l10n/#activation-status","title":"Activation Status","text":"<p>You can determine and use the activation status of a Fluent file in a view to make some decisions; what template to render for example. The way you would do that is with the <code>ftl_file_is_active</code> function. For example:</p> <pre><code># views.py\nfrom lib.l10n_utils import L10nTemplateView\nfrom lib.l10n_utils.fluent import ftl_file_is_active\n\n\n# class-based view example\nclass AboutView(L10nTemplateView):\n    ftl_files_map = {\n        \"about.html\": [\"about\"],\n        \"about_new.html\": [\"about_new\", \"about\"],\n    }\n\n    def get_template_names(self):\n        if ftl_file_is_active(\"mozorg/about_new\"):\n            template_name = \"about_new.html\"\n        else:\n            template_name = \"about.html\"\n\n        return [template_name]\n\n\n# function view example\ndef about_view(request):\n    if ftl_file_is_active(\"mozorg/about_new\"):\n        template = \"mozorg/about_new.html\"\n        ftl_files = [\"mozorg/about_new\", \"mozorg/about\"]\n    else:\n        template = \"about.html\"\n        ftl_files = [\"mozorg/about\"]\n\n    render(request, template, ftl_files=ftl_files)\n</code></pre>"},{"location":"l10n/#active-locales","title":"Active Locales","text":"<p>To see which locales are active for a particular .ftl file you can either look in the metadata file for that .ftl file, which is the one with the same path but in the <code>metadata</code> folder instead of a locale folder in the www-l10n repository. Or if you'd like something a bit nicer looking and more convenient there is the <code>active_locales</code> management command:</p> <pre><code>$ ./manage.py l10n_update\n</code></pre> <pre><code>$ ./manage.py active_locales mozorg/mission\n</code></pre> <pre><code>There are 91 active locales for mozorg/mission.ftl:\n- af\n- an\n- ar\n- ast\n- az\n- be\n- bg\n- bn\n...\n</code></pre> <p>You get an alphabetically sorted list of all of the active locales for that .ftl file. You should run <code>./manage.py l10n_update</code> as shown above for the most accurate and up-to-date results.</p>"},{"location":"l10n/#string-extraction","title":"String extraction","text":"<p>The string extraction process for both new .ftl content and updates to existing .ftl content is handled through automation. On each commit to <code>main</code> a command is run that looks for changes to the <code>l10n/</code> directory. If a change is detected, it will copy those files into a new branch in mozilla-l10n/www-l10n and then a bot will open a pull request containing those changes. Once the pull request has been reviewed and merged by the L10n team, everything is done.</p> <p>To view the state of the latest automated attempt to open an L10N PR, see:</p> <ul> <li>Mozorg L10N PR action</li> </ul> <p>(We also just try to open L10N PRs every 3 hours, to catch any failed jobs that are triggered by a commit to <code>main</code>)</p>"},{"location":"l10n/#css","title":"CSS","text":"<p>If a localized page needs some locale-specific style tweaks, you can add the style rules to the page's stylesheet like this:</p> <pre><code>html[lang=\"it\"] #features li {\n  font-size: 20px;\n}\n\nhtml[dir=\"rtl\"] #features {\n  float: right;\n}\n</code></pre> <p>If a locale needs site-wide style tweaks, font settings in particular, you can add the rules to <code>/media/css/l10n/{{LANG}}/intl.css</code>. Pages on Bedrock automatically includes the CSS in the base templates with the <code>l10n_css</code> helper function. The CSS may also be loaded directly from other Mozilla sites with such a URL: <code>//mozorg.cdn.mozilla.net/media/css/l10n/{{LANG}}/intl.css</code>.</p> <p>Open Sans, the default font on mozilla.org, doesn't offer non-Latin glyphs. <code>intl.css</code> can have <code>@font-face</code> rules to define locale-specific fonts using custom font families as below:</p> <ul> <li>X-LocaleSpecific-Light: Used in combination with Open Sans Light. The font can come in 2 weights: normal and optionally bold</li> <li>X-LocaleSpecific: Used in combination with Open Sans Regular. The font can come in 2 weights: normal and optionally bold</li> <li>X-LocaleSpecific-Extrabold: Used in combination with Open Sans Extrabold. The font weight is 800 only</li> </ul> <p>Here's an example of <code>intl.css</code>:</p> <pre><code>@font-face {\n  font-family: X-LocaleSpecific-Light;\n  font-weight: normal;\n  font-display: swap;\n  src: local(mplus-2p-light), local(Meiryo);\n}\n\n@font-face {\n  font-family: X-LocaleSpecific-Light;\n  font-weight: bold;\n  font-display: swap;\n  src: local(mplus-2p-medium), local(Meiryo-Bold);\n}\n\n@font-face {\n  font-family: X-LocaleSpecific;\n  font-weight: normal;\n  font-display: swap;\n  src: local(mplus-2p-regular), local(Meiryo);\n}\n\n@font-face {\n  font-family: X-LocaleSpecific;\n  font-weight: bold;\n  font-display: swap;\n  src: local(mplus-2p-bold), local(Meiryo-Bold);\n}\n\n@font-face {\n  font-family: X-LocaleSpecific-Extrabold;\n  font-weight: 800;\n  font-display: swap;\n  src: local(mplus-2p-black), local(Meiryo-Bold);\n}\n</code></pre> <p>Localizers can specify locale-specific fonts in one of the following ways:</p> <ul> <li>Choose best-looking fonts widely used on major platforms, and specify those with the <code>src: local(name)</code> syntax</li> <li>Find a best-looking free Web font, add the font files to <code>/media/fonts/</code>, and specify those with the <code>src: url(path)</code> syntax</li> <li>Create a custom Web font to complement missing glyphs in Open Sans, add the font files to <code>/media/fonts/l10n/</code>, and specify those with the <code>src: url(path)</code> syntax. M+ 2c offers various international glyphs and looks similar to Open Sans, while Noto Sans is good for the bold and italic variants. You can create subsets of these alternative fonts in the WOFF and WOFF2 formats using a tool found on the Web. See Bug 1360812 for the Fulah (ff) locale's example</li> </ul> <p>Developers should use the <code>.open-sans</code> mixin instead of <code>font-family: 'Open Sans'</code> to specify the default font family in CSS. This mixin has both Open Sans and X-LocaleSpecific so locale-specific fonts, if defined, will be applied to localized pages. The variant mixins, <code>.open-sans-light</code> and <code>.open-sans-extrabold</code>, are also available.</p>"},{"location":"l10n/#all","title":"All","text":""},{"location":"l10n/#locale-specific-templates","title":"Locale-specific Templates","text":"<p>While the <code>ftl_has_messages</code> template function is great in small doses, it doesn't scale particularly well. A template filled with conditional copy can be difficult to comprehend, particularly when the conditional copy has associated CSS and/or JavaScript.</p> <p>In instances where a large amount of a template's copy needs to be changed, or when a template has messaging targeting one particular locale, creating a locale-specific template may be a good choice.</p> <p>Locale-specific templates function simply by naming convention. For example, to create a version of <code>/firefox/new.html</code> specifically for the <code>de</code> locale, you would create a new template named <code>/firefox/new.de.html</code>. This template can either extend <code>/firefox/new.html</code> and override only certain blocks, or be entirely unique.</p> <p>When a request is made for a particular page, bedrock's rendering function automatically checks for a locale-specific template, and, if one exists, will render it instead of the originally specified (locale-agnostic) template.</p> <p>Note</p> <p>Creating a locale-specific template for en-US was not possible when this feature was introduced, but it is now. So you can create your en-US-only template and the rest of the locales will continue to use the default.</p>"},{"location":"l10n/#specifying-active-locales-in-views","title":"Specifying Active Locales in Views","text":"<p>Normally we rely on activation tags in our translation files (.lang files) to determine in which languages a page will be available. This will almost always be what we want for a page. But sometimes we need to explicitly state the locales available for a page. The <code>impressum</code> page for example is only available in German and the template itself has German hard-coded into it since we don't need it to be translated into any other languages. In cases like these we can send a list of locale codes with the template context and it will be the final list. This can be accomplished in a few ways depending on how the view is coded.</p> <p>For a plain view function, you can simply pass a list of locale codes to <code>l10n_utils.render</code> in the context using the name <code>active_locales</code>. This will be the full list of available translations. Use <code>add_active_locales</code> if you want to add languages to the existing list:</p> <pre><code>def french_and_german_only(request):\n    return l10n_utils.render(request, \"home.html\", {\"active_locales\": [\"de\", \"fr\"]})\n</code></pre> <p>If you don't need a custom view and are just using the <code>page()</code> helper function in your <code>urls.py</code> file, then you can similarly pass in a list:</p> <pre><code>page(\"about\", \"about.html\", active_locales=[\"en-US\", \"es-ES\"]),\n</code></pre> <p>Or if your view is even more fancy and you're using a Class-Based-View that inherits from <code>LangFilesMixin</code> (which it must if you want it to be translated) then you can specify the list as part of the view Class definition:</p> <pre><code>class MyView(LangFilesMixin, View):\n    active_locales = [\"zh-CN\", \"hi-IN\"]\n</code></pre> <p>Or in the <code>urls.py</code> when using a CBV:</p> <pre><code>url(r\"about/$\", MyView.as_view(active_locales=[\"de\", \"fr\"])),\n</code></pre> <p>The main thing to keep in mind is that if you specify <code>active_locales</code> that will be the full list of localizations available for that page. If you'd like to add to the existing list of locales generated from the lang files then you can use the <code>add_active_locales</code> name in all of the same ways as <code>active_locales</code> above. It's a list of locale codes that will be added to the list already available. This is useful in situations where we would have needed the l10n team to create an empty .lang file with an active tag in it because we have a locale-specific-template with text in the language hard-coded into the template and therefore do not otherwise need a .lang file.</p>"},{"location":"l10n/#about-l10n-integrations","title":"About L10N integrations","text":"<p>Bedrock manages an l10n pipeline that moves the l10n data (fluent <code>.ftl</code> files) between the l10n team and bedrock. This section describes how that works.</p> <ol> <li>FILE SETUP</li> </ol> <p>The source for Fluent files currently is <code>./l10n/</code>.</p> <p>Here's a summary of the files within this directory:</p> <pre><code>./l10n/en/  # This is where source Fluent templates go\n./l10n/configs/pontoon.toml  # Config if using community/Pontoon translations\n./l10n/configs/vendor.toml  # Config if using a paid-for translation service such as Smartling\n./l10n/configs/special-templates.toml   # Only needed to exclude certain files from all community AND vendor translation, e.g. we use staff translation only\n\n./l10n/l10n-pontoon.toml  # Entrypoint for community localization.\n./l10n/l10n-vendor.toml  # Entrypoint for vendor and staff localization\n\n./data/l10n-team/  # populated via a git sync using data FROM the l10n team\n</code></pre> <p>The root <code>.toml</code> files point to the ones in <code>/configs/</code> and are a 'gateway' through which we specify which config files are relevant to which translation strategy (community or vendor - or neither if it's staff-only translation).</p> <ol> <li>REPO SETUP</li> </ol> <p>There are two repos, to hold the translation files as part of the pipeline.</p> <ul> <li>A repo in where the files are sent to for the L10N team's automation to pick up. For example, Mozorg uses <code>github.com/mozilla-l10n/www-l10n/</code>.</li> <li>An optional repo where files are post-processed following translation. For example, Mozorg uses <code>github.com/mozmeao/www-l10n/</code>.</li> </ul> <p>Important</p> <p>This repo is optional if not using Pontoon/community translations. Why? If the translations are done by the community (via Pontoon), there is a possibility that not enough of the strings will be translated in order to render the content in the relevant locale. We run a <code>CI (Continuous Integration)</code> task to determine whether a locale has enough translated strings to be considered 'active'. If we used a vendor entirely, we would expect all locales to be 100% translated.</p> <ol> <li>CI SETUP</li> </ol> <p>Details of how MozMarRobot is hooked are best gleaned from looking at <code>https://gitlab.com/mozmeao/www-fluent-update</code>.</p> <p>In short, once new translations land in the string-source repo (e.g. <code>github.com/mozilla-l10n/www-l10n</code>) they are cloned over to the activation-check repo <code>github.com/mozmeao/www-l10n/</code> by CI and later pulled into Bedrock from there.</p> <ol> <li>CONFIGURATION SETTINGS.</li> </ol> <p>There are many settings in <code>settings/base.py</code> that help bedrock know what remote repos and local folders to use. Search this file for settings starting with <code>FLUENT_</code> to find them.</p> <ol> <li>L10N UPDATE SCRIPT.</li> </ol> <p>Uploading strings for translation</p> <p>Uploading <code>en</code>-locale source strings from Bedrock to the <code>github.com/mozilla-l10n/</code> repo is handled by <code>bedrock/bin/open-ftl-pr.sh</code>.</p> <p>See the Github workflow in <code>.github/workflows/</code> for where this is triggered.</p> <p>Downloading translated strings</p> <p>The script <code>bedrock/lib/l10n_utils/management/commands/l10n_update.py</code> will pull down the appropriate translations.</p>"},{"location":"legal-docs/","title":"Legal Docs","text":""},{"location":"legal-docs/#legaldocs","title":"Legal Docs","text":"<p>Privacy notices and their applicable translations are markdown files managed by the legal team in the legal-docs repository.</p> <p>When the markdown files are imported into bedrock they are parsed using the default python markdown library and BeautifulSoup. BeautifulSoup allows content selection and manipulation using CSS selectors.</p> <p>For example the code:</p> <pre><code>{{ doc.select('body &gt; section &gt; [datetime] ~ p')|join|safe }}\n</code></pre> <p>means something like:</p> <p>From the document, find the <code>body</code> element, then find the <code>section</code> element that is its direct descendant, then look for a direct descendant with a <code>datetime</code> attribute, select all <code>p</code> that are its siblings. Join that array of data, and then print it without filtering it for unsafe characters.</p> <p>If you would like to see the structure of the html you're working with, you can print it all to the page with <code>{{ doc.select('body') }}</code>.</p>"},{"location":"legal-docs/#templates","title":"Templates","text":"<p>There are three templates:</p> <ul> <li>base-notice</li> <li>base-notice-headings</li> <li>base-notice-paragraphs</li> </ul>"},{"location":"legal-docs/#base-notice","title":"base-notice","text":"<p>This is a basic template that will extract a lead-in section and add the appropriate classes to style lists. It will print the rest of the privacy notice un-altered.</p>"},{"location":"legal-docs/#base-notice-headings","title":"base-notice-headings","text":"<p>This template is preferred for longer privacy notices. It collapses content under h3 headings.</p> <p>The V1.2 subscription services notice is a good example of this template. It prefers content formatted like:</p> <pre><code># Start the document with an h1, it will be used for the page title and first heading\n\nVersion 1.2, Effective February 5, 2024\n{: datetime=\"2024-02-05\" }\n\n## The first heading will be the heading in the lead-in section\n\nParagraphs after the first heading but before later headings will be displayed as part of the lead-in section.\n\nA line will appear under the last paragraph of the lead-in.\n\n## This will be displayed as an h2 heading and the sibling elements will not be collapsed until an h3 is encountered\n\nThis paragraph will be visible\n\n### This will be displayed as an h3 heading and will serve as a toggle for all its siblings until the next h3 {: provide-an-id }\n\n* This will be a bulleted list that is collapsed under the h3 heading\n\nThis will be a paragraph that is collapsed under the h3 heading\n\n### Footnote {: footnote }\n\nIf a section contains a heading with an ID of `footnote` the section will be extracted and output as the last thing on the page.\n\nNone of the elements in this section will be collapsed.\n</code></pre>"},{"location":"legal-docs/#base-notice-paragraphs","title":"base-notice-paragraphs","text":"<p>This is an older style template that we would like to phase out in favour of the heading template. It assumes the notice will be formatted in a series of sections each with an introductory paragraph and then bulleted lists of further information. When the notice is rendered, the bulleted lists are collapsed behind a \"learn more\" button.</p>"},{"location":"mozilla-accounts/","title":"Mozilla account helpers","text":""},{"location":"mozilla-accounts/#mozilla-accounts-helpers","title":"Mozilla accounts helpers","text":"<p>Note</p> <p>Since a rebranding in October 2023, we now refer to \"Mozilla accounts\" in our web pages instead of \"Firefox accounts\". This rebranding is so far superficial, and sign up flows still go to <code>accounts.firefox.com</code>. Because of this, our internal code and helpers still use <code>FxA</code> or <code>fxa</code> as a common abbreviation. However the language used around them should now be \"Mozilla accounts\" going forward.</p> <p>Marketing pages often promote the creation of a Mozilla account as a common call to action (CTA). This is typically accomplished using either a sign-up form, or a prominent link/button. Other products such as Mozilla VPN use similar account auth flows to manage subscriptions. To accomplish these tasks, bedrock templates can take advantage of a series of Python helpers which can be used to standardize product referrals, and make supporting these auth flows easier.</p> <p>Note</p> <p>See the attribution docs (Mozilla accounts attribution) for more a detailed description of the analytics functions these helpers provide.</p>"},{"location":"mozilla-accounts/#mozilla-account-sign-up-form","title":"Mozilla account sign-up form","text":"<p>Use the <code>fxa_email_form</code> macro to display a Mozilla account sign-up form on a page.</p>"},{"location":"mozilla-accounts/#usage","title":"Usage","text":"<p>To use the form in a Jinja template, first import the <code>fxa_email_form</code> macro:</p> <pre><code>{% from \"macros.html\" import fxa_email_form with context %}\n</code></pre> <p>The form can then be invoked using:</p> <pre><code>{{ fxa_email_form(entrypoint='mozilla.org-firefox-accounts') }}\n</code></pre> <p>The macro's respective JavaScript and CSS dependencies should also be imported in the page:</p> <p>Javascript:</p> <pre><code>import FxaForm from './path/to/fxa-form.es6.js';\n\nFxaForm.init();\n</code></pre> <p>The above JS is also available as a pre-compiled bundle, which can be included directly in a template:</p> <pre><code>{{ js_bundle('fxa_form') }}\n</code></pre> <p>CSS:</p> <pre><code>@import '../path/to/fxa-form';\n</code></pre> <p>The JavaScript files will automatically handle things such as adding metrics parameters for Firefox desktop browsers. The CSS file contains some default styling for the sign-up form.</p>"},{"location":"mozilla-accounts/#configuration","title":"Configuration","text":"<p>The sign-up form macro accepts the following parameters (* indicates a required parameter)</p> &gt; Parameter name &gt; Definition &gt; Format &gt; Example &gt; entrypoint* Unambiguous identifier for which page of the site is the referrer. mozilla.org-directory-page 'mozilla.org-firefox-accounts' &gt; entrypoint_experiment Used to identify experiments. Experiment ID 'whatsnew-headlines' &gt; entrypoint_variation Used to track page variations in multivariate tests. Usually just a number or letter but could be a short keyword. Variant identifier 'b' &gt; style An optional parameter used to invoke an alternatively styled page at accounts.firefox.com. String &gt; 'trailhead' &gt; class_name Applies a CSS class name to the form. Defaults to: 'fxa-email-form' String 'fxa-email-form' &gt; form_title The main heading to be used in the form (optional with no default). Localizable string 'Join Firefox' . &gt; intro_text Introductory copy to be used in the form. Defaults to a well localized string. Localizable string 'Enter your email address to get started.' . &gt; button_text Button copy to be used in the form. Defaults to a well localized string. Localizable string 'Sign Up' . &gt; button_class CSS class names to be applied to the submit button. String of one or more CSS class names 'mzp-c-button mzp-t-primary mzp-t-product' &gt; utm_campaign Used to identify specific marketing campaigns. Defaults to <code>fxa-embedded-form</code> Campaign name prepended to default value 'trailhead-fxa-embedded-form' &gt; utm_term Used for paid search keywords. Brief keyword 'existing-users' &gt; utm_content Declared when more than one piece of content (on a page or at a URL) links to the same place, to distinguish between them. Description of content, or name of experiment treatment 'get-the-rest-of-firefox' <p>Invoking the macro will automatically include a set of default <code>UTM (Urchin Tracking Module)</code> parameters as hidden form input fields:</p> <ul> <li><code>utm_source</code> is automatically assigned the value of the <code>entrypoint</code> parameter.</li> <li><code>utm_campaign</code> is automatically set as the value of <code>fxa-embedded-form</code>. This can be prefixed with a custom value by passing a <code>utm_campaign</code> value to the macro. For example, <code>utm_campaign='trailhead'</code> would result in a value of <code>trailhead-fxa-embedded-form</code>.</li> <li><code>utm_medium</code> is automatically set as the value of <code>referral</code>.</li> </ul> <p>Note</p> <p>When signing into a Mozilla account using this form on a Firefox Desktop browser, it will also activate the Sync feature.</p>"},{"location":"mozilla-accounts/#mozilla-account-links","title":"Mozilla account links","text":"<p>Use the <code>fxa_button</code> helper to create a <code>CTA (Call To Action)</code> button or link to https://accounts.firefox.com/.</p>"},{"location":"mozilla-accounts/#usage_1","title":"Usage","text":"<pre><code>{{ fxa_button(entrypoint='mozilla.org-firefox-sync-page', button_text='Sign In') }}\n</code></pre> <p>Note</p> <p>There is also a <code>fxa_link_fragment</code> helper which will construct a valid <code>href</code> property. This is useful when constructing an inline link inside a paragraph, for example.</p> <p>Note</p> <p>When signing into a Mozilla account using this link on a Firefox Desktop browser, it will also activate the Sync feature.</p> <p>For more information on the available parameters, read the \"Common Parameters\" section further below.</p>"},{"location":"mozilla-accounts/#mozilla-monitor-links","title":"Mozilla Monitor links","text":"<p>Use the <code>monitor_fxa_button</code> helper to link to https://monitor.mozilla.org/ via a Mozilla accounts auth flow.</p>"},{"location":"mozilla-accounts/#usage_2","title":"Usage","text":"<pre><code>{{ monitor_fxa_button(entrypoint=_entrypoint, button_text='Sign Up for Monitor') }}\n</code></pre> <p>For more information on the available parameters, read the \"Common Parameters\" section further below.</p>"},{"location":"mozilla-accounts/#pocket-links","title":"Pocket links","text":"<p>Use the <code>pocket_fxa_button</code> helper to link to https://getpocket.com/ via a Mozilla accounts auth flow.</p>"},{"location":"mozilla-accounts/#usage_3","title":"Usage","text":"<pre><code>{{ pocket_fxa_button(entrypoint='mozilla.org-firefox-pocket', button_text='Try Pocket Now', optional_parameters={'s': 'ffpocket'}) }}\n</code></pre> <p>For more information on the available parameters, read the \"Common Parameters\" section below.</p>"},{"location":"mozilla-accounts/#common-parameters","title":"Common Parameters","text":"<p>The <code>fxa_button</code>, <code>pocket_fxa_button</code>, and <code>monitor_fxa_button</code> helpers all support the same standard parameters:</p> Parameter name Definition Format Example entrypoint* Unambiguous identifier for which page of the site is the referrer. This also serves as a value for 'utm_source'. 'mozilla.org-firefox-pocket' 'mozilla.org-firefox-pocket' button_text* The button copy to be used in the call to action. Localizable string 'Try Pocket Now' class_name A class name to be applied to the link (typically for styling with CSS). String of one or more class names 'pocket-main-cta-button' is_button_class A boolean value that dictates if the <code>CTA (Call To Action)</code> should be styled as a button or a link. Defaults to 'True'. Boolean True or False include_metrics A boolean value that dictates if metrics parameters should be added to the button href. Defaults to 'True'. Boolean True or False optional_parameters An dictionary of key value pairs containing additional parameters to append the the href. Dictionary {'s': 'ffpocket'} optional_attributes An dictionary of key value pairs containing additional data attributes to include in the button. Dictionary {'data-cta-text': 'Try Pocket Now', 'data-cta-type': 'pocket','data-cta-position': 'primary'} <p>Note</p> <p>The <code>fxa_button</code> helper also supports an additional <code>action</code> parameter, which accepts the values <code>signup</code>, <code>signin</code>, and <code>email</code> for configuring the type of authentication flow.</p>"},{"location":"mozilla-accounts/#vpn-helpers","title":"Mozilla <code>VPN (Virtual Private Network)</code> Links","text":"<p>Use the <code>vpn_subscribe_link</code> helpers to create a <code>VPN (Virtual Private Network)</code> subscription link via a Mozilla accounts auth flow.</p>"},{"location":"mozilla-accounts/#usage_4","title":"Usage","text":"<pre><code>{{ vpn_subscribe_link(entrypoint='www.mozilla.org-vpn-product-page', link_text='Get Mozilla VPN') }}\n</code></pre>"},{"location":"mozilla-accounts/#common-vpn-virtual-private-network-parameters","title":"Common <code>VPN (Virtual Private Network)</code> Parameters","text":"<p>Both helpers for Mozilla <code>VPN (Virtual Private Network)</code> support the same parameters (* indicates a required parameter)</p> &gt; Parameter name &gt; Definition &gt; Format &gt; Example &gt; entrypoint* Unambiguous identifier for which page of the site is the referrer. This also serves as a value for 'utm_source'. 'www.mozilla.org-page-name' 'www.mozilla.org-vpn-product-page' &gt; link_text* The link copy to be used in the call to action. Localizable string 'Get Mozilla VPN' &gt; class_name A class name to be applied to the link (typically for styling with CSS). String of one or more class names 'vpn-button' &gt; lang Page locale code. Used to query the right subscription plan ID in conjunction to country code. Locale string 'de' &gt; country_code Country code provided by the <code>CDN (Content Delivery Network)</code>. Used to determine the appropriate subscription plan ID. Two digit, uppercase country code 'DE' &gt; optional_parameters An dictionary of key value pairs containing additional parameters to append the the href. Dictionary {'utm_campaign': 'vpn-product-page'} &gt; optional_attributes An dictionary of key value pairs containing additional data attributes to include in the button. Dictionary {'data-cta-text': 'VPN Sign In', 'data-cta-type': 'fxa-vpn', 'data-cta-position': 'navigation'} <p>The <code>vpn_subscribe_link</code> helper has an additional <code>plan</code> parameter to support linking to different subscription plans.</p> &gt; Parameter name &gt; Definition &gt; Format &gt; Example &gt; plan Subscription plan ID. Defaults to 12-month plan. '12-month' '12-month' or 'monthly'"},{"location":"mozilla-accounts/#firefox-sync-and-uitour","title":"Firefox Sync and UITour","text":"<p>Since Firefox 80 the accounts link and email form macros use <code>UITour&lt;ui-tour&gt;</code> to show the Mozilla accounts page and log the browser into Sync or an account. For non-Firefox browsers or if UITour is not available, the flow uses normal links that allow users to log into the Mozilla accounts website only, without connecting the Firefox Desktop client. This transition was introduced to later migrate Firefox Desktop to an OAuth based client authentication flow.</p> <p>The script that handles this logic is <code>/media/js/base/fxa-link.js</code>, and will automatically apply to any link with a <code>js-fxa-cta-link</code> class name. The current code automatically detects if you are in the supported browser for this flow and updates links to drive them through the UITour API. The UITour <code>showFirefoxAccounts</code> action supports flow id parameters, <code>UTM (Urchin Tracking Module)</code> parameters and the email data field.</p>"},{"location":"mozilla-accounts/#testing-sign-up-flows","title":"Testing Sign-up Flows","text":"<p>Testing the Mozilla account sign-up flows on a non-production environment requires some additional configuration.</p> <p>Configuring bedrock:</p> <p>Set the following in your local <code>.env</code> file:</p> <pre><code>FXA_ENDPOINT=https://accounts.stage.mozaws.net/\n</code></pre> <p>For Mozilla <code>VPN (Virtual Private Network)</code> links you can also set:</p> <pre><code>VPN_ENDPOINT=https://stage.guardian.nonprod.cloudops.mozgcp.net/\nVPN_SUBSCRIPTION_URL=https://accounts.stage.mozaws.net/\n</code></pre> <p>Note</p> <p>The above values for staging are already set by default when <code>Dev=True</code>, which will also apply to demo servers. You may only need to configure your <code>.env</code> file if you wish to change a setting to something else.</p>"},{"location":"newsletters/","title":"Newsletters","text":""},{"location":"newsletters/#newsletters","title":"Newsletters","text":"<p>Bedrock includes support for signing up for and managing subscriptions and preferences for Mozilla newsletters.</p> <p>Many pages have a form to sign-up for the default newsletters, \"Mozilla Foundation\" and \"Firefox &amp; You\". Other pages have more specific sign up forms, such as the contribute page, or Mozilla VPN wait-list page.</p>"},{"location":"newsletters/#features","title":"Features","text":"<ul> <li>Ability to subscribe to a newsletter from a web form. Many pages on the site might include this form.</li> <li>Whole pages devoted to subscribing to one newsletter, often with custom text, branding, and layout.</li> <li>Newsletter preference center - allow user to change their email preferences (e.g. language, HTML vs. text), as well as which newsletters they're subscribed to, etc. Access is limited by requiring a user-specific token in the URL (it's a UUID). The full URL is included as a link in each newsletter sent to the user. Users can also recover a link to their token by visiting the newsletter recovery page and entering their email address.</li> </ul>"},{"location":"newsletters/#newsletters_1","title":"Newsletters","text":"<p>Newsletters have a variety of characteristics. Some of these are implemented in Bedrock, others are transparent to Bedrock but implemented in the basket back-end that provides our interface to the newsletter vendor.</p> <ul> <li> <p>Public name - the name that is displayed to users, e.g. \"Firefox Weekly Tips\".</p> </li> <li> <p>Internal name - a short string that is used internal to Bedrock and basket to identify a newsletter. Typically these are lowercase strings of words joined by hyphens, e.g. \"firefox-tips\". This is what we send to basket to identify a newsletter, e.g. to subscribe a user to it.</p> </li> <li> <p>Show publicly - pages like the newsletter preferences center show a list of unsubscribed newsletters and allow subscribing to them. Some newsletters aren't included in that list by default (though they are shown if the user is already subscribed, to let them unsubscribe). If the user has a Mozilla account, there are also some other related newsletters that will always be shown in the list.</p> </li> <li> <p>Languages - newsletters are available in a particular set of languages. Typically when subscribing to a newsletter, a user can choose their preferred language. We should try not to let them subscribe to a newsletter in a language that it doesn't support.</p> <p>The backend only stores one language for the user though, so whenever the user submits one of our forms, whatever language they last submitted is what is saved for their preference for everything.</p> </li> <li> <p>Welcome message - each newsletter can have a canned welcome message that is sent to a user when they subscribe to it. Newsletters should have both an HTML and a text version of this.</p> </li> <li> <p>Drip campaigns - some newsletters implement so-called drip campaigns, in which a series of canned messages are dribbled out to the user over a period of time. E.g. 1 week after subscribing, they might get message 1; a week later, message 2, and so on until all the canned messages have been sent.</p> <p>Because drip campaigns depend on the sign-up date of the user, we're careful not to accidentally change the sign-up date, which could happen if we sent redundant subscription commands to our backend.</p> </li> </ul>"},{"location":"newsletters/#bedrock-and-basket","title":"Bedrock and Basket","text":"<p>Bedrock is the user-facing web application. It presents an interface for users to subscribe and manage their subscriptions and preferences. It does not store any information. It gets all newsletter and user-related information, and makes updates, via web requests to the Basket server. These requests are made typically made by Bedrock's front-end JavaScript modules.</p> <p>The Basket server implements an HTTP API for the newsletters. The front-end (Bedrock) can make calls to it to retrieve or change users' preferences and subscriptions, and information about the available newsletters. Basket implements some of that itself, and other functions by calling the newsletter vendor's API. Details of that are outside the scope of this document, but it's worth mentioning that both the user token (UUID) and the newsletter internal name mentioned above are used only between Bedrock and Basket.</p> <p>See the Basket docs for more information.</p>"},{"location":"newsletters/#urls","title":"URLs","text":"<p>Here are a few important mozorg newsletter URLs. Some of these were established before Bedrock came along, and so are unlikely to be changed.</p> <ul> <li><code>/newsletter/</code> - Subscribe to 'mozilla-and-you' newsletter (public name: \"Firefox &amp; You\")</li> <li><code>/newsletter/existing/{USERTOKEN}/</code> - User management of their preferences and subscriptions.</li> <li><code>/newsletter/confirm/{USERTOKEN}/</code> - URL someone lands on when they confirm their email address after initially subscribing.</li> <li><code>/newsletter/country/{USERTOKEN}/</code> - Allows users to change their country.</li> <li><code>/newsletter/recovery/</code> - Allows users to recover a link containing their token so they can manage their subscriptions.</li> <li><code>/newsletter/updated/</code> - A page users are redirected to after updating their details, or unsubscribing.</li> </ul> <p>Note</p> <p>URLs that contain <code>{USERTOKEN}</code> will have their path rewritten on page load so that they no longer contain the token e.g. <code>/newsletter/existing/{USERTOKEN}/</code> will be rewritten to just <code>/newsletter/existing/</code>. This helps to prevent accidental sharing of user tokens in URLS and also against referral information leakage.</p>"},{"location":"newsletters/#footer-sign-up","title":"Footer sign-up","text":"<p>In some common templates, you can customize the footer sign-up form by overriding the email_form template block. For example, to have no sign-up form:</p> <pre><code>{% block email_form %}{% endblock %}\n</code></pre> <p>The default is:</p> <pre><code>{% block email_form %}{{ email_newsletter_form() }}{% endblock %}\n</code></pre> <p>This will render a sign-up for \"Firefox &amp; You\". You can pass parameters to the macro <code>email_newsletter_form</code> to change that. For example, the <code>newsletters</code> parameter controls which newsletter is signed up for, and <code>title</code> can override the text:</p> <pre><code>{% block email_form %}\n    {{ email_newsletter_form('app-dev',\n                             'Sign up for more news about the Firefox Marketplace.') }}\n{% endblock %}\n</code></pre> <p>The <code>newsletters</code> parameter, the first positional argument, can be either a list of newsletter IDs or a comma separated list of newsletters IDs:</p> <pre><code>{% block email_form %}\n    {{ email_newsletter_form('mozilla-foundation, mozilla-and-you') }}\n{% endblock %}\n</code></pre> <p>Pages can control whether country or language fields are included by passing <code>include_language=[True|False]</code> and/or <code>include_country=[True|False]</code>.</p>"},{"location":"pipeline/","title":"Continuous Integration & Deployment","text":""},{"location":"pipeline/#pipeline","title":"Continuous Integration &amp; Deployment","text":"<p>Bedrock runs a series of automated tests as part of continuous integration workflow and deployment pipeline. You can learn more about each of the individual test suites by reading their respective pieces of documentation:</p> <ul> <li>Python unit tests (see Run the tests).</li> <li>JavaScript unit tests (see Front-end testing).</li> <li>Redirect tests (see Testing redirects).</li> <li>Functional tests (see Front-end testing).</li> </ul>"},{"location":"pipeline/#deployed-site-urls","title":"Deployed site URLs","text":""},{"location":"pipeline/#dev","title":"Dev","text":"<ul> <li>Mozorg URL: https://www-dev.allizom.org/</li> <li>Bedrock locales: dev repo</li> <li>Bedrock Git branch: main, deployed on git push</li> <li>Firefox download URL: https://bouncer-bouncer.stage.mozaws.net/</li> </ul>"},{"location":"pipeline/#staging","title":"Staging","text":"<ul> <li>Mozorg URL: https://www.allizom.org/</li> <li>Bedrock locales: prod repo</li> <li>Bedrock Git branch: stage, deployed on git push</li> <li>Firefox download URL: https://download.mozilla.org/</li> </ul>"},{"location":"pipeline/#production","title":"Production","text":"<ul> <li>Mozorg URL: https://www.mozilla.org/</li> <li>Bedrock locales: prod repo</li> <li>Bedrock Git branch: prod, deployed on git push with date-tag</li> <li>Firefox download URL: https://download.mozilla.org/</li> </ul> <p>Note</p> <p>By default, the Demo servers on GCP point to the Bouncer Dev service at https://dev.bouncer.nonprod.webservices.mozgcp.net/ To change this, you will have adjust GCP Secrets - see the demo sites docs</p> <p>You can check the currently deployed git commit by checking /revision.txt on any of these URLs.</p>"},{"location":"pipeline/#tests-in-the-lifecycle-of-a-change","title":"Tests in the lifecycle of a change","text":"<p>Below is an overview of the tests during the lifecycle of a change to bedrock:</p>"},{"location":"pipeline/#local-development","title":"Local development","text":"<p>The change is developed locally, and page specific integration tests can be executed against a locally running instance of the application. If testing changes to the website as a whole is required, then pushing changes to the special <code>run-integration-tests</code> branch (see below) is much faster than running the full test suite locally.</p>"},{"location":"pipeline/#pull-request","title":"Pull request","text":"<p>Once a pull request is submitted, a Unit Tests Github Action will run both the Python and JavaScript unit tests, as well as the suite of redirect headless HTTP(s) response checks.</p>"},{"location":"pipeline/#push-to-main-branch","title":"Push to main branch","text":"<p>Whenever a change is pushed to the main branch, a new image is built and deployed to the dev environment, and the full suite of headless and UI tests are run. This is handled by the pipeline, and is subject to change according to the settings in the Github Action workflow defined in <code>bedrock/.github/workflows/integration_tests.yml</code>.</p> <p>The tests for the dev environment are currently configured as follows:</p> <ul> <li>Firefox, Chromium, and Webkit headless browsers via Playwright.</li> <li>Chrome (latest) via local Selenium grid.</li> <li>Firefox (latest) via local Selenium grid.</li> <li>Internet Explorer 11 (smoke tests) via Sauce Labs.</li> <li>Headless tests.</li> </ul> <p>Note</p> <p>The deployment workflow runs like this</p> <ol> <li> <p>A push to the <code>main</code>/<code>stage</code>/<code>prod</code>/<code>run-integration-tests</code> branch of <code>mozilla/bedrock</code> triggers a webhook ping to the (private) <code>mozilla-sre-deploy/deploy-bedrock</code> repo.</p> </li> <li> <p>A Github Action (GHA) in <code>mozilla-sre-deploy/deploy-bedrock</code> builds a \"release\"-ready Bedrock container image, which it stores in a private container registry (private because our infra requires container-image access to be locked down). Using the same commit, the workflow also builds an equivalent set of public Bedrock container images, which are pushed to Docker Hub.</p> </li> <li> <p>The GHA deploys the relevant container image to the appropriate environment.</p> </li> <li> <p>The GHA pings a webhook back in <code>mozilla/bedrock</code> to run integration tests against the environment that has just been deployed.</p> </li> </ol>"},{"location":"pipeline/#push-to-stage-branch","title":"Push to stage branch","text":"<p>Whenever a change is pushed to the stage branch, a production docker image is built, published to Docker Hub, and deployed to a public staging environment. Once the new image is deployed, the full suite of UI tests is run against it again, but this time with the addition of the <code>headless download tests</code>.</p>"},{"location":"pipeline/#tagged-commit","title":"Push to prod branch (tagged)","text":"<p>When a tagged commit is pushed to the <code>prod</code> branch, a production container image (private, see above) is built, and a set of public images is also built and pushed to Docker Hub if needed (usually this will have already happened as a result of a push to the <code>main</code> or <code>stage</code> branch). The production image is deployed to each production deployment.</p> <p>Push to prod cheat sheet</p> <ol> <li> <p>Check out the <code>main</code> branch</p> </li> <li> <p>Make sure the <code>main</code> branch is up to date with <code>mozilla/bedrock main</code></p> </li> <li> <p>Check that dev deployment is green:</p> <ol> <li>View the Integration Tests Github Action and look at the run labelled <code>Run Integration tests for main</code></li> </ol> </li> <li> <p>Check that stage deployment is also green (<code>Run Integration tests for stage</code>)</p> </li> <li> <p>Tag and push the deployment by running <code>bin/tag-release.sh --push</code></p> </li> </ol> <p>Note</p> <p>By default the <code>tag-release.sh</code> script will push to the <code>origin</code> git remote. If you'd like for it to push to a different remote name you can either pass in a <code>-r</code> or <code>--remote</code> argument, or set the <code>MOZ_GIT_REMOTE</code> environment variable. So the following are equivalent:</p> <pre><code>bin/tag-release.sh --push -r mozilla\n</code></pre> <pre><code>MOZ_GIT_REMOTE=mozilla bin/tag-release.sh --push\n</code></pre> <p>And if you'd like to just tag and not push the tag anywhere, you may omit the <code>--push</code> parameter.</p>"},{"location":"pipeline/#what-is-currently-deployed","title":"What Is Currently Deployed?","text":"<p>You can look at the git log of the <code>main</code> branch to find the last commit with a date-tag on it (e.g. 2022-05-05): this commit will be the last one that was deployed to production. You can also use the whatsdeployed.io service to get a nice view of what is actually currently deployed to Dev, Stage, and Prod:</p> <p></p>"},{"location":"pipeline/#instance-configuration-switches","title":"Instance Configuration &amp; Switches","text":"<p>We have a separate repo for configuring our primary instances (dev, stage, and prod). The docs for updating configurations in that repo are on their own page, but there is a way to tell what version of the configuration is in use on any particular instance of bedrock. You can go to the <code>/healthz-cron/</code> URL on an instance (see prod for example) to see the current commit of all of the external Git repos in use by the site and how long ago they were updated. The info on that page also includes the latest version of the database in use, the git revision of the bedrock code, and how long ago the database was updated. If you recently made a change to one of these repos and are curious if the changes have made it to production, this is the URL you should check.</p>"},{"location":"pipeline/#updating-selenium","title":"Updating Selenium","text":"<p>There are several components for Selenium, which are independently versioned. The first is the Python client, and this can be updated via the test dependencies. The other components are the Selenium versions used in both SauceLabs and the local Selenium grid. These versions are selected automatically based on the required OS / Browser configuration, so they should not need to be updated or specified independently.</p>"},{"location":"pipeline/#adding-test-runs","title":"Adding test runs","text":"<p>Test runs can be added by creating a new job in <code>bedrock/.github/workflows/integration_tests.yml</code> with the desired variables and pushing that branch to Github. For example, if you wanted to run the smoke tests in IE10 (using Saucelabs) you could add the following clause to the matrix:</p> <pre><code>- LABEL: test-ie10-saucelabs\n  BROWSER_NAME: internet explorer\n  BROWSER_VERSION: \"10.0\"\n  DRIVER: SauceLabs\n  PYTEST_PROCESSES: \"8\"\n  PLATFORM: Windows 8\n  MARK_EXPRESSION: smoke\n</code></pre> <p>You can use Sauce Labs platform configurator to help with the parameter values.</p>"},{"location":"pipeline/#pushing-to-the-integration-tests-branch","title":"Pushing to the integration tests branch","text":"<p>If you have commit rights to our Github repo (mozilla/bedrock) you can simply push your branch to the branch named <code>run-integration-tests</code>, and the app will be deployed and the full suite of integration tests for that branch will be run. Please announce in our Slack channel (#www on mozilla.slack.com) that you'll be doing this so that we don't get conflicts. Also remember that you'll likely need to force push, as there may be commits on that branch which aren't in yours -- so, if you have the <code>mozilla/bedrock</code> remote set as <code>mozilla</code>:</p> <pre><code>$ git push -f mozilla $(git branch --show-current):run-integration-tests\n</code></pre>"},{"location":"redirects/","title":"Managing redirects","text":""},{"location":"redirects/#redirects","title":"Managing Redirects","text":"<p>We have a redirects app in bedrock that makes it easier to add and manage redirects. Due to the size, scope, and history of mozilla.org we have quite a lot of redirects. If you need to add or manage redirects read on.</p>"},{"location":"redirects/#add-a-redirect","title":"Add a redirect","text":"<p>You should add redirects in the app that makes the most sense. For example, if the source URL is <code>/firefox/...</code> then the <code>bedrock.firefox</code> app is the best place. Redirects are added to a <code>redirects.py</code> file within the app. If the app you want to add redirects to doesn't have such a file, you can create one and it will automatically be discovered and used by bedrock as long as said app is in the <code>INSTALLED_APPS</code> setting (see <code>bedrock/mozorg/redirects.py</code> as an example).</p> <p>Once you decide where it should go you can add your redirect. To do this you simply add a call to the <code>bedrock.redirects.util.redirect</code> helper function in a list named <code>redirectpatterns</code> in <code>redirects.py</code>. For example:</p> <pre><code>from bedrock.redirects.util import redirect\n\n\nredirectpatterns = [\n    redirect(r\"^rubble/barny/$\", \"/flintstone/fred/\"),\n]\n</code></pre> <p>This will make sure that requests to <code>/rubble/barny/</code> (or with the locale like <code>/pt-BR/rubble/barny/</code>) will get a 301 response sending users to <code>/flintstone/fred/</code>.</p> <p>The <code>redirect()</code> function has several options. Its signature is as follows:</p> <pre><code>def redirect(\n    pattern,\n    to,\n    permanent=True,\n    locale_prefix=True,\n    anchor=None,\n    name=None,\n    query=None,\n    vary=None,\n    cache_timeout=12,\n    decorators=None,\n    re_flags=None,\n    to_args=None,\n    to_kwargs=None,\n    prepend_locale=True,\n    merge_query=False,\n):\n    \"\"\"\n    Return a url matcher suited for urlpatterns.\n\n    pattern: the regex against which to match the requested URL.\n    to: either a url name that `reverse` will find, a url that will simply be returned,\n        or a function that will be given the request and url captures, and return the\n        destination.\n    permanent: boolean whether to send a 301 or 302 response.\n    locale_prefix: automatically prepend `pattern` with a regex for an optional locale\n        in the URL. This locale (or None) will show up in captured kwargs as 'locale'.\n    anchor: if set it will be appended to the destination URL after a '#'.\n    name: if used in a `urls.py` the redirect URL will be available as the name\n        for use in calls to `reverse()`. Does _NOT_ work if used in a `redirects.py` file.\n    query: a dict of query params to add to the destination URL.\n    vary: if you used an HTTP header to decide where to send users you should include that\n        header's name in the `vary` arg.\n    cache_timeout: number of hours to cache this redirect. just sets the proper `cache-control`\n        and `expires` headers.\n    decorators: a callable (or list of callables) that will wrap the view used to redirect\n        the user. equivalent to adding a decorator to any other view.\n    re_flags: a string of any of the characters: \"iLmsux\". Will modify the `pattern` regex\n        based on the documented meaning of the flags (see python re module docs).\n    to_args: a tuple or list of args to pass to reverse if `to` is a url name.\n    to_kwargs: a dict of keyword args to pass to reverse if `to` is a url name.\n    prepend_locale: if true the redirect URL will be prepended with the locale from the\n        requested URL.\n    merge_query: merge the requested query params from the `query` arg with any query params\n        from the request.\n\n    Usage:\n    urlpatterns = [\n        redirect(r'projects/$', 'mozorg.product'),\n        redirect(r'^projects/seamonkey$', 'mozorg.product', locale_prefix=False),\n        redirect(r'apps/$', 'https://marketplace.firefox.com'),\n        redirect(r'firefox/$', 'firefox.new', name='firefox'),\n        redirect(r'the/dude$', 'abides', query={'aggression': 'not_stand'}),\n    ]\n    \"\"\"\n</code></pre>"},{"location":"redirects/#differences","title":"Differences","text":"<p>This all differs from <code>urlpatterns</code> in <code>urls.py</code> files in some important ways. The first is that these happen first. If something matches in a <code>redirects.py</code> file it will always win the race if another URL in a <code>urls.py</code> file would also have matched. Another is that these are matched before any locale prefix stuff happens. So what you're matching against in the redirects files is the original URL that the user requested. By default (unless you set <code>locale_prefix=False</code>) your patterns will match either the plain URL (e.g. <code>/firefox/os/</code>) or one with a locale prefix (e.g. <code>/fr/firefox/os/</code>). If you wish to include this locale in the destination URL you can simply use python's string <code>format()</code> function syntax. It is passed to the <code>format</code> method as the keyword argument <code>locale</code> (e.g. <code>redirect('^stuff/$', '{locale}whatnot/')</code>). If there was no locale in the URL the <code>{locale}</code> substitution will be an empty string. Similarly if you wish to include a part of the original URL in the destination, just capture it with the regex using a named capture (e.g. <code>r'^stuff/(?P&lt;rest&gt;.*)$'</code> will let you do <code>'/whatnot/{rest}'</code>).</p>"},{"location":"redirects/#utilities","title":"Utilities","text":"<p>There are a couple of utility functions for use in the <code>to</code> argument of <code>redirect</code> that will return a function to allow you to match something in an HTTP header.</p>"},{"location":"redirects/#ua_redirector","title":"ua_redirector","text":"<p><code>bedrock.redirects.util.ua_redirector</code> is a function to be used in the <code>to</code> argument that will use a regex to match against the <code>User-Agent</code> HTTP header to allow you to decide where to send the user. For example:</p> <pre><code>from bedrock.redirects.util import redirect, ua_redirector\n\n\nredirectpatterns = [\n    redirect(\n        r\"^rubble/barny/$\",\n        ua_redirector(\"firefox(os)?\", \"/firefox/\", \"/not-firefox/\"),\n        cache_timeout=0,\n    ),\n]\n</code></pre> <p>You simply pass it a regex to match, the destination URL (substitutions from the original URL do work) if the regex matches, and another destination URL if the regex does not match. The match is not case sensitive unless you add the optional <code>case_sensitive=True</code> argument.</p> <p>Note</p> <p>Be sure to include the <code>cache_timeout=0</code> so that you won't be bitten by any caching proxies sending all users one way or the other. Do not set the <code>Vary: User-Agent</code> header; this will not work in production.</p>"},{"location":"redirects/#header_redirector","title":"header_redirector","text":"<p>This is basically the same as <code>ua_redirector</code> but works against any header. The arguments are the same as above except that thre is an additional first argument for the name of the header:</p> <pre><code>from bedrock.redirects.util import redirect, header_redirector\n\n\nredirectpatterns = [\n    redirect(\n        r\"^rubble/barny/$\",\n        header_redirector(\"cookie\", \"been-here\", \"/firefox/\", \"/firefox/new/\"),\n        vary=\"cookie\",\n    ),\n]\n</code></pre>"},{"location":"redirects/#testing-redirects","title":"Testing redirects","text":"<p>A suite of tests exists for redirects, which is intended as a reference of the redirects we expect to work on www.mozilla.org. This will become a base for implementing these redirects in the bedrock app and allow us to test them before release.</p>"},{"location":"redirects/#installation","title":"Installation","text":"<p>First follow the <code>installation instructions for bedrock&lt;install&gt;</code>, which will guide you through installing pip and setting up a virtual environment for the tests. The additional requirements can then be installed by using the following commands:</p> <pre><code>$ source venv/bin/activate\n</code></pre> <pre><code>$ pip install -r requirements/dev.txt\n</code></pre>"},{"location":"redirects/#running-the-tests","title":"Running the tests","text":"<p>If you wish to run the full set of tests, which requires a deployed instance of the site (e.g. www.mozilla.org) you can set the <code>--base-url</code> command line option:</p> <pre><code>$ pytest --base-url https://www.mozilla.org tests/redirects/\n</code></pre> <p>By default, tests will run one at a time. If you intend to run the suite against a remote instance of the site (e.g. production) it will run a lot quicker by running the tests in parallel. To do this, you can add <code>-n auto</code> to the command line. Replace <code>auto</code> with an integer if you want to set the maximum number of concurrent processes.</p>"},{"location":"send-to-device/","title":"Send to Device widget","text":""},{"location":"send-to-device/#sendtodevice","title":"Send to Device Widget","text":"<p>The Send to Device widget is a single form which facilitates the sending of a download link from a desktop browser to a mobile device. The form allows sending via email.</p> <p>Important</p> <p>This widget should only be shown to a limited set of locales who are set up to receive the emails. For those locales not in the list, direct links to the respective app stores should be shown instead. If a user is on iOS or Android, <code>CTA (Call To Action)</code> buttons should also link directly to respective app stores instead of showing the widget. This logic should be handled on a page-by-page basis to cover individual needs.</p> <p>Note</p> <p>A full list of supported locales can be found in <code>settings/base.py</code> under <code>SEND_TO_DEVICE_LOCALES</code>, which can be used in the template logic for each page to show the form.</p>"},{"location":"send-to-device/#usage","title":"Usage","text":"<ol> <li> <p>Make sure necessary files are in your CSS/JS bundles:</p> <ul> <li><code>'css/protocol/components/send-to-device.scss'</code></li> <li><code>'js/base/send-to-device.es6.js'</code></li> </ul> </li> <li> <p>Include the macro in your page template:</p> <pre><code>{{ send_to_device() }}\n</code></pre> </li> <li> <p>Initialize the widget:</p> <p>In your page JS, initialize the widget using:</p> <pre><code>import SendToDevice from '/media/js/base/send-to-device.es6';\n\nconst form = new SendToDevice();\nform.init();\n</code></pre> <p>By default the <code>init()</code> function will look for a form with an HTML id of <code>send-to-device</code>. If you need to pass another id, you can do so directly:</p> <pre><code>const form = new SendToDevice('my-custom-form-id');\nform.init();\n</code></pre> </li> </ol>"},{"location":"send-to-device/#configuration","title":"Configuration","text":"<p>The Jinja macro supports parameters as follows (* indicates a required parameter)</p> Parameter name Definition Format Example platform* Platform ID for the receiving device. Defaults to 'all'. String 'all', 'android', 'ios' message_set* ID for the email that should be received. Defaults to 'default'. String 'default', 'fx-mobile-download-desktop', 'fx-whatsnew' dom_id* HTML form ID. Defaults to 'send-to-device'. String 'send-to-device' class_name CSS class name for form orientation. Defaults to 'vertical' String 'horizontal', 'vertical' include_title Should the widget contain a title. Defaults to 'True'. Boolean 'True', 'False' title_text Provides a custom string for the form title, overriding the default. Localizable string 'Send Firefox Lite to your smartphone or tablet' . input_label Provides a custom label for the input field, overriding the default. Localizable string 'Enter your email' . legal_note_email Provides a custom legal note for email use. Localizable String. 'The intended recipient of the email must have consented.' spinner_color Hex color for the form spinner. Defaults to '#000'. String '#fff' button_class Optional button CSS class string. Defaults to 'mzp-t-product' String 'mzp-t-product mzp-t-dark'"},{"location":"sitemap/","title":"Sitemaps","text":""},{"location":"sitemap/#sitemap","title":"Sitemaps","text":"<p><code>bedrock</code> serves a root sitemap at <code>/sitemap.xml</code>, which links to localised sitemaps for each supported locale.</p> <p>The sitemap data is (re)generated on a schedule by www-sitemap-generator and then is pulled into <code>bedrock</code>'s database, from which the XML sitemaps are rendered.</p>"},{"location":"sitemap/#quick-summary","title":"Quick summary","text":""},{"location":"sitemap/#what-does-www-sitemap-generator-do","title":"What does <code>www-sitemap-generator</code> do?","text":"<p><code>www-sitemap-generator</code>, ultimately, produces an updated <code>sitemap.json</code> file if it detects changes in pages since the last time the sitemap was generated. It does this by loading every page and checking its ETag. This <code>sitemap.json</code> data is key to sitemap rendering by <code>bedrock</code>.</p> <p>The update process is run on a schedule via our Gitlab CI setup.</p> <p>Note</p> <p><code>www-sitemap-generator</code> uses the main <code>bedrock</code> release Docker image as its own base container image, which means it has access to all of <code>bedrock</code>'s code and data-loading utils.</p> <p>Bear this in mind when looking at management commands in <code>bedrock</code>; <code>update_sitemaps</code> is actually only called by <code>www-sitemap-generator</code> even though it (currently) lives in <code>bedrock</code></p>"},{"location":"sitemap/#when-is-the-sitemap-data-pulled-into-bedrock","title":"When is the sitemap data pulled into <code>bedrock</code>?","text":"<p>Bedrock's clock pod regularly runs <code>bin/run-db-update.sh</code>, which calls the <code>update_sitemaps_data</code> management command. This is what pulls in data from the <code>www-sitemap-generator</code> git repo and refreshes the <code>SitemapURL</code> records in Bedrock's database. It is from these <code>SitemapURL</code> records that the XML sitemap tree is rendered by <code>bedrock</code>.</p>"},{"location":"task-queue/","title":"Task Queue","text":""},{"location":"task-queue/#task-queue","title":"Task queue","text":"<p>As part of the 2024 Wagtail CMS work, we have added a task queue to process longer-running jobs in the background.</p> <p>The queue is supplied by <code>django-rq</code>, which sits on top of <code>rq</code> and uses Redis as the storage backend.</p> <p>Once infra has been set up fully to support this, documentation will be expanded, but for local development you can start a worker to process jobs in the queue with:</p> <pre><code>make run-local-task-queue\n</code></pre> <p>Note that you will need Redis running on its default port of 6379. Redis is started by default when using Dockerized Bedrock locally.</p>"},{"location":"testing/","title":"Front-end testing","text":""},{"location":"testing/#testing","title":"Front-end testing","text":"<p>Bedrock runs several different types of front-end tests to ensure that the site is working correctly and that new changes don't break existing functionality.</p> <ul> <li>Jasmine unit/behavioral tests are used to test JavaScript code that runs in the browser. These tests are run against both Firefox and Chrome browsers via a GitHub action, which is triggered against all pull requests and commits to the main branch.</li> <li>Playwright integration tests are used to run end-to-end tests in a real browser environment. These tests are run automatically as part of our CI deployment process against dev, stage, and prod. Playwright tests are run against Firefox, Chromium, and Webkit headless browsers for cross-engine coverage.</li> <li>Axe tests are used to test for accessibility issues on key pages. These tests are not run as part of our CI deployment process as they can contain a lot of information, but instead run once per day via a GitHub action against dev. Axe tests are run via Playwright as a subset of tests using the <code>@a11y</code> tag. Accessibility issues are reported in the GitHub action output, which can be downloaded and reviewed.</li> <li>Selenium tests are bedrock's older, legacy integration test suite, which will eventually be replaced by Playwright. These tests are run against Firefox, Chrome, and Internet Explorer (via a mix of both a local Selenium Grid and Sauce Labs) as part of our CI pipeline, and run alongside the Playwright tests.</li> </ul> <p>Note</p> <p>New integration tests should be written using Playwright, but we will continue to run the Selenium tests until they are all migrated over. We will also eventually retire the Internet Explorer tests.</p> <p>The test specs for all of the above suites can be found in the root <code>./tests</code> directory:</p> <ul> <li><code>./tests/unit/</code> for Jasmine tests.</li> <li><code>./tests/playwright/</code> Playwright tests.</li> <li><code>./tests/playwright/specs/a11y/</code> Axe tests.</li> <li><code>./tests/functional/</code> for Selenium tests.</li> </ul>"},{"location":"testing/#automating-the-browser","title":"Automating the browser","text":"<p>Jasmine, Playwright and Selenium all require a browser to run. In order to automate browsers such as Firefox and Chrome, you may also need to have the appropriate drivers installed. To download <code>geckodriver</code> and <code>chromedriver</code> and have them ready to run in your system, there are a couple of ways:</p> <p>Download geckodriver and add it to your system path:</p> <pre><code>$ cd /path/to/your/downloaded/files/\n</code></pre> <pre><code>$ mv geckodriver /usr/local/bin/\n</code></pre> <p>If you're on MacOS, download <code>geckodriver</code> directly using Homebrew, which automatically places it in your system path:</p> <pre><code>$ brew install geckodriver\n</code></pre> <p>Download chromedriver and add it to your system path:</p> <pre><code>$ cd /path/to/your/downloaded/files/\n</code></pre> <pre><code>$ mv chromedriver /usr/local/bin/\n</code></pre> <p>If you're on MacOS, download <code>chromedriver</code> directly using Homebrew/Cask, which automatically places it in your system path:</p> <pre><code>$ brew tap homebrew/cask\n</code></pre> <pre><code>$ brew cask install chromedriver\n</code></pre>"},{"location":"testing/#running-jasmine-tests","title":"Running Jasmine tests","text":"<p>Jasmine and its dependencies are installed via npm and are included when you run <code>make preflight</code> to install bedrock's main dependencies.</p> <pre><code>$ make preflight\n</code></pre> <p>Next, make sure you activate your bedrock virtual env.</p> <pre><code>$ pyenv activate bedrock\n</code></pre> <p>You can then run the full suite of Jasmine tests with the following command:</p> <pre><code>$ npm run test\n</code></pre> <p>This will also run all our front-end linters and formatting checks before running the Jasmine test suite. If you only want to run the tests themselves, you can run:</p> <pre><code>$ npm run jasmine\n</code></pre>"},{"location":"testing/#writing-jasmine-tests","title":"Writing Jasmine tests","text":"<p>See the Jasmine documentation for tips on how to write JS behavioral or unit tests. We also use Sinon for creating test spies, stubs and mocks.</p>"},{"location":"testing/#debugging-jasmine-tests","title":"Debugging Jasmine tests","text":"<p>If you need to debug Jasmine tests, you can also run them interactively in the browser using the following command:</p> <pre><code>$ npm run jasmine-serve\n</code></pre>"},{"location":"testing/#running-playwright-tests","title":"Running Playwright tests","text":"<p>Playwright test dependencies are installed via NPM but are not included in the <code>make preflight</code> command along with bedrock's core dependencies. This is because the dependencies are not required to run the site, and also include several large binary files for each headless browser engine.</p> <p>To install the Playwright dependencies, run the following command:</p> <pre><code>$ cd tests/playwright &amp;&amp; npm install &amp;&amp; npm run install-deps\n</code></pre>"},{"location":"testing/#specifying-an-environment","title":"Specifying an environment","text":"<p>By default Playwright tests will run against <code>http://localhost:8000/</code>. Remember to have your development server running before starting the test suite locally.</p> <p>You can also set <code>PLAYWRIGHT_BASE_URL</code> in your <code>.env</code> to point to a different environment, such as dev or stage. For example:</p> <pre><code>PLAYWRIGHT_BASE_URL=https://dev.bedrock.nonprod.webservices.mozgcp.net\n</code></pre>"},{"location":"testing/#running-the-test-suite","title":"Running the test suite","text":"<p>To run the full suite of tests (from the <code>/tests/playwright/</code> directory):</p> <pre><code>$ npm run integration-tests\n</code></pre> <p>This will run all tests against three different headless browser engines (Firefox, Chromium, WebKit).</p>"},{"location":"testing/#running-specific-tests","title":"Running specific tests","text":"<p>Tests are grouped using tags, such as <code>@mozorg</code>, <code>@firefox</code>, <code>@vpn</code>. To run only one group of tests, instead of the whole suite, you can use <code>--grep</code>:</p> <pre><code>$ npx playwright test --grep @firefox\n</code></pre> <p>To run only a specific test file, such as <code>firefox-new.spec.js</code>, you can pass the filename:</p> <pre><code>$ npx playwright test firefox-new\n</code></pre> <p>See the Playwright CLI docs for more options when running and debugging tests.</p>"},{"location":"testing/#writing-tests","title":"Writing tests","text":"<p>Playwright test spec files are found in the <code>./tests/playwright/specs/</code> directory.</p> <p>See the Playwright docs for more examples on how to write tests.</p>"},{"location":"testing/#guidelines-for-writing-integration-tests","title":"Guidelines for writing integration tests","text":"<ul> <li>Try and keep tests focused on user journeys and key functionality. For example, a test for the download page should focus on the download button, and not the footer or header.</li> <li>Test expected functionality from a user perspective. For example, if a user clicks a button, the test should check that the expected action occurs. Try to avoid testing implementation details, as these are both invisible to the user and likely to change more frequently.</li> <li>Keep tests organized and cleanly separated. Each page should have its own test spec file, and each test should be responsible for a specific purpose, or component of a page.</li> <li>Try and use <code>data-testid</code> attributes for a locator strategy, as these are less likely to change than other attributes.</li> <li>Avoid string checking as tests may break if strings are updated, or could change depending on the page locale.</li> <li>When writing tests, push them to the <code>run-integration-tests</code> branch to run them against the deployed environment prior to merging to <code>main</code>. This will allow you to catch any issues that may not be present in local testing. It's also worth running tests a few times to identify any potential intermittent failures.</li> </ul>"},{"location":"testing/#user-agent-string-overrides","title":"User Agent string overrides","text":"<p>Playwright tests use User Agent string overrides to mock different browser and operating systems combinations. By default tests run with User Agent strings configured for Firefox and Chrome running on Windows, and Safari running on macOS. This is accomplished using an <code>OpenPage()</code> helper that can be imported in each test file:</p> <pre><code>const openPage = require('../scripts/open-page');\nconst url = '/en-US/firefox/new/';\n\ntest.beforeEach(async ({ page, browserName }) =&gt; {\n    await openPage(url, page, browserName);\n});\n</code></pre> <p>To mock a different browser or operating system combination, tests can manually load a different override instead of using <code>openPage</code>:</p> <pre><code>test.beforeEach(async ({ page, browserName }) =&gt; {\n    if (browserName === 'webkit') {\n        // Set macOS 10.14 UA strings.\n        await page.addInitScript({\n            path: `./scripts/useragent/mac-old/${browserName}.js`\n        });\n    } else {\n        // Set Windows 8.1 UA strings (64-bit).\n        await page.addInitScript({\n            path: `./scripts/useragent/win-old/${browserName}.js`\n        });\n    }\n\n    await page.goto(url + '?automation=true');\n});\n</code></pre>"},{"location":"testing/#accessibility-testing-axe","title":"Accessibility testing (Axe)","text":"<p>Axe tests are run as a subset of Playwright tests using the <code>@a11y</code> tag. These tests are run against the dev environment once per day via a GitHub action. The axe spec files can be found in the <code>./tests/playwright/specs/a11y/</code> directory.</p> <p>To run the Axe tests locally, you can use the following command from the <code>./tests/playwright/</code> directory:</p> <pre><code>$ npm run a11y-tests\n</code></pre> <p>The Axe tests consist of two different test types. One that scans an entire page for accessibility issues, and another that scans a specific element for issues (such as the main navigation and footer). These tests can also be run at both desktop and mobile viewport sizes.</p> <p>Test results are output to the console, and any issues found will be created as HTML report files in the <code>./tests/playwright/test-results-a11y/</code> directory. When run via the GitHub action, the reports are also output to the annotation logs for each test job.</p> <p>A list of all the Axe rules that are checked by the tests can be viewed in the axe-core repo.</p>"},{"location":"testing/#running-selenium-tests","title":"Running Selenium tests","text":"<p>Note</p> <p>Selenium tests are being retired in favour of the newer Playwright test suite. Whilst we will continue to run the Selenium tests until they are all migrated over, new tests should be written using Playwright.</p> <p>Before running the Selenium tests, please make sure to follow the bedrock <code>installation docs&lt;install&gt;</code>, including the database sync that is needed to pull in external data such as event/blog feeds etc. These are required for some of the tests to pass.</p> <p>To run the full Selenium integration test suite against your local bedrock instance:</p> <pre><code>$ pytest --base-url http://localhost:8000 --driver Firefox --html tests/functional/results.html tests/functional/\n</code></pre> <p>This will run all test suites found in the <code>tests/functional</code> directory and assumes you have bedrock running at <code>localhost</code> on port <code>8000</code>. Results will be reported in <code>tests/functional/results.html</code>.</p> <p>Note</p> <p>If you omit the <code>--base-url</code> command line option then a local instance of bedrock will be started, however the tests are not currently able to run against bedrock in this way.</p> <p>By default, tests will run one at a time. This is the safest way to ensure predictable results, due to bug 1230105. If you want to run tests in parallel (this should be safe when running against a deployed instance), you can add <code>-n auto</code> to the command line. Replace <code>auto</code> with an integer if you want to set the maximum number of concurrent processes.</p> <p>Note</p> <p>There are some tests that do not require a browser. These can take a long time to run, especially if they're not running in parallel. To skip these tests, add <code>-m 'not headless'</code> to your command line.</p> <p>To run a single test file you must tell pytest to execute a specific file e.g. <code>tests/functional/test_newsletter.py</code>:</p> <pre><code>$ pytest --base-url http://localhost:8000 --driver Firefox --html tests/functional/results.html tests/functional/firefox/new/test_download.py\n</code></pre> <p>To run a single test you can filter using the <code>-k</code> argument supplied with a keyword e.g. <code>-k test_download_button_displayed</code>:</p> <pre><code>$ pytest --base-url http://localhost:8000 --driver Firefox --html tests/functional/results.html tests/functional/firefox/new/test_download.py -k test_download_button_displayed\n</code></pre> <p>You can also easily run the tests against any bedrock environment by specifying the <code>--base-url</code> argument. For example, to run all Selenium integration tests against dev:</p> <pre><code>$ pytest --base-url https://www-dev.allizom.org --driver Firefox --html tests/functional/results.html tests/functional/\n</code></pre> <p>Note</p> <p>For the above commands to work, Firefox needs to be installed in a predictable location for your operating system. For details on how to specify the location of Firefox, or running the tests against alternative browsers, refer to the pytest-selenium documentation.</p> <p>For more information on command line options, see the pytest documentation.</p>"},{"location":"testing/#running-tests-in-sauce-labs","title":"Running tests in Sauce Labs","text":"<p>You can also run tests in Sauce Labs directly from the command line. This can be useful if you want to run tests against Internet Explorer when you're on Mac OSX, for instance.</p> <ol> <li>Sign up for an account at https://saucelabs.com/opensauce/.</li> <li>Log in and obtain your Remote Access Key from user settings.</li> <li>Run a test specifying <code>SauceLabs</code> as your driver, and pass your credentials.</li> </ol> <p>For example, to run the home page tests using Internet Explorer via Sauce Labs:</p> <pre><code>$ SAUCELABS_USERNAME=thedude SAUCELABS_API_KEY=123456789 SAUCELABS_W3C=true SELENIUM_EXCLUDE_DEBUG=logs pytest --base-url https://www-dev.allizom.org --driver SauceLabs --capability browserName 'internet explorer' --capability platformName 'Windows 10' --html tests/functional/results.html tests/functional/test_home.py\n</code></pre>"},{"location":"testing/#writing-selenium-tests","title":"Writing Selenium tests","text":"<p>Tests usually consist of interactions and assertions. Selenium provides an API for opening pages, locating elements, interacting with elements, and obtaining state of pages and elements. To improve readability and maintainability of the tests, we use the Page Object model, which means each page we test has an object that represents the actions and states that are needed for testing.</p> <p>Well written page objects should allow your test to contain simple interactions and assertions as shown in the following example:</p> <pre><code>def test_sign_up_for_newsletter(base_url, selenium):\n    page = NewsletterPage(base_url, selenium).open()\n    page.type_email(\"noreply@mozilla.com\")\n    page.accept_privacy_policy()\n    page.click_sign_me_up()\n    assert page.sign_up_successful\n</code></pre> <p>It's important to keep assertions in your tests and not your page objects, and to limit the amount of logic in your page objects. This will ensure your tests all start with a known state, and any deviations from this expected state will be highlighted as potential regressions. Ideally, when tests break due to a change in bedrock, only the page objects will need updating. This can often be due to an element needing to be located in a different way.</p> <p>Please take some time to read over the Selenium documentation for details on the Python client API.</p>"},{"location":"testing/#destructive-tests","title":"Destructive tests","text":"<p>By default all tests are assumed to be destructive, which means they will be skipped if they're run against a sensitive environment. This prevents accidentally running tests that create, modify, or delete data on the application under test. If your test is nondestructive you will need to apply the <code>nondestructive</code> marker to it. A simple example is shown below, however you can also read the pytest markers documentation for more options.</p> <pre><code>import pytest\n\n\n@pytest.mark.nondestructive\ndef test_newsletter_default_values(base_url, selenium):\n    page = NewsletterPage(base_url, selenium).open()\n    assert \"\" == page.email\n    assert \"United States\" == page.country\n    assert \"English\" == page.language\n    assert page.html_format_selected\n    assert not page.text_format_selected\n    assert not page.privacy_policy_accepted\n</code></pre>"},{"location":"testing/#smoke-tests","title":"Smoke tests","text":"<p>Smoke tests are considered to be our most critical tests that must pass in a wide range of web browsers, including Internet Explorer 11. The number of smoke tests we run should be enough to cover our most critical pages where legacy browser support is important.</p> <pre><code>import pytest\n\n\n@pytest.mark.smoke\n@pytest.mark.nondestructive\ndef test_download_button_displayed(base_url, selenium):\n    page = DownloadPage(selenium, base_url, params=\"\").open()\n    assert page.is_download_button_displayed\n</code></pre> <p>You can run smoke tests only by adding <code>-m smoke</code> when running the test suite on the command line.</p>"},{"location":"testing/#waits-and-expected-conditions","title":"Waits and Expected Conditions","text":"<p>Often an interaction with a page will cause a visible response. While Selenium does its best to wait for any page loads to be complete, it's never going to be as good as you at knowing when to allow the test to continue. For this reason, you will need to write explicit waits in your page objects. These repeatedly execute code (a condition) until the condition returns true. The following example is probably the most commonly used, and will wait until an element is considered displayed:</p> <pre><code>from selenium.webdriver.support import expected_conditions as expected\nfrom selenium.webdriver.support.ui import WebDriverWait as Wait\n\nWait(selenium, timeout=10).until(\n    expected.visibility_of_element_located(By.ID, \"my_element\")\n)\n</code></pre> <p>For convenience, the Selenium project offers some basic expected conditions, which can be used for the most common cases.</p>"},{"location":"testing/#debugging-selenium","title":"Debugging Selenium","text":"<p>Debug information is collected on failure and added to the HTML report referenced by the <code>--html</code> argument. You can enable debug information for all tests by setting the <code>SELENIUM_CAPTURE_DEBUG</code> environment variable to <code>always</code>.</p>"},{"location":"testing/#testing-basket-email-forms","title":"Testing Basket email forms","text":"<p>When writing integration tests for front-end email newsletter forms that submit to Basket, we have some special case email addresses that can be used just for testing:</p> <ol> <li>Any newsletter subscription request using the email address \"success@example.com\" will always return success from the basket client.</li> <li>Any newsletter subscription request using the email address \"failure@example.com\" will always raise an exception from the basket client.</li> </ol> <p>Using the above email addresses enables newsletter form testing without actually hitting the Basket instance, which reduces automated newsletter spam and improves test reliability due to any potential network flakiness.</p>"},{"location":"testing/#headless-tests","title":"Headless tests","text":"<p>There are targeted headless tests for the download pages. These tests and are run as part of the pipeline to ensure that download links constructed via product details are well formed and return valid 200 responses.</p>"},{"location":"uitour/","title":"Mozilla.UITour","text":""},{"location":"uitour/#ui-tour","title":"Mozilla.UITour","text":""},{"location":"uitour/#introduction","title":"Introduction","text":"<p><code>Mozilla.UITour</code> is a JS library that exposes an event-based Web API for communicating with the Firefox browser chrome. It can be used for tasks such as opening menu panels, highlighting buttons, or querying Mozilla account signed-in state. It is supported in Firefox 29 onward, but some API calls are only supported in later versions.</p> <p>For security reasons <code>Mozilla.UITour</code> will only work on white-listed domains and over a secure connection. The list of allowed origins can be found here: https://searchfox.org/mozilla-central/source/browser/app/permissions</p> <p>The <code>Mozilla.UITour</code> library is maintained on Mozilla Central.</p> <p>Important</p> <p>The API is supported only on the desktop versions of Firefox. It doesn't work on Firefox for Android and iOS.</p>"},{"location":"uitour/#local-development","title":"Local development","text":"<p>To develop or test using Mozilla.UITour locally you need to create some custom preferences in <code>about:config</code>.</p> <ul> <li><code>browser.uitour.testingOrigins</code> (string) (value: local address e.g. <code>http://127.0.0.1:8000</code>)</li> <li><code>browser.uitour.requireSecure</code> (boolean) (value: <code>false</code>)</li> </ul> <p>Note that <code>browser.uitour.testingOrigins</code> can be a comma separated list of domains, e.g.</p> <pre><code>'http://127.0.0.1:8000, &lt;https://www-demo2.allizom.org&gt;'\n</code></pre> <p>Important</p> <p>Prior to Firefox 36, the testing preference was called <code>browser.uitour.whitelist.add.testing</code> (Bug 1081772). This old preference does not accept a comma separated list of domains, and you must also exclude the domain protocol e.g. <code>https://</code>. A browser restart is also required after adding an allowed domain.</p> <p>If you are working on Mozilla accounts integration, you can use the <code>identity.fxaccounts.autoconfig.uri</code> config property to change the Accounts server. For example, to change it to stage environment use this value: <code>https://accounts.stage.mozaws.net/</code>. Restart the browser and make sure the configuration updated. <code>identity.fxaccounts.remote.root</code> preference should now point to <code>https://accounts.stage.mozaws.net</code>. If it has not changed for some reason, update it manually. Ref: https://mozilla-services.readthedocs.io/en/latest/howtos/run-fxa.html</p>"},{"location":"uitour/#javascript-api","title":"JavaScript API","text":"<p>The UITour API documentation can be found in the Mozilla Source Tree Docs.</p>"},{"location":"vpn-subscriptions/","title":"Mozilla VPN Subscriptions","text":""},{"location":"vpn-subscriptions/#vpn_subscriptions","title":"Mozilla VPN Subscriptions","text":"<p>The Mozilla VPN landing page displays both pricing and currency information that is dependant on someone's physical location in the world (using geo-location). If someone is in the United States, they should see pricing in $USD, and if someone is in Germany they should see pricing in Euros. The page is also available in multiple languages, which can be viewed independently of someone's physical location. So someone who lives in Switzerland, but is viewing the page in German, should still see pricing and currency displayed in Swiss Francs (CHF).</p> <p>Additionally, it is important that we render location specific subscription links, as purchasing requires a credit card that is registered to each country where we have a plan available. We are also legally obligated to prevent both purchasing and/or downloading of Mozilla VPN in certain countries. In countries where VPN is not yet available, we also rely on geo-location to hide subscription links, and instead to display a call to action to encourage prospective customers to sign up to the VPN wait list.</p> <p>To facilitate all of the above, we rely on our CDN to return an appropriate country code that relates to where a visitor's request originated from (see Geo Template View). We use that country code in our helpers and view logic for the VPN landing page to decide what to display in the pricing section of the page (see <code>Mozilla :abbr:`VPN (Virtual Private Network)</code> Links `_)."},{"location":"vpn-subscriptions/#server-architecture","title":"Server architecture","text":"<p>Bedrock is configured so that when <code>dev=True</code>, VPN subscription links will point to the Mozilla accounts staging environment. When <code>dev=False</code>, they will point to the Fxa production environment.</p> <p>So our different environments are mapped like so:</p> <ul> <li><code>http://localhost:8000</code> -&gt; <code>https://accounts.stage.mozaws.net/</code></li> <li><code>https://www-dev.allizom.org/products/vpn/</code> -&gt; <code>https://accounts.stage.mozaws.net/</code></li> <li><code>https://www.allizom.or/products/vpn/</code> -&gt; <code>https://accounts.firefox.com/</code></li> <li><code>https://www.mozilla.org/products/vpn</code> -&gt; <code>https://accounts.firefox.com/</code></li> </ul> <p>This allows the product and QA teams to routinely test changes and new VPN client releases on https://www-dev.allizom.org/products/vpn/, prior to being available in production.</p>"},{"location":"vpn-subscriptions/#adding-new-countries-for-vpn","title":"Adding new countries for VPN","text":"<p>When launching VPN in new countries there is a set process to follow.</p>"},{"location":"vpn-subscriptions/#launch-steps","title":"Launch steps","text":"<ol> <li>All the code changes below should be added behind a feature switch.</li> <li>Once the PR is reviewed and merged, the product QA team should be notified and they can then perform testing on https://www-dev.allizom.org/products/vpn/. Often the QA team will request a date for code to be ready for testing to begin.</li> <li>Code can be pushed to production ahead of time (but will be disabled behind the feature switch by default).</li> <li>Once QA gives the green light on launch day, the feature switch can then be enabled in production.</li> <li>QA will then do a final round of post-launch QA to verify subscriptions / purchasing works in the new countries in production.</li> </ol>"},{"location":"vpn-subscriptions/#code-changes","title":"Code changes","text":"<p>Reference: officially assigned list of ISO country codes. Reference: list of ISO 4217 currency codes`</p> <p>The majority of config changes need to happen in <code>bedrock/settings/base.py</code>:</p> <ol> <li> <p>Add new pricing plan configs to <code>VPN_PLAN_ID_MATRIX</code> for any new countries that require newly created plan IDs (these will be provided by the VPN team). Separate plan IDs for both dev and prod are required for each new currency / language combination (this is because the product QA team need differently configured plans on dev to routinely test things like renewal and cancellation flows). Meta data such as price, total price and saving for each plan / currency should also be provided.</p> <p>Example pricing plan config for $USD / English containing both 12-month and monthly plans:</p> <pre><code>\n</code></pre> VPN_PLAN_ID_MATRIX = { \"usd\": { \"en\": { \"12-month\": { \"id\": ( <p>\"price_1J0Y1iKb9q6OnNsLXwdOFgDr\" if DEV else \"price_1Iw85dJNcmPzuWtRyhMDdtM7\"</p> <p>), \"price\": \"US$4.99\", \"total\": \"US$59.88\", \"saving\": 50, \"analytics\": { \"brand\": \"vpn\", \"plan\": \"vpn\", \"currency\": \"USD\", \"discount\": \"60.00\", \"price\": \"59.88\", \"period\": \"yearly\", },</p> <p>}, \"monthly\": { \"id\": ( \"price_1J0owvKb9q6OnNsLExNhEDXm\" if DEV else \"price_1Iw7qSJNcmPzuWtRMUZpOwLm\" ), \"price\": \"US$9.99\", \"total\": None, \"saving\": None, \"analytics\": { \"brand\": \"vpn\", \"plan\": \"vpn\", \"currency\": \"USD\", \"discount\": \"0\", \"price\": \"9.99\", \"period\": \"monthly\", }, },</p> <p>}</p> <p>}, # repeat for other currency / language configs.</p> <p>}</p> <p>See the Begin Checkout section of the <code>analytics docs&lt;analytics&gt;</code> for more a detailed description of what should be in the analytics objects.</p> </li> <li> <p>Map each new country code to one or more applicable pricing plans in <code>VPN_VARIABLE_PRICING</code>.</p> <p>Example that maps the <code>US</code> country code to the pricing plan config above:</p> <pre><code>\n</code></pre> VPN_VARIABLE_PRICING = { \"US\": { <p>\"default\": VPN_PLAN_ID_MATRIX[\"usd\"][\"en\"],</p> <p>}, # repeat for other country codes.</p> <p>}</p> </li> <li> <p>Once every new country has a mapping to a pricing plan, add each new country code to the list of supported countries in <code>VPN_COUNTRY_CODES</code>. Because new countries need to be added behind a feature switch, you may want to create a new variable temporarily for this until launched, such as <code>VPN_COUNTRY_CODES_WAVE_VI</code>. You can then add these to <code>VPN_COUNTRY_CODES</code> in <code>products/views.py</code> using a simple function like so:</p> <pre><code>\n</code></pre> def vpn_available(request): <p>country = get_country_from_request(request) country_list = settings.VPN_COUNTRY_CODES</p> if switch(\"vpn-wave-vi\"): <p>country_list = settings.VPN_COUNTRY_CODES + settings.VPN_COUNTRY_CODES_WAVE_VI</p> <p>return country in country_list</p> <p>The function could then be used in the landing page view like so:</p> <pre><code>\n</code></pre> <p>vpn_available_in_country = (vpn_available(request),)</p> </li> <li> <p>If you now test the landing page locally, you should hopefully see the newly added pricing for each new country (add the <code>?geo=[INSERT_COUNTRY_CODE]</code> param to the page URL to mock each country). If all is well, this is the perfect time to add new unit tests for each new country. This will help give you confidence that the right plan ID is displayed for each new country / language option.</p> <pre><code>def test_vpn_subscribe_link_variable_12_month_us_en(self):\n    \"\"\"Should contain expected 12-month plan ID (US / en-US)\"\"\"\n    markup = self._render(\n        plan=\"12-month\",\n        country_code=\"US\",\n        lang=\"en-US\",\n    )\n    self.assertIn(\"?plan=price_1Iw85dJNcmPzuWtRyhMDdtM7\", markup)\n\n\ndef test_vpn_subscribe_link_variable_monthly_us_en(self):\n    \"\"\"Should contain expected monthly plan ID (US / en-US)\"\"\"\n    markup = self._render(\n        plan=\"monthly\",\n        country_code=\"US\",\n        lang=\"en-US\",\n    )\n    self.assertIn(\"?plan=price_1Iw7qSJNcmPzuWtRMUZpOwLm\", markup)\n</code></pre> </li> <li> <p>Next, update <code>VPN_AVAILABLE_COUNTRIES</code> to the new total number of countries where VPN is available. Again, because this needs to be behind a feature switch you may want a new temporary variable that you can use in <code>products/views.py</code>:</p> <pre><code>available_countries = settings.VPN_AVAILABLE_COUNTRIES\n\nif switch(\"vpn-wave-vi\"):\n    available_countries = settings.VPN_AVAILABLE_COUNTRIES_WAVE_VI\n</code></pre> </li> <li> <p>Finally, there is also a string in <code>l10n/en/products/vpn/shared.ftl</code> that needs updating to include the new countries. This should be a new string ID, and behind a feature switch in the template:</p> <pre><code>vpn-shared-available-countries-v6 = We currently offer { -brand-name-mozilla-vpn } in Austria, Belgium, Canada, Finland, France, Germany, Ireland, Italy, Malaysia, the Netherlands, New Zealand, Singapore, Spain, Sweden, Switzerland, the UK, and the US.\n</code></pre> <pre><code>{% if switch('vpn_wave_vi') %}\n    {{ ftl('vpn-shared-available-countries-v6', fallback='vpn-shared-available-countries-v5') }}\n{% else %}\n    {{ ftl('vpn-shared-available-countries-v5') }}\n{% endif %}\n</code></pre> </li> <li> <p>After things are launched in production and QA has verified that all is well, don't forget to file an issue to tidy up the temporary variables and switch logic.</p> </li> </ol>"},{"location":"vpn-subscriptions/#excluded-countries","title":"Excluded countries","text":"<p>For a list of country codes where we are legally obligated to prevent purchasing VPN, see <code>VPN_EXCLUDED_COUNTRY_CODES</code> in <code>bedrock/settings/base.py</code>.</p> <p>For a list of country codes where we are also required to prevent downloading the VPN client, see <code>VPN_BLOCK_DOWNLOAD_COUNTRY_CODES</code>.</p>"},{"location":"architecture/decisions/","title":"Index","text":""},{"location":"architecture/decisions/#architectural-decisions","title":"Architectural Decision Records","text":"<p>We record major architectural decisions for bedrock in Architecture Decision Records (ADR), as described by Michael Nygard. Below is the list of our current ADRs.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/","title":"1. Record architecture decisions","text":""},{"location":"architecture/decisions/0001-record-architecture-decisions/#1-record-architecture-decisions","title":"1. Record architecture decisions","text":"<p>Date: 2019-01-07</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#context","title":"Context","text":"<p>We need to record the architectural decisions made on this project.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#decision","title":"Decision","text":"<p>We will use Architecture Decision Records, as described by Michael Nygard.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#consequences","title":"Consequences","text":"<p>See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools.</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/","title":"2. Move CI/CD Pipelines to Gitlab","text":""},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#2-move-cicd-pipelines-to-gitlab","title":"2. Move CI/CD Pipelines to Gitlab","text":"<p>Date: 2019-10-09</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#status","title":"Status","text":"<p>Superseded by 0010</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#context","title":"Context","text":"<p>Our current CI/CD pipelines are implemented in Jenkins. We would like to decommission our Jenkins server by the end of this year. We have implemented CI/CD pipelines using Gitlab in other projects, including basket, nucleus and the snippets-service.</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#decision","title":"Decision","text":"<p>We will move our existing CI/CD pipeline implementation from Jenkins to Gitlab.</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#consequences","title":"Consequences","text":"<p>We will continue to use www-config to version control our Kubernetes yaml files, but we will replace the use of git-sync-operator and its branch with self-managed instances of gitlab runner executing jobs defined in a new .gitlab-ci.yml file leveraging what we have learned implementing similar solutions in nucleus-config, basket-config, and snippets-config. We will also eliminate our last dependency on Deis Workflow, which we have been using for dynamic demo deployments based on the branch name, in favor of a fixed number of pre-configured demo deployments, potentially supplemented by Heroku Review Apps.</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/","title":"3. Use Cloudflare Workers and Convert for multi-variant testing","text":""},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#3-use-cloudflare-workers-and-convert-for-multi-variant-testing","title":"3. Use Cloudflare Workers and Convert for multi-variant testing","text":"<p>Date: 2019-10-09</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#context","title":"Context","text":"<p>Our current method for implementing multi-variant tests involves frequent, often non-trivial code changes to our most high traffic download pages. Prioritizing and running concurrent experiments on such pages is also often complex, increasing the risk of accidental breakage and making longer-term changes harder to roll out. Our current tool, Traffic Cop, also requires significant custom code to accomodate these types of situations. Accurately measuring and reporting on the outcome of experiments is also a time consuming step of the process for our data science team, often requiring custom instrumentation and analysis.</p> <p>We would like to make our end-to-end experimentation process faster, with increased capacity, whilst also minimizing the performance impact and volume of code churn related to experiments running on our most important web pages.</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#decision","title":"Decision","text":"<p>We will use Cloudflare Workers to redirect a small percentage of traffic to standalone, experimental versions of our download pages. The worker code will live in the www-workers repository. We will implement a (vetted and approved) third-party experimentation tool called Convert for use on those experimental pages.</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#consequences","title":"Consequences","text":"<p>Convert experiment code will be separated from our main web pages, where the vast majority of our traffic is routed. This will minimize code churn on our most important pages, and also reduce the performance impact and risks involved in using a third-party experimentation tool. Using Cloudflare Workers to redirect traffic to experimental pages also has significant performance benefits over handling redirection client-side.</p> <p>In terms of features, Convert offers a custom dashboard for configuring, prioritizing, and running multi-variant tests. It also has built-in analysis and reporting tools, which are all areas where we hope to see significant savings in time and resources.</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/","title":"4. Use Fluent For Localization","text":""},{"location":"architecture/decisions/0004-use-fluent-for-localization/#4-use-fluent-for-localization","title":"4. Use Fluent For Localization","text":"<p>Date: 2019-12-16</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#context","title":"Context","text":"<p>The current localization (l10n) system uses the outdated and unsupported .lang format, which our l10n team would prefer to no longer support. Mozilla's current l10n standard for products and websites is Fluent.</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#decision","title":"Decision","text":"<p>In order to update our l10n practices and technology and support from Mozilla's existing l10n infrastructure and teams we will decomission the .lang system in bedrock and implement one based on Fluent. We will support both during a transition period.</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#consequences","title":"Consequences","text":"<p>Dealing with strings and templates is very different in Fluent (see the updated bedrock docs). There will be a period of developer training and adjustment to the new way of writing and previewing templates. The biggest change is that strings are no longer in the templates at all, and are instead referenced by string IDs which are in Fluent files (.ftl files).</p> <p>The positive side of this change is that the developer has total control over the strings in the translation files and there are no string extraction or merge steps.</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/","title":"5. Use a Single Docker Image For All Deployments","text":""},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#5-use-a-single-docker-image-for-all-deployments","title":"5. Use a Single Docker Image For All Deployments","text":"<p>Date: 2020-07-07</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#context","title":"Context","text":"<p>We currently build an individual docker image for each deployment (dev, stage, and prod) that contains the proper data for that environment. It would save time and testing if we only built a single image that could be promoted to each environment and loaded with the proper data at startup.</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#decision","title":"Decision","text":"<p>We will use a Kubernetes DaemonSet to ensure that a data updater pod is running on each node in a cluster. This pod will keep the database and l10n files updated in a volume that will be used by the other bedrock pods to access the data.</p> <p>GitHub issue</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#consequences","title":"Consequences","text":"<p>This change means that bedrock will be more simple to run because each pod will no longer need to be responsible for keeping its data updated, and so it will run only the bedrock web process and not also the updater daemon. It also means that there is a risk of a bedrock pod being run on a node that hasn't had the updater pod run yet, so there would be no available data. We will handle this by ensuring that bedrock won't start when the data isn't available, and so k8s will not send traffic to those pods until they're successfully up and responding, and will keep trying to start pods on the node untill they succeed.</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/","title":"6. Revise tooling for Python dependency management","text":""},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#6-revise-tooling-for-python-dependency-management","title":"6. Revise tooling for Python dependency management","text":"<p>Date: 2022-02-25</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#status","title":"Status","text":"<p>Superseded by 0007, but the context in this ADR is still useful</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#context","title":"Context","text":"<p>At the moment of revisiting our dependency-management approach, Bedrock's Python dependencies were installed from a hand-cut <code>requirements/*.txt</code> files which (sensibly) included hashes so that we could be sure about what our Python package installer, <code>pip</code>, was actually installing.</p> <p>However, this process was onerous: * We had a number of requirements files, <code>base</code>, <code>prod</code>, <code>dev</code>, <code>migration</code> (no longer required but still being processed at installation time) and <code>docs</code> - all of which had to be hand-maintained. * Hashes needed to be generated when adding/updating a dependency. This was done with a specific tool <code>hashin</code> and needed to be done for each requirement. * When <code>pip</code> detects hashes in a requirements file, it automatically requires hashes for all packages it installs, including subdependencies of dependecies mentioned in <code>requirements/*.txt</code>. This in turn meant that adding or updating a new dep often required hashing-in one or more subdeps -- and at worst, a change or niggle with <code>pip</code> would result in a new subdep being implicitly required, which would then fail to install because it was not hashed in to the requirements file.</p> <p>Other projects (both within MEAO and across Mozilla) used more sophisticated dependency management tools, including: * <code>pip-tools</code> - which draws reqs from an input file and generates a requirements.txt complete with hashes * <code>pip-compile-multi</code> - which extends pip-tools' behaviour to support multiple output files and shared input files * <code>poetry</code> - which combines a lockfile approach with a standalone virtual environment * <code>pipenv</code> - which similarly combines a lockfile with a virtual environment * <code>conda</code> - a language-agnostic package manager and environment management system * simply <code>pip</code></p> <p>The ideal solution would support all of the following: * Simple input file format/syntax * Ability to pin dependencies * Support for installing with hash-checking of packages * Automatic hashing of requirements, rather than having to manually do it with <code>hashin</code> et al. * Support for multiple build configurations (eg prod, dev, docs) * Dependabot compatibility, so we still get alerts and updates * An unopinionated approach to virtualenvs \u2013 can work with and without them, so that developers can use the virtualenv tooling they prefer and we don't have to use a virtualenv in our containers if we don't want to * Sufficiently active maintenance of the project * Use/knowledge of the tooling elsewhere in the broader organisation</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#decision","title":"Decision","text":"<p>After evaluating the above, including <code>pip-tools</code>, <code>pip-compile-multi</code> and <code>poetry</code> in greater depth, <code>pip-compile-multi</code> was selected.</p> <p>Significant factors were how allows us to pin our top-level dependencies in a clutter-free input format, supports inheritance between files and miltiple output files with ease, and it automatically generates hashes for subdependencies.</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#consequences","title":"Consequences","text":"<p><code>pip-compile-multi</code> has been easily integrated into the Bedrock workflow, but there is one non-trivial downside: Github's Dependabot service does not play well with the combination of multiple requirements files and inheritance between them. As such, does not currently produce reliable updates (either partial updates or some requirements files seem to be ignored entirely). See https://github.com/dependabot/dependabot-core/issues/536</p> <p>Strictly, though, we don't need the convenience of Dependabot - we have a <code>make</code> command to identify stale deps and recompiling is another, single, <code>make</code> command. Also, we're more likely to compile a bunch of Dependabot PRs into one changeset (eg with <code>paul-mclendahand</code>), than to merge them straight to <code>master</code>/<code>main</code> one at at time. As long as we're getting Github security alerts for vulnerable dependencies, we'll be OK.</p> <p>That said, if we did find we needed Dependabot compatibility, <code>pip-tools</code> and some extra legwork in the Makefile to deal with prod, dev and docs deps separately would likely be a viable alternative.</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/","title":"7. Further revise tooling for Python dependency management","text":""},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#7-further-revise-tooling-for-python-dependency-management","title":"7. Further revise tooling for Python dependency management","text":"<p>Date: 2022-03-02</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#context","title":"Context","text":"<p>While pip-compile-multi gave us plenty fot benefits (see ADR 0006) the lack of Dependabot support was an annoyance and replacing it with alternatives seemed fairly involved.</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#decision","title":"Decision","text":"<p>We've downgraded to regular <code>pip-compile</code> and instead are doing the extra legwork in the Makefile instead. The input files are indentical, so we do not need to pin sub-dependencies, and we still get automatic hash generation for all packages.</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#consequences","title":"Consequences","text":"<p>There should be no downsides to switching away from pip-compile-multi in this context. If Dependabot still does not manage to parse our multiple requirements files, we should look to renaming them in case that tips the balance (as has been suggested by a colleague)</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/","title":"8. Move Demos To GCP","text":""},{"location":"architecture/decisions/0008-move-demos-to-gcp/#8-move-demos-to-gcp","title":"8. Move Demos To GCP","text":"<p>Date: 2022-07-14</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#context","title":"Context","text":"<p>Previously, demos for Bedrock were run on Heroku. This worked fine, but Heroku's recent security incident there meant our integration had to be disabled, prompting discussion of self-managed demo instances.</p> <p>In addition, while it was possible to demo Bedrock in Pocket Mode on Heroku, by amending the settings via the Heroku web UI, the domains set up (www-demoX.allizom.org) were originally set up for Mozorg, and as such may be confusing for colleagues reviewing Pocket changes. Flipping and un-flipping settings in Heroku to enable Mozorg Mode or Pocket Mode was also extra legwork that we ideally would do without, too.</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#decision","title":"Decision","text":"<p>We have implemented a new, self-managed, approach to running demos, using a handful of Google Cloud Platform services. Cloud Build and Cloud Run are the most significant ones.</p> <p>Cloud Build has triggers which monitor pushes to specific branches, then builds a Bedrock container from the branch, using the appropriate env vars for Pocket or Mozorg use, including the SITE_MODE env var that specifies the mode Bedrock runs in.</p> <p>Cloud Run then deploys the built container as a 'serverless' webapp. By default, supervisord runs in the container, so it updates DB and L10N files automatically.</p> <p>This process is triggered by a simple push to a specific target branch. e.g. pushing code to mozorg-demo-2 will result in the relevant code being deployed in Mozorg mode to www-demo2.allizom.org, while pushing to pocket-demo-4 will deploy it to www-demo4.tekcopteg.com in Pocket mode.</p> <p>Environment variables can also be configured by developers, via two dedicated env files in the Bedrock codebase, which are only used for demo services. Clashes are unlikely, and can still be managed with common sense.</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#consequences","title":"Consequences","text":"<p>Upsides:</p> <p>It is now easier to stand up Pocket demos in addition to existing Mozorg demos, plus we have full control over the infrastructure our demos are run on.</p> <p>We will no longer need to use Heroku for demos. In the future, we may also be able to support ad-hoc 'review apps', which we have also used Heroku for in the past.</p> <p>Downsides:</p> <p>1) If a new secret value is required on a demo instance, and so that value cannot go into the demo env vars file because our codebase is public, some SRE-like devops is needed to add that secret value to GCP's Secret Manager Service. This can be quick, but requires understanding how that side fits together, plus access, so may need a backender to add them.</p> <p>2) At the moment, only the MEAO Backend team have GCP access, which is handy to monitor whether a demo has successfull be pushed out, or to amend secrets, etc. Both of these issues can be addressed without a lot of work.</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/","title":"9. Manage Contentful schema state via migrations","text":""},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#9-manage-contentful-schema-state-via-migrations","title":"9. Manage Contentful schema state via migrations","text":"<p>Date: 2022-09-09</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#status","title":"Status","text":"<p>Superseded by 0012</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#context","title":"Context","text":"<p>Our chosen CMS Contentful is powerful and can be configured via its UI  quite easily. However, wanted to bring this under control using migrations so that changes are explicit, reviewable, repeatable and stored. This would be a key part of moving to a \"CMS-as-Code\" approach to using Contentful, where content-type changes and data migrations (outside of regular content entry) are managed via code.</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#decision","title":"Decision","text":"<p>We wanted to have as close as possible to the experience provided by the excellent Django Migrations framework, where we would:</p> <ul> <li>be able to script migrations, rather than resort to \"clickops\"</li> <li>be able to apply them individually or en masse</li> <li>be able to store the state of which migrations have/have not been applied in a central datastore (and ideally Contentful)</li> </ul> <p>We experimented with hand-cutting our own framework, which was looking viable, but then we came across https://github.com/jungvonmatt/contentful-migrations which does all of the above. We've evaluated it and it seems fit for purpose, even if it has some gaps, so we've adopted it as our current way to manage and apply migrations to our Contentful setup.</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#consequences","title":"Consequences","text":"<p>We've gained a tool that enables code-based changes to Contentful, which helps in two ways:</p> <p>1) It enables and eases the initial work to migrate from Legacy Compose to new Compose (these are both ways of structuring pages in Contentful) 2) It lays tracks for moving to CMS-as-Code</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/","title":"10. Move CI to Github Actions for Unit and Integration tests","text":""},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#10-move-ci-to-github-actions-for-unit-and-integration-tests","title":"10. Move CI to Github Actions for Unit and Integration tests","text":"<p>Date: 2023-04-06</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#context","title":"Context","text":"<p>Prior to this work, Bedrock's CI/CD pipeline involved Github, Gitlab and CircleCI. We were mirroring from Github to Gitlab to benefit from Gitlab's CI tooling for our functional integration tests, including private (i.e. Mozilla-managed) runners.</p> <p>Additionally, we were using a third party (CircleCI) to run our Python and JS unit tests.</p> <p>Since then, two things have changed:</p> <ol> <li>Github Actions (GHA) have arrived</li> <li>We are now able to use private runners with GHA</li> </ol>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#decision","title":"Decision","text":"<p>We will move our CI/CD pipeline from being a combination of Github + Gitlab + CircleCI to just Github, using GHA.</p> <p>This will mean:</p> <ol> <li>The mirroring to Gitlab will no longer be necessary.</li> <li>Unit tests move from CircleCI to GHA. They will continue to be run on every PR raised against <code>mozilla/bedrock</code>.</li> <li>Functional/integration tests move from Gitlab to GHA. They will still be triggered by a successful deployment to dev/test/stage/prod.</li> </ol> <p>This work will be carried out in parallel with changes to how our deployment pipeline works, as that side is also being moved out of Gitlab and into GHA + GCP. When a deployment succeeds, a GHA in the deployment repo will trigger a GHA in <code>mozilla/bedrock</code>, which will then run the functional integration tests.</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#consequences","title":"Consequences","text":""},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#pros","title":"Pros","text":"<ul> <li>We're no longer mirroring from Github to Gitlab, which will make understanding the deployment pipeline easier for new (and current) developers</li> <li>We will no longer have Gitlab in our pipeline, removing a potential point of failure that could block releases</li> <li>We can still use private runners for our functional integration tests and more (just via GHA instead of Gitlab), giving us control over security and machine resource spec</li> </ul>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#cons","title":"Cons","text":"<ul> <li>There's a risk that there will still be new race conditions or CI kick-off failures if the webhook from the deployment repo to mozilla/bedrock fails.</li> <li>We will not all get visibility of a failed webhook ping from the deployment repo's GHA, because that's locked down to be private. We can mitigate this risk with a sensible pattern of Slack notifications (e.g. Start, Success, Failure), so a missing notification will itself be a significant thing.</li> </ul>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/","title":"11. Use StatsD for metrics collection","text":""},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#11-use-statsd-for-metrics-collection","title":"11. Use StatsD for metrics collection","text":"<p>Date: 2023-05-19</p>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#context","title":"Context","text":"<p>We need to implement a metrics collection solution to gain insights into the performance and behavior of bedrock. Metrics play a crucial role in understanding system health, identifying bottlenecks, and making informed decisions for optimization and troubleshooting.</p>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#decision","title":"Decision","text":"<p>StatsD is a proven open-source solution that provides a lightweight and scalable approach to capturing, aggregating, and visualizing application metrics. It offers numerous benefits that align with bedrock's needs:</p> <ol> <li> <p>Simplicity and Ease of Integration: StatsD is easy to install and integrate into our existing Python codebase. It provides a simple API that allows us to instrument our code and send metrics with minimal effort.</p> </li> <li> <p>Aggregation and Sampling: StatsD supports various aggregation methods, such as sum, average, maximum, and minimum, which can be applied to collected metrics. Additionally, it provides built-in support for sampling, allowing us to reduce the volume of metrics collected while still maintaining statistical significance.</p> </li> <li> <p>Scalability: StatsD is designed to handle high volumes of metrics and can easily scale horizontally to accommodate increasing demands. It relies on a fire-and-forget mechanism, where the metrics are sent asynchronously, ensuring minimal impact on the performance of our application.</p> </li> <li> <p>Integration with Monitoring and Visualization Tools: At Mozilla we already have a stack available and configured by SRE that uses StatsD along with Telegraf to send metrics to Grafana for visualization and monitoring. This integration will enable us to analyze and visualize our metrics, create dashboards, and set up alerts for critical system thresholds.</p> </li> </ol>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#overview-of-how-statsd-telegraf-and-grafana-work-together","title":"Overview of how StatsD, Telegraf, and Grafana work together.","text":"<p>Here's an overview of how these tools fit into the workflow:</p> <ul> <li>StatsD:   StatsD is responsible for collecting and aggregating metrics data within the application.  It   provides a simple API that allows us to instrument our code and send metrics to a StatsD server.   StatsD operates over UDP and uses a lightweight protocol for sending metrics.</li> <li>Telegraf:   Telegraf is an agent-based data collection tool that can receive metrics from various sources,   including StatsD. Telegraf acts as an intermediary between the data source (StatsD) and the data   visualization tool (Grafana). It can collect, process, and forward metrics data to different   destinations.</li> <li>Grafana:   Grafana is a popular open-source data visualization and monitoring tool. It provides a rich set of   features for creating dashboards, visualizing metrics, and setting up alerts. Grafana can connect   to Telegraf to retrieve metrics data and display it in a user-friendly and customizable manner.</li> </ul>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#consequences","title":"Consequences","text":"<ol> <li> <p>Metrics Design and Instrumentation: Proper metrics design and instrumentation are crucial to deriving meaningful insights. We need to invest time and effort in identifying the key metrics to capture and strategically instrument our codebase to provide actionable data for analysis.</p> </li> <li> <p>Operational Overhead: Introducing a new tool requires additional operational effort for monitoring, maintaining, and scaling the StatsD infrastructure. However, since this infrastructure is in use currently by other projects within Mozilla, this overhead is already being assumed and is spread out across projects.</p> </li> <li> <p>Integration Effort: While integrating StatsD into bedrock is relatively straightforward, we will need to allocate development time to instrument our codebase and ensure that metrics are captured at relevant points within the application.</p> </li> </ol>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#considerations-and-best-practices-for-metrics-design","title":"Considerations and best practices for metrics design","text":"<ul> <li>Identify Key Metrics:   Identify the key aspects of our website that we want to monitor and measure. These could include   response times, error rates, database query performance, and cache hit ratios.</li> <li>Granularity and Context:   Determine the appropriate level of granularity for our metrics. We can choose to measure metrics   at the application level, specific Django views, individual API endpoints, or even down to   specific functions or code blocks within bedrock.</li> <li>Define Consistent Metric Names:   Choose meaningful and consistent names for our metrics. This helps in easily understanding and   interpreting the collected data. </li> <li>Timing Metrics:   Use timing metrics to measure the duration of specific operations. This can include measuring the   time taken to render a template, execute a database query, or process a request.  StatsD provides   a timing metric type that captures the duration and calculates statistics such as average,   maximum, and minimum durations.</li> <li>Counting Metrics:   Use counting metrics to track occurrences of specific events. This can include counting the number   of requests received or the number of errors encountered. StatsD supports counting metric types   that increments a value each time an event occurs.</li> <li>Sampling:   Consider implementing sampling to reduce the number of metrics collected while still maintaining   statistical significance. We can selectively sample a subset of requests or events to ensure a   representative sample of data for analysis if a particular metric is of high volume.</li> <li>Re-evaluate often:   Continuously evaluate our metrics and refine them based on changing requirements and insights   gained from analysis.</li> </ul>"},{"location":"architecture/decisions/0012-wagtail-for-cms/","title":"12. Use Wagtail CMS","text":""},{"location":"architecture/decisions/0012-wagtail-for-cms/#12-use-wagtail-as-bedrocks-cms","title":"12. Use Wagtail as Bedrock's CMS","text":"<p>Date: 2024-04-15</p>"},{"location":"architecture/decisions/0012-wagtail-for-cms/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0012-wagtail-for-cms/#context","title":"Context","text":"<p>As Bedrock evolves, expanding the number of content-managed pages will give us greater agility. We needed to evaluate our options and pick a best-fit solution.</p>"},{"location":"architecture/decisions/0012-wagtail-for-cms/#decision","title":"Decision","text":"<p>We previously used Contentful as a headless CMS, but have decided (https://docs.google.com/document/d/1icqCOtCIMhducdrlKKYRBfGsbwsyrFTUH1wvjVldbKo/edit) to move to Wagtail CMS (wagtail.org), which we'll integrate with the Bedrock codebase (https://docs.google.com/document/d/1aQc-FRhI69XQwoaXmvbp9s7zy8UaCVQhZyF6RGTt4Lk/edit)</p>"},{"location":"architecture/decisions/0012-wagtail-for-cms/#consequences","title":"Consequences","text":"<ul> <li> <p>The integration of a Django-based CMS into the Bedrock codebase will allow for a significantly faster and clearer developer experience when creating content-managed pages, plus the option (over time) for members of the org to create new pages based on CMS templates with no development needed, unless the pages have new designs.</p> </li> <li> <p>There is a significant amount of engineering work needed, including:</p> </li> <li>We'll need to integrate Wagtail into Bedrock, which first necessitates  refactoring away our bespoke i18n mechanism and using Django's own i18n logic.</li> <li>We'll need to develop workflows around adding Wagtail-managed pages that the whole team understands</li> <li>We'll need to integrate Wagtail with our chosen localization vendor, which requires a custom integration</li> <li>Because we have stopped using Contentful as a source of data, we have the last exported state of the data in our DB, and will need to migrate pages that previously used Contentful to the new CMS</li> </ul>"},{"location":"attribution/","title":"Index","text":""},{"location":"attribution/#attribution","title":"Attribution","text":"<p>Attribution is the practice of recording the main touch points that a website visitor encounters on their path to downloading or signing up for one of our products. It often involves a multi-step user journey, sometimes across multiple properties, but the goal is to end up with informative data that tells us where the user of a product initially came from, and what their journey looked like along the way.</p> <p>These documents define how attribution works for the different products on our websites.</p> <ul> <li>Mozorg analytics</li> <li>Mozilla CJMS affiliate attribution</li> <li>Managing Data Privacy and Consent</li> <li>Mozilla accounts attribution</li> <li>Firefox desktop attribution</li> <li>Firefox mobile attribution</li> </ul>"},{"location":"attribution/0001-analytics/","title":"Mozorg Analytics","text":""},{"location":"attribution/0001-analytics/#analytics","title":"Mozorg analytics","text":""},{"location":"attribution/0001-analytics/#google-analytics","title":"Google Analytics","text":"<p>We use Google Analytics (GA) to track how our website is used.</p> <p>Implementation</p> <p>Google calls a 3<sup>rd</sup> party JavaScript library that is imported by adding a script tag to a website, Google names these \"tags\".</p> <p>We include the tag for Google Tag Manager (GTM) on our website. GTM is a service meant to simplify and centralize the tags included on a website in cases where multiple tags are needed. Their web-based user interface can then be used to watch for user actions on the website and then trigger events to be sent to tags.</p> <p>We do no not use any of GTM's most powerful features. Our use of GTM is a historical artifact of our Universal Analytics (UA) (aka GA3) implementation. GTM is a tool to let non-technical users add code to a website, however, there is no one outside of the websites team who is trained to do that.</p> <p>The only tag we include with GTM is the Google Tag (GTag), and that in turn connects to our Google Analytics (GA) account.</p> <p>There are three ways we send events from our site to GA:</p> <ol> <li>Google's Enhanced Event Measurement logs certain events automatically.</li> <li>GTM watches elements with specific data-attributes for user interaction</li> <li>Bedrock watches for specific events, formats them, and sends them to GTM using the dataLayer</li> </ol> <p>Implementation Principles</p> <p>The current implementation tries very hard to keep any kind of logic and formatting of our events in bedrock where it can be tested, code reviewed, and version controlled.</p> <p>Many user interactions will trigger multiple events. For example: clicking the \"get subscription\" button on the VPN page will trigger <code>link</code>, <code>cta_click</code>, and <code>begin_checkout</code> events. This is totally fine.</p> <p>If you're creating a new event use the two word noun_verb scheme that Google came up with and use snake_case, even if one of your noun or verb is more than one word.</p> <p>Debugging</p> <ul> <li>GTM is managed with Tag Manager https://tagmanager.google.com/</li> <li>Our gTag is also managed with Tag Manager https://tagmanager.google.com/#/home#tags</li> <li>GA, GTM, and gTag can be debugged using Tag Assistant https://tagassistant.google.com/</li> <li>GA also has a debug view https://support.google.com/analytics/answer/7201382?hl=en</li> </ul>"},{"location":"attribution/0001-analytics/#how-can-visitors-opt-out-of-ga","title":"How can visitors opt out of GA?","text":"<p>Visitors to the website can opt-out of loading Google Analytics on our website by enabling Do Not Track (DNT) in their web browser. We facilitate this by using a DNT helper that our team maintains. We also respect Global Privacy Control (GPC) as an additional opt-out signal.</p> <p>Alternatively, visitors can also opt-out of GA by visiting the cookie settings page, which is linked to in the main site footer on every page.</p>"},{"location":"attribution/0001-analytics/#event-tracking","title":"Event Tracking","text":""},{"location":"attribution/0001-analytics/#enhanced-event-measurement","title":"Enhanced Event Measurement","text":"<p>Pageviews, scrolls, video events, and outbound link clicks are being collected using GA4's enhanced event measurement.</p> <p>Some form submissions are also being collected but newsletter signups are not (see bug #13348) . They are instead being tracked with the <code>newsletter_subscribe</code> event.</p> <p>See the full list of events GA collects by default. https://support.google.com/analytics/answer/9216061</p>"},{"location":"attribution/0001-analytics/#data-attributes","title":"Data Attributes","text":"<p>One place where we do still rely on GTM to watch for an trigger events is when we use data-attributes to pass information. There are only two events we do this with and they are primarily used on buttons and links.</p>"},{"location":"attribution/0001-analytics/#cta-click","title":"CTA Click","text":"<p>CTA (\"Call to Action\") click is intented to track the one or two main actions the page is designed to get the user to do. This data-attribute can be used on either <code>&lt;button&gt;</code> or <code>&lt;a&gt;</code>. Links can go to or away from the site, a button might trigger a JS function instead of going away from the page, that's still a cta.</p> <p>The attribute <code>data-cta-text</code> must be present to trigger the event. All links to accounts.mozilla.com must also use <code>data-cta-type</code>.</p> Data Attribute Expected Value <code>data-cta-text</code> * Text or name of the link (e.g. <code>Sign Up</code>, <code>Start Here</code>, <code>Get Relay</code>, <code>See your report</code>, <code>Read the Manifesto</code>). -   This does not need to exactly match the text displayed to the user -   Defining this is useful to group the link clicks across locales -   -   this attribute is required <code>data-cta-position</code> Location of CTA on the page (e.g. <code>primary</code>, <code>secondary</code>, <code>banner</code>, <code>pricing</code>) <code>data-cta-type</code> fxa-servicename (e.g. <code>fxa-sync</code>, <code>fxa-monitor</code>, <code>fxa-vpn</code>, <code>monitor</code>, <code>relay</code>, <code>pocket</code>) -   This is to group CTAs by their destination -   Do not use this to identify the element (ie. link, button) <code>data-cta-name</code> A identifier for this cta that is unique across the entire site. (e.g. <code>fx20-primarycta</code>, <code>wnp118-sfaq-so-special-features</code>). This is to help with reporting since it is difficult to filter on more than one parameter at a time. <pre><code>&lt;a href=\"https://monitor.firefox.com/\" data-cta-text=\"Check for breaches\" data-cta-type=\"fxa-monitor\"&gt;Check for breaches&lt;/a&gt;\n\n&lt;a href=\"{{ url('firefox.browsers.mobile.get-app') }}\" data-cta-text=\"Send Link for Firefox Mobile\" data-cta-position=\"banner\"&gt;Send me a link&lt;/a&gt;\n\n&lt;a href=\"{{ url('firefox.browsers.mobile.ios') }}\" data-cta-text=\"Firefox for iOS\"&gt;Firefox for iOS&lt;/a&gt;\n</code></pre>"},{"location":"attribution/0001-analytics/#link-click","title":"Link Click","text":"<p>Link click is intended to track links that are of interest but not the focus of the page. Examples include links in paragraphs, lists, FAQs, supplemental content, or in a navigation menu. Links can go to or away from the site.</p> <p>The attribute <code>data-link-text</code> must be present to trigger the event.</p> Data Attribute Expected Value <code>data-link-text</code> * Text or name of the link (e.g. <code>Monitor</code>, <code>Features</code>, <code>Instagram (mozilla)</code>, <code>Mozilla VPN</code>). - * this attribute is required <code>data-link-position</code> Location of CTA on the page (e.g. <code>topnav</code>, <code>subnav</code>, <code>body</code>, <code>features</code>) <pre><code>&lt;p&gt;This is text with a &lt;a href=\"#\" data-link-text=\"simple\"&gt;simple&lt;/a&gt;example.&lt;/p&gt;\n\n&lt;li&gt;&lt;a href=\"{{ url('firefox.features.pdf-editor') }}\" data-link-text=\"Edit PDFs\"&gt;Edit PDFs&lt;/a&gt; on the go within your Firefox browser window.&lt;/li&gt;\n</code></pre> <p>Link click is also commonly used for navigation menus. If you wish to indicate that a link is nested you can include the categories seperated by a dash (<code>topnav - firefox</code>, <code>footer - company</code>)</p> <pre><code>&lt;li&gt;&lt;a href=\"{{ url('firefox.developer.index') }}\" data-link-text=\"Firefox Developer Edition\" data-link-position=\"footer\"&gt;{{ ftl('footer-developer-edition') }}&lt;/a&gt;&lt;/li&gt;\n\n&lt;li&gt;&lt;a href=\"{{ url('firefox.browsers.mobile.android') }}\" data-link-text=\"Firefox for Android\" data-link-position=\"topnav - firefox\"&gt;&lt;/li&gt;\n</code></pre>"},{"location":"attribution/0001-analytics/#data-layer-events","title":"Data Layer Events","text":"<p>The data layer is a JS object we can push events to and GTM will read from it.</p> <pre><code>window.dataLayer.push({'event': 'event_name'});\n</code></pre> <p>We push a mix of recommended events and custom events to the data layer. When creating a new custom event please follow the Implementation Principles outlined above. Remember, both GTM and GA must be configured to recieve new events.</p> <p>https://developers.google.com/analytics/devguides/collection/ga4/reference/events?client_type=gtag#begin_checkout</p> <p>https://mozilla-hub.atlassian.net/wiki/spaces/EN/pages/430866463/GA4+Custom+Events</p> <p>https://developers.google.com/tag-platform/tag-manager/datalayer</p> <p>Events that bedrock will send to GTM include:</p> <ul> <li>begin_checkout</li> <li>cta_click</li> <li>default_browser_set</li> <li>dimension_set</li> <li>experiment_view</li> <li>link_click</li> <li>newsletter_subscribe</li> <li>product_download (firefox_download, firefox_mobile_download, etc)</li> <li>send_to_device</li> <li>social_share</li> <li>stub_session_set</li> <li>widget_action</li> </ul>"},{"location":"attribution/0001-analytics/#begin-checkout","title":"Begin Checkout","text":"<p>We are using GA4's recommended eCommerce event begin_checkout for VPN referrals to the FxA Subscription Platform with purchase intent. This event can accept values for other products but we are not currently using it for anything other than VPN.</p> <p>Note</p> <p>Any link to Mozilla accounts should also be using <code>mozilla accounts attribution&lt;mozilla-accounts-attribution&gt;</code></p> <p><code>datalayer-begincheckout.es6.js</code> contains generic functions that can be called on to push the appropriate information to the dataLayer. The script is expecting the following values:</p> Property Value <code>item_id</code> Text or name of the link (e.g. <code>Sign Up</code>, <code>Join Now</code>, <code>Start Here</code>). <code>brand</code> fxa-servicename (e.g. <code>fxa-sync</code>, <code>fxa-monitor</code>) <code>plan</code> Location of CTA on the page (e.g. <code>primary</code>, <code>secondary</code>, <code>header</code>) <code>period</code> Location of CTA on the page (e.g. <code>primary</code>, <code>secondary</code>, <code>header</code>) <code>price</code> Location of CTA on the page (e.g. <code>primary</code>, <code>secondary</code>, <code>header</code>) <code>currency</code> Location of CTA on the page (e.g. <code>primary</code>, <code>secondary</code>, <code>header</code>) <code>discount</code> Location of CTA on the page (e.g. <code>primary</code>, <code>secondary</code>, <code>header</code>) <ul> <li>item_id: Stripe Plan ID</li> <li>brand: <code>relay</code>, <code>vpn</code>, or <code>monitor</code></li> <li> <p>plan:</p> <ul> <li><code>vpn-monthly</code></li> <li><code>vpn-yearly</code></li> <li><code>vpn-relay-yearly</code></li> <li><code>relay-email-monthly</code></li> <li><code>relay-email-yearly</code></li> <li><code>relay-phone-monthly</code></li> <li><code>relay-phone-yearly</code></li> <li><code>monitor-monthly</code></li> <li><code>monitor-yearly</code></li> </ul> </li> <li> <p>period: <code>monthly</code> or <code>yearly</code></p> </li> <li> <p>price: cost displayed at checkout, pre tax (example: 119.88)</p> </li> <li> <p>currency: in 3-letter ISO 4217 format (examples: USD, EUR)</p> </li> <li> <p>discount: value of the discount in the same currency as price (example: 60.00)</p> </li> </ul> <p>There are two ways to use TrackBeginCheckout:</p> <p>1)  Call the function passing the values directly.</p> <pre><code>TrackBeginCheckout.getEventObjectAndSend(item_id, brand, plan, period, price, currency, discount)\n</code></pre> <p>2)  Pass the values as a data attribute.</p> <p>The <code>vpn_subscribe_link</code> will automatically generate a <code>data-ga-item</code> object and add the <code>ga-begin-checkout</code> class to links they create -- as long as there is analytics information associated with the plan in its lookup table.</p> <p>To use this method you will need to include <code>datalayer-begincheckout-init.es6.js</code> in the page bundle.</p> <pre><code>&lt;a href=\"{{ fxa link }}\"\n    class=\"ga-begin-checkout\"\n    data-ga-item=\"{\n        'id' : 'price_1Iw7qSJNcmPzuWtRMUZpOwLm',\n        'brand' : 'vpn',\n        'plan' : 'vpn',\n        'period' : 'monthly',\n        'price' : '9.99',\n        'discount' : '0',\n        'currency' : 'USD'\n    }\"\n&gt;\n    Get monthly plan\n&lt;/a&gt;\n</code></pre>"},{"location":"attribution/0001-analytics/#default-browser","title":"Default Browser","text":"<p>Trigger this event when a user sets their default browser to Firefox. It's an important conversion for us!</p> <pre><code>window.dataLayer.push({\n    event: 'default_browser_set',\n});\n</code></pre>"},{"location":"attribution/0001-analytics/#newsletter-subscribe","title":"Newsletter Subscribe","text":""},{"location":"attribution/0001-analytics/#product-downloads","title":"Product Downloads","text":"<p>Important</p> <p>VPN support has not been added. Firefox, Firefox Mobile, Focus, Klar, and Pocket are currently supported.</p> <p>When the user signals their intent do install one of our products we log a download event named for the product. This intent could be: clicking an app store badge, triggering a file download, or sending themselves the link using the send to device widget. The events are in the format [product name]_download and all function the same. So they use the same JavaScript \"TrackProductDownload\". For this documentation the following custom events will be talked about as <code>product_download</code> :</p> <ul> <li><code>firefox_download</code></li> <li><code>firefox_mobile_download</code></li> <li><code>focus_download</code></li> <li><code>klar_download</code></li> <li><code>pocket_download</code></li> </ul> <p>Properties for use with <code>product_download</code> (not all products will have all options):</p> <ul> <li>product (one of: firefox, firefox_mobile, focus, klar, pocket, vpn)</li> <li>platform optional (one of: win, win-msi, win64, win64-msi, win64-aarch64, macos, linux, linux64, android, ios)</li> <li>method (one of: site, store, or adjust)</li> <li>release_channel optional (one of: release, esr, devedition, beta, nightly)</li> <li>download_language optional (example: en-CA)</li> </ul> <p>There are two ways to use TrackProductDownload:</p> <p>1)  Call the function, passing it the same URL you are sending the user to:</p> <pre><code>TrackProductDownload.sendEventFromURL(downloadURL);\n</code></pre> <p>2)  Add a class to the link:</p> <pre><code>&lt;a href=\"{{ link }}\" class=\"ga-product-download\"&gt;Link text&lt;/a&gt;\n</code></pre> <p>You do NOT need to include <code>datalayer-productdownload-init.es6.js</code> in the page bundle, it is already included in the site bundle.</p> <p>Note</p> <p>Most apps listed in appstores.py are supported but you may still want to check that the URL you are tracking is identified as valid in <code>`</code>isValidDownloadURL <code>` and will be recognized by</code>getEventFromUrl`.</p> <p>If you would like to track something as a download that is not currently in the appstores.py you can get and send the event object manually. This most often happens with adjust links generated for specific campaigns:</p> <pre><code>let customEventObject = TrackProductDownload.getEventObject(\n        'firefox_mobile',\n        '', // if you are not redirecting to a specific store, leave platform empty\n        'adjust'\n    );\nTrackProductDownload.sendEvent(customEventObject);\n</code></pre> <p>Note</p> <p>Calling TrackProductDownload will also fire an event named <code>product_download</code> so two events are being logged for each product download. This is because prior to Feb 2024 we only used one unified product download event and did not have the individual product download events yet. The split events are considered easier to deal with for reporting purposes inside GA4. Some data science dashboards use <code>product_download</code> because it has existed longer. Ideally, we will remove it some day.</p>"},{"location":"attribution/0001-analytics/#send-to-device","title":"Send to Device","text":""},{"location":"attribution/0001-analytics/#social-share","title":"Social Share","text":""},{"location":"attribution/0001-analytics/#stub-session-set","title":"Stub Session Set","text":""},{"location":"attribution/0001-analytics/#widget-action","title":"Widget Action","text":"<p>We are using the custom event <code>widget_action</code> to track the behaviour of javascript widgets.</p> <p>How do you chose between ``widget_action`` and ``cta_click``?</p> widget_action cta_click The action is specific or unique. The action is \\\"click\\\". (Only the language switcher changes the page language.) The user does not leave the page. It sends the user somewhere else. It requires Javascript to work. No JS required. It can perform several actions. It does one action. (A modal can be opened and closed.) There could be several on the page doing different things. There could be several on the page doing the same thing. (An accordion list of FAQs) (A download button in the header and footer.) <p>Properties for use with <code>widget_action</code> (not all widgets will use all options):</p> <ul> <li> <p>type</p> <ul> <li>Required.</li> <li>The type of widget.</li> <li>Examples: \\\"modal\\\", \\\"protection report\\\", \\\"affiliate notification\\\", \\\"help icon\\\".</li> <li>Avoid \"button\" or \"link\". If you want to track a link or button use `cta_click`.</li> </ul> </li> <li> <p>action</p> <ul> <li>Required.</li> <li>The thing that happened.</li> <li>Examples: \\\"open\\\", \\\"accept\\\", \\\"timeout\\\", \\\"vote up\\\".</li> <li>Avoid \"click\". If you want to track a click use `cta_click`.</li> </ul> </li> <li> <p>text</p> <ul> <li>How is this action labeled to the user?</li> <li>Examples: \\\"Okay\\\", \\\"Check your protection report\\\", \\\"Get the app\\\"</li> </ul> </li> <li> <p>name</p> <ul> <li>Give the widget a name.</li> <li>You probably only need this optional attribute if the <code>text</code> value is not enough to tell the widgets apart.</li> <li>This can help you group actions from the same widget, or make it easier to find the widget in the reports.</li> <li>The dashes are not required but they\\'re allowed if you want to match the element class or ID.</li> <li>Examples: \\\"dad-joke-banner\\\", \\\"focus-qr-code\\\", \\\"Join Firefox Modal\\\"</li> </ul> </li> <li> <p>non_interaction (boolean)</p> <ul> <li>True if the action was triggered by something other than a user gesture.</li> <li>If it\\'s not included we assume the value is false</li> </ul> </li> </ul> <p>To use <code>widget_action</code> push your event to the <code>dataLayer</code>:</p> <pre><code>window.dataLayer.push({\n    event: 'widget_action',\n    type: 'banner',\n    action: 'accept',\n    name: 'dad-jokes-banner'\n});\n\nwindow.dataLayer.push({\n    event: 'widget_action',\n    type: 'modal',\n    action: 'open',\n    name: 'help-icon'\n    text: 'Get Browser Help'\n});\n\nwindow.dataLayer.push({\n    event: 'widget_action',\n    type: 'vote',\n    action: 'helpful',\n    name: 'vpn-resource-center'\n    text: 'What is an IP address?'\n});\n\nwindow.dataLayer.push({\n    event: 'widget_action',\n    type: 'details',\n    action: 'open',\n    name: 'relay-faq'\n    text: 'Where is Relay available?'\n});\n</code></pre>"},{"location":"attribution/0001-analytics/#dimension-set","title":"Dimension Set","text":"<p>When using GA4 through GTM there isn't a way to set user scoped custom dimensions without an accompanying event. The custom event we use for this is <code>dimension_set</code>.</p> <pre><code>window.dataLayer.push({\n    event: 'dimension_set',\n    firefox_is_default: true\n});\n</code></pre> <p>User scoped custom dimensions must be configured in GA4. The list of supported custom dimensions is:</p> <ul> <li><code>firefox_is_default</code> (boolean)</li> <li><code>firefox_is_signed_in</code> (boolean)</li> </ul>"},{"location":"attribution/0001-analytics/#glean","title":"Glean","text":"<p>In addition to GA, Bedrock also runs a parallel web analytics implementation using Mozilla\\'s own Glean telemetry <code>SDK (Software Development Kit)</code>.</p> <p>One advantage to Glean is that it is a first-party solution, meaning that we have full control over the data we collect and how it is used. It is also less likely to be blocked by ad blockers or privacy tools.</p> <p>Using Glean\\'s standardized schema for data collection, we can also take advantage of automated dashboard creation in Looker (see below), which makes it easier to query data than some other tools such as GA4\\'s default dashboard.</p>"},{"location":"attribution/0001-analytics/#where-can-i-query-glean-data","title":"Where can I query Glean data?","text":"<p>The easiest place to view Glean data is in Looker:</p> <ul> <li>Website sessions dashboard</li> <li>Event monitoring dashboard</li> </ul> <p>If you need more detailed queries, you can click \\\"Explore from here\\\" from within each visualization to create your own queries.</p> <p>It is also possible to create more complex queries for raw Glean events using any of our standard Telemetry tools. The easiest way to do this is via the Glean Dictionary. For example, if you view the page load ping, you will see a table in the \\\"Access\\\" section (see screenshot below) that contains different links to query the event data.</p> <p></p>"},{"location":"attribution/0001-analytics/#filtering-out-non-production-pings","title":"Filtering out non-production pings","text":"<p>Bedrock automatically sets an <code>app_channel</code> tag with a value of either <code>prod</code> or <code>non-prod</code>, depending on the environment. This is present in all pings in the <code>client_info</code> section, and is useful for filtering out non-production data in telemetry dashboards.</p> <p>If you are viewing one of the dashboards linked above, make sure you set the <code>app_channel</code> filter to <code>prod</code> to only see production data.</p>"},{"location":"attribution/0001-analytics/#recording-page-load-events","title":"Recording page load events","text":"<p>Glean automatically records a page load event when the page is loaded. This event contains basic information about the page, such as the URL, the page title, and the referrer. The page load event is recorded in the <code>glean.page_load</code> event. Each page load event is associated with a unique <code>glean.page_id</code> metric, which is used to group all events related to a single page view / session.</p>"},{"location":"attribution/0001-analytics/#recording-click-events","title":"Recording click events","text":"<p>Glean will automatically record click events on any HTML element that has at least one of the following data attributes:</p> <ul> <li><code>data-glean-id</code>: A string indicating an identifier of the clicked element.</li> <li><code>data-glean-type</code>: A string indicating the type of the clicked element.</li> <li><code>data-glean-label</code>: A string indicating the label of the clicked element.</li> </ul> <p>Each click event will also record a <code>glean.page_id</code> metric, so that we can associate the click event with the page view that triggered it.</p> <p>Bedrock also has a custom <code>Mozilla.Glean.clickEvent()</code> helper that can be used to record click events directly via JavaScript:</p> <pre><code>if (typeof window.Mozilla.Glean !== 'undefined') {\n    window.Mozilla.Glean.clickEvent({\n        id: 'firefox_download',\n        type: 'macos',\n        label: 'release'\n    });\n}\n</code></pre> <p>Important</p> <p>When calling <code>Mozilla.Glean.clickEvent()</code> directly, make sure to always check if the <code>Mozilla.Glean</code> object is defined first.</p>"},{"location":"attribution/0001-analytics/#defining-additional-metrics-and-pings","title":"Defining additional metrics and pings","text":"<p>Outside of the standard page load and click event metrics recorded by Glean, any additional metrics we send to the Glean pipeline is defined in <code>YAML (Yet Another Markup Language)</code> schema files in the <code>./glean/</code> project root directory. The <code>metrics.yaml</code> file defines all the different metrics types and events we record.</p> <p>Note</p> <p>Before running any Glean commands locally, always make sure you have first activated your virtual environment by running <code>pyenv activate bedrock</code>.</p> <p>When Bedrock starts, we automatically run <code>npm run glean</code> which parses these schema files and then generates some JavaScript library code in <code>./media/js/libs/glean/</code>. This library code is not committed to the repository on purpose, in order to avoid people altering it and becoming out of sync with the schema. This library code is then imported into our Glean analytics code in <code>./media/js/glean/</code>, which is where we initiate page views and capture click events.</p> <p>Running <code>npm run glean</code> can also be performed independently of starting bedrock. It will also first lint the schema files.</p> <p>Important</p> <p>All metrics and events we add to the YAML file first undergo a data review before being recorded in production. Additionally changes or updates to existing metrics should also undergo a data review.</p>"},{"location":"attribution/0001-analytics/#debugging-pings","title":"Debugging pings","text":"<p>Glean supports debugging pings via a set of flags that can be enabled directly in the browser\\'s web console.</p> <ul> <li><code>window.Glean.setLogPings(true)</code> (enable verbose ping logging in the web console).</li> <li><code>window.Glean.setDebugViewTag('bedrock')</code> (send pings to the Glean debug dashboard with the tag name <code>bedrock</code>).</li> <li>You can also use <code>window.Glean.debugSession()</code> for automatically opening a link to the Debug Ping Viewer with your current session selected.</li> </ul> <p>Note</p> <p>After enabling Glean debugging in the web console, it will be remembered when navigating across pages using <code>sessionStorage</code>. To stop debugging, you need to either close the browser tab, or delete the items from <code>sessionStorage</code>. You can disable ping logging by calling <code>window.Glean.setLogPings(false)</code>.</p>"},{"location":"attribution/0001-analytics/#how-can-visitors-opt-out-of-glean","title":"How can visitors opt out of Glean?","text":"<p>Website visitors can opt out of Glean by visiting the cookie settings page, which is linked to in the main site footer on every page. Clicking opt-out will set a cookie which Glean checks for before initializing on page load.</p>"},{"location":"attribution/0002-firefox-desktop/","title":"Firefox Desktop attribution","text":""},{"location":"attribution/0002-firefox-desktop/#firefox_desktop_attribution","title":"Firefox desktop attribution","text":"<p>Firefox Desktop Attribution (often referred to as Stub Attribution) is a system that enables Mozilla to link website attributable referral data (including Google Analytics data) to a user's Firefox profile. When a website visitor lands on www.mozilla.org and clicks to download Firefox, we pass attribution data about their visit to the Firefox installer for inclusion in Telemetry. This is to enable Mozilla to better understand how changes to our website and different marketing campaigns can affect installation rates, as well as overall product retention. The data also gives us an insight into how many installations originate from www.mozilla.org, as opposed to elsewhere on the internet.</p>"},{"location":"attribution/0002-firefox-desktop/#scope-and-requirements","title":"Scope and requirements","text":"<ul> <li>Attribution was originally only possible via the Firefox stub installer on Windows (hence the name stub attribution), however it now also works on full installer links, and across all desktop release channels.</li> <li>Attribution now also works on macOS. The flow does not yet work for Linux, Android or iOS devices.</li> <li>Attribution will only be passed if a website visitor has their Do Not Track (DNT) and Global Privacy Control (GPC) preferences disabled in their browser. Visitors can opt-out by enabling DNT or GPC. This is covered in our privacy policy.</li> </ul>"},{"location":"attribution/0002-firefox-desktop/#how-does-attribution-work","title":"How does attribution work?","text":"<p>See the Application Logic Flow Chart for a more detailed visual representation of the steps below (Mozilla access only).</p> <ol> <li>A user visits a page on www.mozilla.org. On page load, a JavaScript function collects referral and analytics data about from where their visit originated (see the table below for a full list of attribution data we collect).</li> <li>Once the attribution data is validated, bedrock then generates an attribution session ID. This ID is included in the user's attribution data, and is also sent to Google Analytics as a non-interaction event.</li> <li>Next we send the attribution data to an authentication service that is part of bedrock's back-end server. The data is validated again, then base64 encoded and returned to the client together with an signed, encrypted signature to prove that the data came from www.mozilla.org.</li> <li>The encoded attribution data and signature are then stored as cookies in the user's web browser. The cookies have the IDs <code>moz-stub-attribution-code</code> (the attribution code) and <code>moz-stub-attribution-sig</code> (the encrypted signature). Both cookies have a 24 hour expiry.</li> <li>Once the user reaches a Firefox download page, bedrock then checks if both attribution cookies exist, and if so appends the authenticated data to the Firefox download link. The query parameters are labelled <code>attribution_code</code> and <code>attribution_sig</code>.</li> <li>When the user clicks the Firefox download link, another attribution service hosted at <code>download.mozilla.org</code> then decrypts and validates the attribution signature. If the secret matches, a unique download token is generated. The service then stores both the attribution data (including the Google Analytics client ID) and the download token in Mozilla's private server logs.</li> <li>The service then passes the download token and attribution data (excluding the GA client ID) into the installer being served to the user.</li> <li>Once the user installs Firefox, the data that was passed to the installer is then stored in the users' Telemetry profile.</li> <li>During analysis, the download token can be used to join Telemetry data with the corresponding GA data in the server logs.</li> </ol> <p>Note</p> <p>The stub attribution script uses the attribute <code>data-download-version</code> to identify what links are download links.</p>"},{"location":"attribution/0002-firefox-desktop/#attribution-data","title":"Attribution data","text":"Name Description Example <code>utm_source</code> Query param identifying the referring site which sent the visitor. <code>utm_source=google</code> <code>utm_medium</code> Query param identifying the type of link, such as referral, cost per click, or email. <code>utm_medium=cpc</code> <code>utm_campaign</code> Query param identifying the specific marketing campaign that was seen. <code>utm_campaign=fast</code> <code>utm_content</code> Query param identifying the specific element that was clicked. <code>utm_content=getfirefox</code> <code>referrer</code> The domain of the referring site when the link was clicked. <code>google.com</code> <code>ua</code> Simplified browser name parsed from the visitor's User Agent string. <code>chrome</code> <code>experiment</code> Query param identifying an experiment name that visitor was a cohort of. <code>taskbar</code> <code>variation</code> Query param identifying the experiment variation that was seen by the visitor. <code>client_id_ga4</code> Google Analytics 4 Client ID. <code>1715265578.1681917481</code> <code>session_id</code> A random 10 digit string identifier used to associate attribution data with GA session. <code>9770365798</code> <code>dlsource</code> A hard-coded string ID used to distinguish mozorg downloads from archive downloads <code>mozorg</code> <p>Note</p> <p>If any of the above values are not present then a default value of <code>(not set)</code> will be used.</p>"},{"location":"attribution/0002-firefox-desktop/#cookies","title":"Cookies","text":"<p>The cookies created during the attribution flow are as follows:</p> Name Value Domain Path Expiry <code>moz-stub-attribution-code</code> Base64 encoded attribution string <code>www.mozilla.org</code> <code>/</code> 24 hours <code>moz-stub-attribution-sig</code> Base64 encoded signature <code>www.mozilla.org</code> <code>/</code> 24 hours"},{"location":"attribution/0002-firefox-desktop/#measuring-campaigns-and-experiments","title":"Measuring campaigns and experiments","text":"<p>Firefox Desktop Attribution was originally designed for measuring the effectiveness of marketing campaigns where the top of the funnel was outside the remit of www.mozilla.org. For these types of campaigns, stub attribution requires zero configuration. It just works in the background and passes along any attribution data that exists.</p> <p>It is also possible to measure the effectiveness of experiments on installation rates and retention. This is achieved by adding optional <code>experiment</code> and <code>variation</code> parameters to a page URL. Additionally, these values can also be set via JavaScript using:</p> <pre><code>Mozilla.StubAttribution.experimentName = 'experiment-name';\nMozilla.StubAttribution.experimentVariation = 'v1';\n</code></pre> <p>Note</p> <p>When setting a experiment parameters using JavaScript like in the example above, it must be done prior to calling <code>Mozilla.StubAttribution.init()</code>.</p>"},{"location":"attribution/0002-firefox-desktop/#return-to-addonsmozillaorg-rtamo","title":"Return to addons.mozilla.org (RTAMO)","text":"<p>Return to AMO (RTAMO) is a Firefox feature whereby a first-time installation onboarding flow is initiated, that redirects a user to install the extension they have chosen whilst browsing AMO using a different browser. RTAMO works by leveraging the existing stub attribution flow, and checking for specific <code>utm_</code> parameters that were passed if the referrer is from AMO.</p> <p>Specifically, the RTAMO feature looks for a <code>utm_content</code> parameter that starts with <code>rta:</code>, followed by an ID specific to an extension. For example: <code>utm_content=rta:dUJsb2NrMEByYXltb25kaGlsbC5uZXQ</code>. The stub attribution code in bedrock also checks the referrer before passing this on, to make sure the links originate from AMO. If RTAMO data comes from a domain other than AMO, then the attribution data is dropped.</p> <p>RTAMO initially worked for only a limited subset of addons recommended by Mozilla. This functionality was recently expanded by the AMO team to cover all publically listed addons, under a project called <code>Extended RTAMO (ERTAMO)</code>.</p> <p>Important</p> <p>Because RTAMO is a user facing feature, expressly requested by the user from the AMO page, we deem the RTAMO flow as an essential/necessary use of attribution data. We do however limit the amount of data we collect to only what's essential for the RTAMO to function as a feature. Non-essential fields such as the Google Analytics client ID are omitted. We also continue to respect Do Not Track (DNT) as a valid opt-out signal.</p>"},{"location":"attribution/0002-firefox-desktop/#how-can-visitors-opt-out","title":"How can visitors opt out?","text":"<p>Visitors to the website can opt-out of desktop attribution on our website by enabling Do Not Track (DNT) in their web browser. We facilitate this by using a DNT helper that our team maintains.</p>"},{"location":"attribution/0002-firefox-desktop/#local-testing","title":"Local testing","text":"<p>For stub attribution to work locally or on a demo instance, a value for the HMAC key that is used to sign the attribution code must be set via an environment variable e.g.</p> <pre><code>STUB_ATTRIBUTION_HMAC_KEY=thedude\n</code></pre> <p>Note</p> <p>This value can be anything if all you need to do is test the bedrock functionality. It only needs to match the value used to verify data passed to the stub installer for full end-to-end testing via Telemetry.</p>"},{"location":"attribution/0002-firefox-desktop/#manual-testing-for-code-reviews","title":"Manual testing for code reviews","text":"<p>You might not need to test all these depending on what is changing this is an exhaustive testing guide. This guide assumes demo1, make sure you're testing on the right URL.</p> <ol> <li> <p>Use Chrome on Windows or MacOS with DNT and adblocking disabled.</p> </li> <li> <p>Open https://www-demo1.allizom.org/en-US/?utm_source=ham&amp;utm_campaign=pineapple</p> </li> <li> <p>Using Dev Tools, open the Application tab and inspect cookies.</p> </li> <li> <p>Look for a cookie called <code>moz-stub-attribution-code</code> and copy the value (it should be a base64 encoded string).</p> </li> </ol> <p>5.</p> <pre><code>Decode the base64 string (e.g. using &lt;https://base64decode.org&gt;) and check that:\n\n:   -   ``dlsource`` parameter value is mozorg\n    -   ``client_id_ga4`` and ``session_id`` parameters exist\n    -   ``client_id_ga4`` should look something like 0700077325.1656063224 (the numbers will differ but the format with the middle period should look the same).\n    -   ``source`` and ``campaign`` have the values ham and pineapple, respectively.\n    -   The ua value should be chrome (assuming you tested in Chrome).\n    -   Everything else should be (not set).\n</code></pre> <ol> <li> <p>Inspect the \"Download Firefox\" button in the top right and verify the download URL contains <code>attribution_code</code> and <code>attribution_sig</code> params.</p> </li> <li> <p>Click \"Download Firefox\".</p> </li> <li> <p>Inspect the \"Try downloading again\" link and check for the <code>attribution_code</code> and <code>attribution_sig</code> params.</p> <ul> <li>decode the value of <code>attribution_code</code> to check it has the expected values</li> </ul> </li> </ol> <p>Other places on the site you may want to check:</p> <ul> <li>firefox/all (inspect the network request to check that the attribution params were added on click)</li> <li>firefox/new</li> <li>firefox/enterprise</li> </ul>"},{"location":"attribution/0003-firefox-mobile/","title":"Firefox Mobile attribution","text":""},{"location":"attribution/0003-firefox-mobile/#firefox_mobile_attribution","title":"Firefox mobile attribution","text":"<p>For Firefox mobile referrals we use native app store web links with additional campaign parameters to help measure download to install rates.</p>"},{"location":"attribution/0003-firefox-mobile/#app-store-url-helpers","title":"App store url helpers","text":"<p>To help streamline creating app store referral links we have <code>app_store_url()</code> and <code>play_store_url()</code> helpers, which accept a <code>product```` name and an optional \\`campaign</code>` parameter.</p> <p>For example:</p> <pre><code>play_store_url('firefox', 'firefox-home')\napp_store_url('firefox', 'firefox-home')\n</code></pre> <p>Would render:</p> <pre><code>https://play.google.com/store/apps/details?id=org.mozilla.firefox&amp;referrer=utm_source%3Dwww.mozilla.org%26utm_medium%3Dreferral%26utm_campaign%3Dfirefox-home&amp;hl=en\nhttps://apps.apple.com/us/app/apple-store/id989804926?pt=373246&amp;ct=firefox-home&amp;mt=8\n</code></pre> <p>For Firefox Focus:</p> <pre><code>play_store_url('focus', 'firefox-browsers-mobile-focus')\napp_store_url('focus', 'firefox-browsers-mobile-focus')\n</code></pre> <p>Would render:</p> <pre><code>https://play.google.com/store/apps/details?id=org.mozilla.focus&amp;referrer=utm_source%3Dwww.mozilla.org%26utm_medium%3Dreferral%26utm_campaign%3Dfirefox-browsers-mobile-focus&amp;hl=en\nhttps://apps.apple.com/us/app/apple-store/id1055677337?pt=373246&amp;ct=firefox-browsers-mobile-focus&amp;mt=8\n</code></pre>"},{"location":"attribution/0003-firefox-mobile/#app-store-redirects","title":"App store redirects","text":"<p>Occasionally we need to create a link that can auto redirect to either the Apple App Store or the Google Play Store depending on user agent. A common use case is to embed inside a QR Code, which people can then scan on their phone to get a shortcut to the app. To make this easier bedrock has a special redirect URL to which you can add product and campaign query strings. When someone hits the redirect URL, bedrock will attempt to detect their mobile platform and then auto redirect to the appropriate app store.</p> <p>The base redirect URL is <code>https://www.mozilla.org/firefox/browsers/mobile/app/</code>, and to it you can add both a <code>product</code> and <code>campaign</code> query parameter. For example, the following URL would redirect to either Firefox on the Apple App Store or on the Google Play Store, with the specified campaign parameter.</p> <pre><code>https://www.mozilla.org/firefox/browsers/mobile/app/?product=firefox&amp;campaign=firefox-whatsnew\n</code></pre> <p>Note</p> <p>The <code>product</code> and <code>campaign</code> parameters are limited to a set of strictly trusted values. To add more product and campaign options, you can add those values to the <code>mobile_app</code> helper function in firefox/redirects.py.</p>"},{"location":"attribution/0003-firefox-mobile/#where-can-i-find-mobile-attribution-data","title":"Where can I find mobile attribution data?","text":"<p>You can find Firefox Android client attribution data in Looker. Firefox iOS data is currently only available in App Store Connect, however this will also be added to Looker in the near future.</p>"},{"location":"attribution/0004-mozilla-accounts/","title":"Mozilla accounts attribution","text":""},{"location":"attribution/0004-mozilla-accounts/#mozilla-accounts-attribution","title":"Mozilla accounts attribution","text":"<p>For products such as Mozilla VPN, Relay, and Monitor, we use Mozilla account as an authentication and subscription service. In addition to Google Analytics for basic conversion tracking, we attribute web page visits and clicks and through to actual subscriptions and installs by passing a specific allow-list of known query parameters through to the subscription platform. This is accomplished by adding referral data as parameters to sign up links on product landing pages.</p>"},{"location":"attribution/0004-mozilla-accounts/#how-does-attribution-work","title":"How does attribution work?","text":"<p>When using any of the Mozilla accounts helpers in bedrock, a default set of attribution parameters are added to each account sign-in / subscription link on a product landing page. Here's what we set for Mozilla VPN, as an example:</p> Name Description Example value <code>utm_source</code> Query param identifying the referring site which sent the visitor. <code>www.mozilla.org-vpn-product-page</code> <code>utm_medium</code> Query param identifying the type of link, such as referral, cost per click, or email. <code>referral</code> <code>utm_campaign</code> Query param identifying the specific marketing campaign that was seen. <code>vpn-product-page</code> <code>entrypoint</code> ID for which page of the website the request originates from (used for funnel analysis). <code>www.mozilla.org-vpn-product-page</code> <code>device_id</code> ID that correlates to the active device being used (used for funnel analysis). Alpha numeric string <code>flow_id</code> The flow identifier. A randomly-generated opaque ID (used for funnel analysis). Alpha numeric string <code>flow_begin_time</code> The time at which a flow event occurred (used for funnel analysis). Timestamp <code>service</code> Product ID used for data analysis in BigQuery (optional). Alpha numeric string <p>When performing data analysis, the default <code>UTM (Urchin Tracking Module)</code> values above are what we equate to \"direct\" traffic (i.e. someone came to the landing page directly then subscribed. They did not arrive from a specific marketing campaign or other channel).</p> <p>If we do detect that someone came from a marketing campaign or other form of referral, then we have logic in place that will replace the default UTM parameters on each link with more specific referral data, so that we can attribute subscriptions to individual campaigns.</p> <p>We also support passing several other optional referral parameters:</p> Name Description Example value <code>coupon</code> A coupon code that can be automatically applied at checkout (case sensitive). <code>VPN20</code> <code>entrypoint_experiment</code> Experiment name ID. Alpha numeric string <code>entrypoint_variation</code> Experiment variation ID Alpha numeric string"},{"location":"attribution/0004-mozilla-accounts/#attribution-logic","title":"Attribution logic","text":"<p>See the Application Logic Flow Chart for a visual representation of the steps below (Mozilla access only).</p> <ol> <li>A website visitor loads a product landing page in their web browser.</li> <li>A JavaScript function then checks for and validates attribution data via a list of known URL parameters (see tables above).</li> <li>If there are UTM parameters in the referral data, then those are used to replace the default values in each sign up link. Additionally if <code>coupon</code> or <code>entrypoint_experiment</code> params found, those are also appended.</li> <li>If no UTM params exist, but there is a referrer cookie set, then the cookie value is used for <code>utm_campaign</code> and <code>utm_source</code> is set to <code>www.mozilla.org</code>. This cookie is often set when we display a \"Get Mozilla VPN\" promo on another mozorg page, such as <code>/whatsnew</code>.</li> <li>If there's no referrer cookie, we next look at <code>document.referrer</code> to see if the visitor came from a search engine. If found, we set <code>utm_medium</code> as <code>organic</code> and <code>utm_source</code> as the search engine name.</li> <li>Next, an metrics function makes a flow API request to the Mozilla accounts authentication server. The request returns a series of metrics parameters that are used to track progress through the sign-up process. These \"flow\" parameters are also appended to each sign up link in addition to the existing attribution data.</li> <li>When someone clicks through and completes the sign up process, attribution data we passed through is emitted as event logs. This data is then joined to a person's Mozilla account data during the Data Science team's ETL process (Extract, Transform, Load), where data is then brought together in Big Query.</li> </ol> <p>Note</p> <p>UTM parameters on sign up links will only be replaced if the page URL contains both a valid <code>utm_source</code> and <code>utm_campaign</code> parameter. All other UTM parameters are considered optional, but will still be passed through, as long as the required parameters exist. This is to avoid mixing referral data from different campaigns.</p>"},{"location":"attribution/0004-mozilla-accounts/#attribution-referrer-cookie","title":"Attribution referrer cookie","text":"<p>In situations where we want to try and track a visitor's first entry point, say if someone lands on a <code>/whatsnew</code> page and then clicks on a \"Get Mozilla VPN\" promo link, then we can set a referral cookie in someone's browser when they click a same-site link (step 4 in the list above).</p> <p>The cookie can be set simply by adding the class name <code>js-fxa-product-referral-link</code> to a same-site link, along with a <code>data-referral-id</code> attribute. When clicked, our attribution logic will use the value of <code>data-referral-id</code> to augment <code>utm_campaign</code> when someone click through to the product page.</p> <p>For example, a referral with <code>data-referral-id=\"navigation\"</code> would result in the following utm parameters being set on sign up links in the product landing page:</p> <ul> <li><code>utm_source=www.mozilla.org</code>.</li> <li><code>utm_campaign=navigation</code>.</li> <li><code>utm_medium=referral</code>.</li> </ul>"},{"location":"attribution/0004-mozilla-accounts/#mozilla-vpn-referral-link-helper","title":"Mozilla VPN referral link helper","text":"<p>For Mozilla VPN, there's a <code>vpn_product_referral_link</code> helper built specifically to help implement account referral links to the VPN landing page:</p> <pre><code>{{ vpn_product_referral_link(\n    referral_id='navigation',\n    link_to_pricing_page=True,\n    link_text='Get Mozilla VPN',\n    class_name='mzp-t-secondary mzp-t-md',\n    page_anchor='#pricing',\n    optional_attributes= {\n        'data-cta-text' : 'Get Mozilla VPN',\n        'data-cta-type' : 'button',\n        'data-cta-position' : 'navigation',\n    }\n) }}\n</code></pre> <p>The helper supports the following parameters:</p> Parameter name Definition Format Example <code>referral_id</code> The ID for the referring page / component. This serves as a value for 'utm_campaign'. String 'navigation' <code>link_to_pricing_page</code> Link to the pricing page instead of the landing page (defaults to <code>False</code>). Boolean True <code>link_text</code> The link copy to be used in the call to action. Localized string 'Get Mozilla VPN' <code>class_name</code> A class name to be applied to the link (typically for styling with CSS). String of one or more class names 'mzp-t-secondary mzp-t-md' <code>page_anchor</code> An optional page anchor for the link destination. String '#pricing' <code>optional_attributes</code> An dictionary of key value pairs containing additional data attributes to include in the button. Dictionary {'data-cta-text': 'Get Mozilla VPN', 'data-cta-type': 'vpn', 'data-cta-position': 'navigation'} <p>The cookie has the following configuration:</p> Cookie name Value Domain Expiry <code>fxa-product-referral-id</code> Campaign identifier <code>www.mozilla.org</code> 1 hour"},{"location":"attribution/0004-mozilla-accounts/#flow-metrics","title":"Flow metrics","text":"<p>Whilst UTM parameters are passed through to sign up links automatically for any page of the website, in order for flow metrics to be added to links, a specific JavaScript bundle needs to be manually run in the page that requires it. The reason why it's separate is that depending on the situation, flow metrics need to get queried and added at specific times and conditions (more on that below).</p> <p>To add flow metrics to links, a page's respective JavaScript bundle should import and initialize the <code>FxaProductButton</code> script.</p> <pre><code>import FxaProductButton from './path/to/fxa-product-button.es6.js';\n\nFxaProductButton.init();\n</code></pre> <p>The above JS is also available as a pre-compiled bundle, which can be included directly in a template:</p> <pre><code>{{ js_bundle('fxa_product_button') }}\n</code></pre> <p>When <code>init()</code> is called, flow metrics will automatically be added to add account sign up links on a page.</p> <p>Important</p> <p>Requests to metrics API endpoints should only be made when an associated <code>CTA (Call To Action)</code> is visibly displayed on a page. For example, if a page contains both a Mozilla accounts sign-up form and a Mozilla Monitor button, but only one CTA is displayed at any one time, then only the metrics request associated with the visible CTA should occur.</p> <p>Note</p> <p>For links generated using the <code>fxa_link_fragment</code> helper, you will also need to manually add a CSS class of <code>js-fxa-product-button</code> to trigger the script.</p>"},{"location":"attribution/0004-mozilla-accounts/#google-analytics-guidelines","title":"Google Analytics guidelines","text":"<p>For <code>GTM (Google Tag Manager)</code> <code>datalayer</code> attribute values in Mozilla account links, please use the <code>analytics&lt;analytics&gt;</code> documentation.</p>"},{"location":"attribution/0005-affiliate-marketing/","title":"Mozilla CJMS Affiliate attribution","text":""},{"location":"attribution/0005-affiliate-marketing/#affiliate_attribution","title":"Mozilla CJMS affiliate attribution","text":"<p>The CJMS affiliate attribution flow comprises an integration between the Commission Junction (CJ) affiliate marketing event system, bedrock, and the Security and Privacy team's CJ micro service (CJMS).</p> <p>The system allows individuals who partner with Mozilla, via CJ, to share referral links for Mozilla with their audiences. When people subscribe using an affiliate link, the partner can be attributed appropriately in CJ's system.</p>"},{"location":"attribution/0005-affiliate-marketing/#how-does-attribution-work","title":"How does attribution work?","text":"<p>For a more detailed breakdown you can view the full flow diagram (Mozilla access only), but at a high level the logic that bedrock is responsible for is as follows:</p> <ol> <li>On pages which include the script, on page load, a JavaScript function looks for a <code>cjevent</code> query parameterin the page URL.</li> <li>If found, we validate the query param value and then <code>POST</code> it together with a Firefox Account <code>flow_id</code> to the CJMS.</li> <li>The CJMS responds with an affiliate marketing ID and expiry time, which we then set as a first-party cookie. This cookie is used to maintain a relationship between the <code>cjevent</code> value and an individual <code>flow_id</code>, so that successful subscriptions can be properly attributed to CJ.</li> <li>If a website visitor later returns to the page with an affiliate marketing cookie already set, then we update the <code>flow_id</code> and <code>cjevent</code> value (if a new one exists) via <code>PUT</code> on their repeat visit. This ensures that the most recent CJ referral is attributed if/when someone decides to purchase a subscription.</li> <li>The CJMS then responds with an updated ID / expiry time for the affiliate marketing cookie.</li> </ol>"},{"location":"attribution/0005-affiliate-marketing/#how-can-visitors-opt-out","title":"How can visitors opt out?","text":"<ol> <li>To facilitate an opt-out of attribution, we display a cookie notification with an opt-out button at the top of the page when the flow initiates.</li> <li>If someone clicks \"Reject\" to opt-out, we generate a new <code>flow_id</code> (invalidating the existing <code>flow_id</code> in the CJMS database) and then delete the affiliate marketing cookie, replacing it with a \"reject\" preference cookie that will prevent attribution from initiating on repeat visits. This preference cookie will expire after 1 month.</li> <li>If someone clicks \"OK\" or closes the opt-out notification by clicking the \"X\" icon, here we assume the website visitor is OK with attribution. We set an \"accept\" preference cookie that will prevent displaying the opt-out notification on future visits (again with a 1 month expiry) and allow attribution to flow.</li> </ol>"},{"location":"attribution/0005-affiliate-marketing/#cookies","title":"Cookies","text":"<p>The affiliate cookie has the following configuration:</p> Cookie name Value Domain Expiry <code>moz-cj-affiliate</code> Affiliate ID <code>www.mozilla.org</code> 30 days <p>Note</p> <p>To query what version of CJMS is currently deployed at the endpoint bedrock points to, you can add <code>__version__</code> at the end of the base URL to see the release number and commit hash. For example: https://stage.cjms.nonprod.cloudops.mozgcp.net/__version__</p>"},{"location":"attribution/0006-consent-management/","title":"Managing Data Privacy and Concent","text":""},{"location":"attribution/0006-consent-management/#consent_management","title":"Managing Data Privacy and Consent","text":"<p>Please see the internal Confluence page on Mozilla's overall approach to handling data privacy and cookie consent management on www.mozilla.org. This page will include detailed legal guidance and FAQs on the permitted use of tracking technologies.</p> <p>Here we will cover bedrock's technical approach to implementing data consent per that legal guidance, whilst also balancing UX considerations and input from other teams.</p> <p>In EU and EAA countries where explicit consent to cookies and analytics is required, there are certain web page URLs where bedrock will display a cookie consent banner. These URLs are stored in a strict allow-list. URLs that are not in this list will neither show a banner, nor load any non-necessary cookies / analytics in the EU/EAA. The intent here is to provide as little disruption for our website visitors as possible, whilst still allowing opt-in to analytics URLs such as campaign pages. It is also possible to force the banner to show on any EU page by adding a query parameter <code>?mozcb=y</code> (used for specific campaign traffic sources such as advertisements).</p> <p>Visitors in the EU/EAA countries can also send an opt-out signal by enabling either Global Privacy Control (GPC) and Do Not Track (DNT) in their browser. If either of these signals are enabled then we do not show a banner. Individual cookie preferences can also be updated via a dedicated cookie settings page linked in the main footer.</p> <p>In non-EU/EAA countries, non-necessary cookies and analytics are loaded by default. Visitors can still opt out via the cookie settings page. Enabling GPC / DNT will also act as an opt-out signal where needed.</p> <p>There is a Figma flowchart detailing the general flow of logic. The code that implements this logic can be found in the <code>media/js/base/consent</code> directory.</p>"},{"location":"attribution/0006-consent-management/#related-dependencies","title":"Related dependencies","text":"<p>For more detail documentation on dependencies used for consent management, see their respective GitHub repositories.</p> <ul> <li>Cookie consent banner repo</li> <li>Cookie helper repo</li> <li>DNT helper repo</li> </ul>"}]}