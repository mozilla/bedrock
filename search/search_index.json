{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Bedrock's documentation!","text":"<p>bedrock is the project behind www.mozilla.org. It is as shiny, awesome, and open-source as always. Perhaps even a little more.</p> <p>bedrock is a web application based on Django, a Python web application framework.</p> <p>Patches are welcome! Feel free to fork and contribute to this project on Github.</p>"},{"location":"#contents","title":"Contents","text":"<p>::: {.toctree maxdepth=\"2\"} install l10n coding contribute pipeline testing redirects newsletters contentful sitemap content-cards banners uitour send-to-device download-buttons mozilla-accounts funnelcake abtest vpn-subscriptions attribution architectural-decisions browser-support :::</p>"},{"location":"abtest/","title":"A/B Testing","text":""},{"location":"abtest/#convert-experiments","title":"Convert experiments","text":"<p>Conversion rate optimization (CRO) experiments on bedrock can be run using a third-party tool called Convert. Convert experiments are for relatively simple multivariate experiments, such as testing changes to headlines, images, or button copy.</p> <p>The Convert script is not included in part of bedrock's base bundle for performance reasons. To use Convert on a page, you can load the script behind a feature flag, which can be turned on / off for only the duration of an experiment. The script should be loaded inside the <code>experiments</code> block in your template:</p> <pre><code>{% block experiments %}\n{% if switch('experiment-convert-page-name', ['en-US']) %}\n{{ js_bundle('convert') }}\n{% endif %}\n{% endblock %}\n</code></pre> <p>Convert A/B tests can be implemented using the Convert dashboard and editor. Convert experiments should be coded and tested against staging, before being reviewed and scheduled to run in production.</p>"},{"location":"abtest/#qa-for-convert-experiments","title":"QA for Convert experiments","text":"<p>The process for QA'ing Convert experiments is as follows:</p> <ol> <li>Bedrock feature switch should be activated on staging.</li> <li>Experiment is built and configured to run on     <code>https://www.allizom.org/*</code></li> <li>In the Github issue for an experiment, someone will request review     by an engineer.</li> </ol> <p>An engineer reviewing the experiment will:</p> <ol> <li>Verify that the experiment is not configured to run on     https://www.mozilla.org/ (production) yet.</li> <li>Activate the experiment to run on stage.</li> </ol> <p>During review, the engineer will compare the following to the experiment plan:</p> <ol> <li>The experiment's logic.</li> <li>Any JS included (in Convert editor's JS field).</li> <li>Any CSS included (in Convert editor's CSS field).</li> <li>The target audience is configured.</li> <li>The goals are configured.</li> <li>The distribution percentages are configured.</li> <li>The target URLs are configured.</li> </ol> <p>Once the engineer is satisfied, the engineer (or someone else with write privileges) will:</p> <ol> <li>Add <code>https://www.mozilla.org/*</code> to the list of URLs the experiment     can run on.</li> <li>Reset the experiment (eliminating any data gathered during QA).</li> <li>Enable the bedrock feature switch in production.</li> <li>Activate (or schedule) the experiment.</li> </ol> <p>After an experiment is finished, the feature switch should be deactivated in production.</p> <p>Note</p> <p><code>*</code> should be replaced by the exact URL pathname for the experiment page.</p>"},{"location":"abtest/#traffic-cop-experiments","title":"Traffic Cop experiments","text":"<p>More complex experiments, such as those that feature full page redesigns, or multi-page user flows, should be implemented using Traffic Cop. Traffic Cop small javascript library which will direct site traffic to different variants in a/b experiments and make sure a visitor always sees the same variation.</p> <p>It's possible to test more than 2 variants.</p> <p>Traffic Cop sends users to experiments and then we use Google Analytics (GA) to analyze which variation is more successful. (If the user has DNT enabled they do not participate in experiments.)</p> <p>All a/b tests should have a mana page detailing the experiment and recording the results.</p>"},{"location":"abtest/#coding-the-variants","title":"Coding the variants","text":"<p>Traffic cop supports two methods of a/b testing. Executing different on page javascript or redirecting to the same URL with a query string appended. We mostly use the redirect method in bedrock. This makes testing easier.</p> <p>Create a variation view for the a/b test.</p> <p>The view can handle the URL redirect in one of two ways:</p> <ol> <li>the same page, with some different content based on the     [variation]{.title-ref} variable</li> <li>a totally different page</li> </ol>"},{"location":"abtest/#content-variation","title":"Content variation","text":"<p>Useful for small focused tests.</p> <p>This is explained on the variation view page.</p>"},{"location":"abtest/#new-page","title":"New page","text":"<p>Useful for large page changes where content and assets are dramatically different.</p> <p>Create the variant page like you would a new page. Make sure it is <code>noindex</code> and does not have a <code>canonical</code> URL.</p> <pre><code>{% block canonical_urls %}&lt;meta name=\"robots\" content=\"noindex,follow\"&gt;{% endblock %}\n</code></pre> <p>Configure as explained on the variation view page.</p>"},{"location":"abtest/#traffic-cop","title":"Traffic Cop","text":"<p>Create a .js file where you initialize Traffic Cop and include that in the experiments block in the template that will be doing the redirection. Wrap the extra js include in a switch.</p> <pre><code>{% block experiments %}\n{% if switch('experiment-berlin-video', ['de']) %}\n{{ js_bundle('firefox_new_berlin_experiment') }}\n{% endif %}\n{% endblock %}\n</code></pre>"},{"location":"abtest/#switches","title":"Switches","text":"<p>See the traffic cop section of the switch docs for instructions.</p>"},{"location":"abtest/#recording-the-data","title":"Recording the data","text":"<p>Note</p> <p>If you are measuring installs as part of your experiment be sure to configure custom stub attribution as well.</p> <p>Including the <code>data-ex-variant</code> and <code>data-ex-name</code> in the analytics reporting will add the test to an auto generated report in GA. The variable values may be provided by the analytics team.</p> <pre><code>if (href.indexOf('v=a') !== -1) {\nwindow.dataLayer.push({\n'data-ex-variant': 'de-page',\n'data-ex-name': 'Berlin-Campaign-Landing-Page'\n});\n} else if (href.indexOf('v=b') !== -1) {\nwindow.dataLayer.push({\n'data-ex-variant': 'campaign-page',\n'data-ex-name': 'Berlin-Campaign-Landing-Page'\n});\n}\n</code></pre> <p>Make sure any buttons and interaction which are being compared as part of the test and will report into GA.</p>"},{"location":"abtest/#viewing-the-data","title":"Viewing the data","text":"<p>The <code>data-ex-name</code> and <code>data-ex-variant</code> are encoded in Google Analytics as custom dimensions 69 and 70.</p> <p>Create a custom report.</p> <p>Set the \"Metrics Group\" to include Sessions. Configure additional metrics depending on what the experiment was measuring (downloads, events, etc.)</p> <p>Set the \"Dimension Drilldowns to have cd69 in the top position and cd70 in the drilldown position.</p> <p>View the custom report and drilldown into the experiment with the matching name.</p>"},{"location":"abtest/#tests","title":"Tests","text":"<p>Write some tests for your a/b test. This could be simple or complex depending on the experiment.</p> <p>Some things to consider checking:</p> <ul> <li>Requests for the default (non variant) page call the correct     template.</li> <li>Requests for a variant page call the correct template.</li> <li>Locales excluded from the test call the correct (default) template.</li> </ul>"},{"location":"abtest/#ab-test-prs-that-might-have-useful-code-to-reuse","title":"A/B Test PRs that might have useful code to reuse","text":"<ul> <li>https://github.com/mozilla/bedrock/pull/5736/files</li> <li>https://github.com/mozilla/bedrock/pull/4645/files</li> <li>https://github.com/mozilla/bedrock/pull/5925/files</li> <li>https://github.com/mozilla/bedrock/pull/5443/files</li> <li>https://github.com/mozilla/bedrock/pull/5492/files</li> <li>https://github.com/mozilla/bedrock/pull/5499/files</li> </ul>"},{"location":"abtest/#avoiding-experiment-collisions","title":"Avoiding experiment collisions","text":"<p>To ensure that Traffic Cop doesn't overwrite data from any other externally controlled experiments (for example Ad campaign tests, or in-product Firefox experiments), you can use the experiment-utils helper to decide whether or not Traffic Cop should initiate.</p> <pre><code>import TrafficCop = from '@mozmeao/trafficcop';\nimport { isApprovedToRun } from '../../base/experiment-utils.es6';\n\nif (isApprovedToRun()) {\nconst cop = new TrafficCop({\nid: 'experiment-name',\nvariations: {\n'entrypoint_experiment=experiment-name&amp;entrypoint_variation=a': 10,\n'entrypoint_experiment=experiment-name&amp;entrypoint_variation=b': 10\n}\n});\n\ncop.init();\n}\n</code></pre> <p>The <code>isApprovedToRun()</code> function will check the page URL's query parameters against a list of well-known experimental params, and return <code>false</code> if any of those params are found. It will also check for some other cases where we do not want to run experiments, such as if the page is being opened in an automated testing environment.</p>"},{"location":"architectural-decisions/","title":"Architectural Decision Records","text":"<p>We record major architectural decisions for bedrock in Architecture Decision Records (ADR), as described by Michael Nygard. Below is the list of our current ADRs.</p> <p>::: {.toctree maxdepth=\"1\" glob=\"\"} architecture/decisions/* :::</p>"},{"location":"attribution/","title":"Attribution","text":"<p>Attribution is the practice of recording the main touch points that a website visitor encounters on their path to downloading or signing up for one of our products. It often involves a multi-step user journey, sometimes across multiple properties, but the goal is to end up with informative data that tells us where the user of a product initially came from, and what their journey looked like along the way.</p> <p>These documents define how attribution works for the different products on our websites.</p>"},{"location":"banners/","title":"Banners","text":"<p>Any page on bedrock can incorporate a top of page banner as a temporary feature. An example of such a banner is the MOFO fundraising form that gets shown on the home page several times a year.</p> <p>Banners can be inserted into any page template by using the <code>page_banner</code> block. Banners can also be toggled on and off using a switch:</p> <pre><code>{% block page_banner %}\n{% if switch('fundraising-banner') %}\n{% include 'includes/banners/fundraiser.html' %}\n{% endif %}\n{% endblock %}\n</code></pre> <p>Banner templates should extend the base banner template, and content can then be inserted using <code>banner_title</code> and <code>banner_content</code> blocks:</p> <pre><code>{% extends 'includes/banners/base.html' %}\n\n{% block banner_title %}We all love the web. Join Mozilla in defending it.{% endblock %}\n\n{% block banner_content %}\n    &lt;!-- insert custom HTML here --&gt;\n{% endblock %}\n</code></pre> <p>CSS styles for banners should be located in <code>media/css/base/banners/</code>, and should extend common base banner styles:</p> <pre><code>@import 'includes/base';\n</code></pre> <p>To initiate a banner on a page, include <code>js/base/banners/mozilla-banner.js</code> in your page bundle and then initiate the banner using a unique ID. The ID will be used as a cookie identifier should someone dismiss a banner and not wish to see it again.</p> <pre><code>(function() {\n'use strict';\n\nfunction onLoad() {\nwindow.Mozilla.Banner.init('fundraising-banner');\n}\n\nwindow.Mozilla.run(onLoad);\n\n})();\n</code></pre> <p>By default, page banners will be rendered directly underneath the primary page navigation. If you want to render a banner flush at the top of the page, you can pass a secondary <code>renderAtTopOfPage</code> parameter to the <code>init()</code> function with a boolean value:</p> <pre><code>(function() {\n'use strict';\n\nfunction onLoad() {\nwindow.Mozilla.Banner.init('fundraising-banner', true);\n}\n\nwindow.Mozilla.run(onLoad);\n\n})();\n</code></pre>"},{"location":"banners/#l10n-for-page-banners","title":"L10n for page banners","text":"<p>Because banners can technically be shown on any page, they need to be broadly translated, or alternatively limited to the subset of locales that have translations. Each banner should have its own <code>.ftl</code> associated with it, and accessible to the template or view it gets used in.</p>"},{"location":"browser-support/","title":"Browser Support","text":"<p>We seek to provide usable experiences of our most important web content to all user agents. But newer browsers are far more capable than older browsers, and the capabilities they provide are valuable to developers and site visitors. We will take advantage of modern browser capabilities. Older browsers will have a different experience of the website than newer browsers. We will strike this balance by generally adhering to the core principles of Progressive Enhancement:</p> <ul> <li>Basic content should be accessible to all web browsers</li> <li>Basic functionality should be accessible to all web browsers</li> <li>Sparse, semantic markup contains all content</li> <li>Enhanced layout is provided by externally linked CSS</li> <li>Enhanced behavior is provided by unobtrusive, externally linked     JavaScript</li> <li>End-user web browser preferences are respected</li> </ul> <p>Some website experiences may require us to deviate from these principles -- imagine a marketing campaign page built under timeline pressure to deliver novel functionality to a particular locale for a short while -- but those will be exceptions and rare.</p>"},{"location":"browser-support/#browser-support-matrix","title":"Browser Support Matrix","text":"<p>Last updated: Updated July 19, 2023</p>"},{"location":"browser-support/#firefox","title":"Firefox","text":"<p>It is important for website visitors to be able to download Firefox on a very broad range of desktop operating systems. As such, we aim to deliver enhanced support to user agents in our browser support matrix below.</p> <p>Enhanced support:</p> Windows 11 and above <ul> <li>All evergreen browsers<ul> <li>Firefox</li> <li>Firefox ESR</li> <li>Chrome</li> <li>Edge</li> <li>Brave</li> <li>Opera</li> </ul> </li> </ul> Windows 10 <ul> <li>All evergreen browsers</li> </ul> macOS 10.15 and above <ul> <li>All evergreen browsers</li> <li>Safari</li> </ul> Linux <ul> <li>All evergreen browsers</li> </ul> <p>Degraded support:</p> <p>Website visitors on slightly older browsers fall under degraded support, which means that the website should be fully readable and accessible, but they may not get enhanced CSS layout or JS features.</p> Windows 10 <ul> <li>Internet Explorer 11</li> </ul> Windows 8.1 and below <ul> <li>Firefox 115</li> <li>Chrome 109</li> <li>Internet Explorer 10</li> </ul> macOS 10.14 and below <ul> <li>Firefox 115</li> <li>Chrome 114</li> <li>Safari 12.1</li> </ul> <p>Note</p> <p>As of Firefox 116 (released August 1st 2023), support for Firefox has been ended on Windows 8.1 and below, as well as on macOS 10.14 and below. Website visitors on these outdated operating systems now fall under degraded support, and we offer them to download Firefox ESR instead.</p> <p>Basic support:</p> <p>Website visitors on very old versions of Internet Explorer will get only a very basic universal CSS style sheet, and a basic no-JS experience.</p> Windows 7 <ul> <li>Internet Explorer 9</li> <li>Internet Explorer 8</li> </ul> <p>Unsupported:</p> <p>Even older versions of Internet Explorer are now unsupported.</p> Windows XP / Vista <ul> <li>Internet Explorer 7</li> <li>Internet Explorer 6</li> </ul> <p>Note</p> <p>Firefox ended support for Windows XP and Vista in 2017 with Firefox 53. Since then, we have continued to serve those users Firefox ESR 52 instead. However, since then support for downloading has been discontinued. The SSL certificates on download.mozilla.org no longer support TLS 1.0.</p>"},{"location":"browser-support/#privacy-security-products","title":"Privacy &amp; security products","text":"<p>Browser support for our privacy and security products (such as VPN, Relay, Monitor etc) is thankfully a simpler story. Since all these product use a Firefox account for authentication, we can simply follow the Firefox Ecosystem Platform browser support documentation.</p> <p>The most notable thing here for bedrock is that Internet Explorer 11 does not need to be supported.</p>"},{"location":"browser-support/#delivering-basic-support","title":"Delivering basic support","text":"<p>On IE browsers that support conditional comments (IE9 and below), basic support consists of no page-specific CSS or JS. Instead, we deliver well formed semantic HTML, and a universal CSS stylesheet that gets applied to all pages. We do not serve these older browsers any JS, with the exception of the following scripts:</p> <ul> <li>Google Analytics / GTM snippet.</li> <li>HTML5shiv for parsing modern HTML semantic elements.</li> <li>Stub Attribution script (IE8 / IE9).</li> </ul> <p>Conditional comments should instead be used to handle content specific to IE. To hide non-relevant content from IE users who see the universal stylesheet, a <code>hide-from-legacy-ie</code> class name can also be applied directly to HTML:</p> <pre><code>&lt;p class=\"hide-from-legacy-ie\"&gt;See what Firefox has blocked for you&lt;/p&gt;\n</code></pre>"},{"location":"browser-support/#delivering-degraded-support","title":"Delivering degraded support","text":"<p>On other legacy browsers where conditional comments are not supported, developers should instead rely on feature detection to deliver a degraded experience where appropriate.</p> <p>Note</p> <p>The following feature detection helpers will return true for all browsers that get enhanced support, but will also return true for IE11 currently, even though that has now moved to degraded support. The reason for this is that whilst many of our newer products don't support IE at all (e.g. Mozilla VPN, Mozilla Monitor, Firefox Relay), we do still need to provide support so that IE users can easily download Firefox. We can decide to update the feature detect in the future, at a time when we think makes sense.</p>"},{"location":"browser-support/#feature-detection-using-css","title":"Feature detection using CSS","text":"<p>For CSS, enhanced experiences can be delivered using feature queries, whilst allowing older browsers to degrade gracefully using simpler layouts when needed.</p> <p>Additionally, there is also a universal CSS class hook available that gets delivered via a site-wide JS feature detection snippet:</p> <pre><code>.is-modern-browser {\n/* Styles will only be applied to browsers that get enhanced support. */\n}\n</code></pre>"},{"location":"browser-support/#feature-detection-using-javascript","title":"Feature detection using JavaScript","text":"<p>For JS, enhanced support can be delivered using a helper that leverages the same feature detection snippet:</p> <pre><code>(function() {\n'use strict';\n\nfunction onLoad() {\n// Code that will only be run on browsers that get enhanced support.\n}\n\nwindow.Mozilla.run(onLoad);\n})();\n</code></pre> <p>The <code>site.isModernBrowser</code> global property can also be used within conditionals like so:</p> <pre><code>if (window.site.isModernBrowser) {\n// Code that will only be run on browsers that get enhanced support.\n}\n</code></pre>"},{"location":"browser-support/#exceptions-updated-2019-06-11","title":"Exceptions (Updated 2019-06-11)","text":"<p>Some pages of the website provide critical functionality to older browsers. In particular, the Firefox desktop download funnel enables users on older browsers to get a modern browser. To the extent possible, we try to deliver enhanced experiences to all user agents on these pages.</p> <p>The following pages get enhanced experiences for a longer list of user agents:</p> <ul> <li><code>/firefox/</code></li> <li><code>/firefox/new/</code></li> <li><code>/firefox/download/thanks/</code></li> </ul> <p>Note</p> <p>An enhanced experience can be defined as a step above basic support. This can be achieved by delivering extra page-specific CSS to legacy browsers, or allowing them to degrade gracefully. It does not mean everything needs to look the same in every browser.</p>"},{"location":"coding/","title":"Developing on Bedrock","text":""},{"location":"coding/#managing-dependencies","title":"Managing Dependencies","text":"<p>For Python we use <code>pip-compile</code> from pip-tools to manage dependencies expressed in our requirements files. <code>pip-compile</code> is wrapped up in Makefile commands, to ensure we use it consistently.</p> <p>If you add a new Python dependency (eg to <code>requirements/prod.in</code> or <code>requirements/dev.in</code>) you can generate a pinned and hash-marked addition to our requirements files just by running:</p> <pre><code>make compile-requirements\n</code></pre> <p>and committing any changes that are made. Please re-build your docker image and test it with <code>make build test</code> to be sure the dependency does not cause a regression.</p> <p>Similarly, if you upgrade a pinned dependency in an <code>*.in</code> file, run <code>make compile-requirements</code> then rebuild, test and commit the results</p> <p>To check for stale Python dependencies (basically <code>pip list -o</code> but in the Docker container):</p> <pre><code>make check-requirements\n</code></pre> <p>For Node packages we use NPM, which should already be installed alongside Node.js.</p>"},{"location":"coding/#front-end-dependencies","title":"Front-end Dependencies","text":"<p>Our team maintains a few dependencies that we serve on Bedrock's front-end.</p> <ul> <li>\\@mozilla-protocol/core:     Bedrock's primary design system</li> <li>\\@mozmeao/cookie-helper:     A complete cookies reader/writer framework</li> <li>\\@mozmeao/dnt-helper: Do     Not Track (DNT) helper</li> <li>\\@mozmeao/trafficcop:     Used for A/B testing page variants</li> </ul> <p>Because they are all published on NPM, install the packages and keep up-to-date with the latest version of each dependency by running an <code>npm install</code>. For further documentation on installing NPM packages, check out the official documentation.</p>"},{"location":"coding/#asset-management-and-bundling","title":"Asset Management and Bundling","text":"<p>Bedrock uses Webpack to manage front-end asset processing and bundling. This includes processing and minifying JavaScript and SCSS/CSS bundles, as well as managing static assets such as images, fonts, and other common file types.</p> <p>When developing on bedrock you can start Webpack by running <code>make run</code> when using Docker, or <code>npm start</code> when running bedrock locally.</p> <p>Once Webpack has finished compiling, a local development server will be available at localhost:8000. When Webpack detects changes to a JS/SCSS file, it will automatically recompile the bundle and then refresh any page running locally in the browser.</p>"},{"location":"coding/#webpack-configuration","title":"Webpack Configuration","text":"<p>We have two main Webpack config files in the root directory:</p> <p>The <code>webpack.static.config.js</code> file is responsible for copying static assets, such as images and fonts, from the <code>/media/</code> directory over to the <code>/assets/</code> directory. This is required so Django can serve them correctly.</p> <p>The <code>webpack.config.js</code> file is responsible for processing JS and SCSS files in the <code>/media/</code> directory and compiling them into the <code>/assets/</code> directory. This config file also starts a local development server and watches for file changes.</p> <p>We use two separate config files to keep responsibilities clearly defined, and to make the configs both shorter and easier to follow.</p> <p>Note</p> <p>Because of the large number of files used in bedrock, only JS and SCSS files managed by <code>webpack.config.js</code> are watched for changes when in development mode. This helps save on memory consumption. The implication of this is that files handled by <code>webpack.static.config.js</code> are only copied over when Webpack first runs. If you update an image for example, then you will need to stop and restart Webpack to pick up the change. This is not true for JS and SCSS files, which will be watched for change automatically.</p>"},{"location":"coding/#asset-bundling","title":"Asset Bundling","text":"<p>Asset bundles for both JS and SCSS are defined in <code>./media/static-bundles.json</code>. This is the file where you can define the bundle names that will get used in page templates. For example, a CSS bundle can be defined as:</p> <pre><code>\"css\": [\n{\n\"files\": [\n\"css/firefox/new/basic/download.scss\"\n],\n\"name\": \"firefox_new_download\"\n}\n]\n</code></pre> <p>Which can then be referenced in a page template using:</p> <pre><code>{{ css_bundle('firefox_new_download') }}\n</code></pre> <p>A JS bundle can be defied as:</p> <pre><code>\"js\": [\n{\n\"files\": [\n\"protocol/js/protocol-modal.js\",\n\"js/firefox/new/basic/download.js\"\n],\n\"name\": \"firefox_new_download\"\n}\n]\n</code></pre> <p>Which can then be referenced in a page template using:</p> <pre><code>{{ js_bundle('firefox_new_download') }}\n</code></pre> <p>Once you define a bundle in <code>static-bundles.json</code>, the <code>webpack.config.js</code> file will use these as entrypoints for compiling JS and CSS and watching for changes.</p>"},{"location":"coding/#writing-javascript","title":"Writing JavaScript","text":"<p>Bedrock's Webpack configuration supports some different options for writing JavaScript:</p>"},{"location":"coding/#default-configuration","title":"Default Configuration","text":"<p>Write <code>example-script.js</code> using ES5 syntax and features. Webpack will bundle the JS as-is, without any additional pre-processing.</p>"},{"location":"coding/#babel-configuration","title":"Babel Configuration","text":"<p>Write <code>example-script.es6.js</code> using ES2015+ syntax. Webpack will transpile the code to ES5 using Babel. This is useful when you want to write modern syntax but still support older browsers.</p> <p>Important</p> <p>Whilst Babel will transpile most modern JS syntax to ES5 when suitable fallbacks exist, it won't automatically include custom polyfills for everything since these can start to greatly increase bundle size. If you want to use <code>Promise</code> or <code>async/await</code> functions for example, then you will need to load polyfills for those. This can be done either at the page level, or globally in <code>lib.js</code> if it's something that multiple pages would benefit from. But please pick and choose wisely, and be concious of performance.</p> <p>For pages that are served to Firefox browsers only, such as <code>/whatsnew</code>, it is also possible to write native ES2015+ syntax and serve that directly in production. Here there is no need to include the <code>.es6.js</code> file extension. Instead, you can simply use <code>.js</code> instead. The rules that which files you can do this in are defined in our ESLint config.</p>"},{"location":"coding/#writing-url-patterns","title":"Writing URL Patterns","text":"<p>URL patterns should be the entire URL you desire, minus any prefixes from URLs files importing this one, and including a trailing slash. You should also give the URL a name so that other pages can reference it instead of hardcoding the URL. Example:</p> <pre><code>path(\"channel/\", channel, name=\"mozorg.channel\")\n</code></pre> <p>If you only want to render a template and don't need to do anything else in a custom view, Bedrock comes with a handy shortcut to automate all of this:</p> <pre><code>from bedrock.mozorg.util import page\npage(\"channel/\", \"mozorg/channel.html\")\n</code></pre> <p>You don't need to create a view. It will serve up the specified template at the given URL (the first parameter. see the Django docs for details). You can also pass template data as keyword arguments:</p> <pre><code>page(\"channel/\", \"mozorg/channel.html\",\n     latest_version=product_details.firefox_versions[\"LATEST_FIREFOX_VERSION\"])\n</code></pre> <p>The variable <code>latest_version</code> will be available in the template.</p>"},{"location":"coding/#finding-templates-by-url","title":"Finding Templates by URL","text":""},{"location":"coding/#general-structure","title":"General Structure","text":"<p>Bedrock follows the Django app structure and most templates are easy to find by matching URL path segments to folders and files within the correct app.</p> <p>| URL:   <code>https://www.mozilla.org/en-US/firefox/features/private-browsing/</code> | Template path:   <code>bedrock/bedrock/firefox/templates/firefox/features/private-browsing.html</code></p> <p>To get from URL to template path:</p> <ul> <li>Ignore <code>https://www.mozilla.org</code> and the locale path segment     <code>/en-US</code>. The next path segment is the app name <code>/firefox</code>.</li> <li>From the root folder of bedrock, find the app's template folder at     <code>bedrock/{app}/templates/{app}</code></li> <li>Match remaining URL path segments (<code>/features/private-browsing</code>) to     the template folder's structure (<code>/features/private-browsing.html</code>)</li> </ul> <p>Note</p> <p><code>mozorg</code> is the app name for the home page and child pages related to Mozilla Corporation (i.e. About, Contact, Diversity).</p>"},{"location":"coding/#whatsnew-and-firstrun","title":"Whatsnew and Firstrun","text":"<p>These pages are specific to Firefox browsers, and only appear when a user updates or installs and runs a Firefox browser for the first time. The URL and template depend on what Firefox browser and version are in use.</p> <p>Note</p> <p>There may be extra logic in the app's <code>views.py</code> file to change the template based on locale or geographic location as well.</p>"},{"location":"coding/#firefox-release","title":"Firefox release","text":"<p>Version number is digits only.</p> <p>| Whatsnew URL: https://www.mozilla.org/en-US/firefox/99.0/whatsnew/ | Template path:   https://github.com/mozilla/bedrock/tree/main/bedrock/firefox/templates/firefox/whatsnew</p> <p>| Firstrun URL: https://www.mozilla.org/en-US/firefox/99.0/firstrun/ | Template path:   https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/firstrun/firstrun.html</p>"},{"location":"coding/#firefox-nightly","title":"Firefox Nightly","text":"<p>Version number is digits and a1.</p> <p>| Whatsnew URL: https://www.mozilla.org/en-US/firefox/99.0a1/whatsnew/ | Template path:   https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/nightly/whatsnew.html</p> <p>| Firstrun URL:   https://www.mozilla.org/en-US/firefox/nightly/firstrun/ | Template path:   https://github.com/mozilla/bedrock/tree/main/bedrock/firefox/templates/firefox/nightly</p>"},{"location":"coding/#firefox-developer","title":"Firefox Developer","text":"<p>Version number is digits and a2.</p> <p>| Whatsnew URL: https://www.mozilla.org/en-US/firefox/99.0a2/whatsnew/ | Template path:   https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/developer/whatsnew.html</p> <p>| Firstrun URL: https://www.mozilla.org/en-US/firefox/99.0a2/firstrun/ | Template path:   https://github.com/mozilla/bedrock/blob/main/bedrock/firefox/templates/firefox/developer/firstrun.html</p>"},{"location":"coding/#release-notes","title":"Release Notes","text":"<p>Release note templates live here: https://github.com/mozilla/bedrock/tree/main/bedrock/firefox/templates/firefox/releases</p> <p>Note</p> <p>Release note content is pulled in from an external data source.</p> <ul> <li>Firefox release:     https://www.mozilla.org/en-US/firefox/99.0.1/releasenotes/</li> <li>Firefox Developer and Beta:     https://www.mozilla.org/en-US/firefox/100.0beta/releasenotes/</li> <li>Firefox Nightly:     https://www.mozilla.org/en-US/firefox/101.0a1/releasenotes/</li> <li>Firefox Android:     https://www.mozilla.org/en-US/firefox/android/99.0/releasenotes/</li> <li>Firefox iOS:     https://www.mozilla.org/en-US/firefox/ios/99.0/releasenotes/</li> </ul>"},{"location":"coding/#optimizing-images","title":"Optimizing Images","text":"<p>Images can take a long time to load and eat up a lot of bandwidth. Always take care to optimize images before uploading them to the site.</p> <p>The script <code>img.sh</code> can be used to optimize images locally on the command line:</p> <ol> <li>Before you run it for the first time you will need to run     <code>npm install</code> to install dependencies</li> <li>Add the image files to git's staging area <code>git add *</code></li> <li>Run the script <code>./bin/img.sh</code></li> <li>The optimized files will not automatically be staged, so be sure to     add them before commiting</li> </ol> <p>The script will:</p> <p>-</p> <pre><code>optimize JPG and PNG files using [tinypng](https://tinypng.com/) (\n\n:   -   this step is optional since running compression on the same\n        images over and over degrades them)\n    -   you will be prompted to add a [TinyPNG API\n        key](https://tinypng.com/developers)\n</code></pre> <ul> <li> <p>optimize SVG images locally with svgo</p> </li> <li> <p>check that SVGs have a viewbox (needed for IE support)</p> </li> <li> <p>check that images that end in <code>-high-res</code> have low res versions as     well</p> </li> </ul>"},{"location":"coding/#embedding-images","title":"Embedding Images","text":"<p>Images should be included on pages using one of the following helper functions.</p>"},{"location":"coding/#primary-image-helpers","title":"Primary image helpers","text":"<p>The following image helpers support the most common features and use cases you may encounter when coding pages:</p>"},{"location":"coding/#static","title":"static()","text":"<p>For a simple image, the <code>static()</code> function is used to generate the image URL. For example:</p> <pre><code>&lt;img src=\"{{ static('img/firefox/new/firefox-wordmark-logo.svg') }}\" alt=\"Firefox\"&gt;\n</code></pre> <p>will output an image:</p> <pre><code>&lt;img src=\"/media/img/firefox/new/firefox-wordmark-logo.svg\" alt=\"Firefox\"&gt;\n</code></pre>"},{"location":"coding/#resp_img","title":"resp_img()","text":"<p>For responsive images, where we want to specify multiple different image sizes and let the browser select which is best to use.</p> <p>The example below shows how to serve an appropriately sized, responsive red panda image:</p> <pre><code>resp_img(\n    url=\"img/panda-500.png\",\n    srcset={\n        \"img/panda-500.png\": \"500w\",\n        \"img/panda-750.png\": \"750w\",\n        \"img/panda-1000.png\": \"1000w\"\n    },\n    sizes={\n        \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n        \"default\": \"calc(100vw - 50px)\"\n    }\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;img src=\"/media/img/panda-500.png\"\n     srcset=\"/media/img/panda-500.png 500w,/media/img/panda-750.png 750w,/media/img/panda-1000.png 1000w\"\n     sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\" alt=\"\"&gt;'\n</code></pre> <p>In the above example we specified the available image sources using the <code>srcset</code> parameter. We then used <code>sizes</code> to say:</p> <ul> <li>When the viewport is greater than <code>1000px</code> wide, the panda image     will take up roughly half of the page width.</li> <li>When the viewport is less than <code>1000px</code> wide, the panda image will     take up roughly full page width.</li> </ul> <p>The default image <code>src</code> is what we specified using the <code>url</code> param. This is also what older browsers will fall back to using. Modern browsers will instead pick the best source option from <code>srcset</code> (based on both the estimated image size and screen resolution) to satisfy the condition met in <code>sizes</code>.</p> <p>Note</p> <p>The value <code>default</code> in the second <code>sizes</code> entry above should be used when you want to omit a media query. This makes it possible to provide a fallback size when no other media queries match.</p> <p>Another example might be to serve a high resolution alternative for a fixed size image:</p> <pre><code>resp_img(\n    url=\"img/panda.png\",\n    srcset={\n        \"img/panda-high-res.png\": \"2x\"\n    }\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;img src=\"/media/img/panda.png\" srcset=\"/media/img/panda-high-res.png 2x\" alt=\"\"&gt;\n</code></pre> <p>Here we don't need a <code>sizes</code> attribute, since the panda image is fixed in size and small enough that it won't need to resize along with the browser window. Instead the <code>srcset</code> image includes an alternate high resolution source URL, along with a pixel density descriptor. This can then be used to say:</p> <ul> <li>When a browser specifies a device pixel ratio of <code>2x</code> or greater,     use <code>panda-high-res.png</code>.</li> <li>When a browser specifies a device pixel ration of less than <code>2x</code>,     use <code>panda.png</code>.</li> </ul> <p>The <code>resp_img()</code> helper also supports localized images by setting the <code>'l10n'</code> parameter to <code>True</code>`:</p> <pre><code>resp_img(\n    url=\"img/panda-500.png\",\n    srcset={\n        \"img/panda-500.png\": \"500w\",\n        \"img/panda-750.png\": \"750w\",\n        \"img/panda-1000.png\": \"1000w\"\n    },\n    sizes={\n        \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n        \"default\": \"calc(100vw - 50px)\"\n    },\n    optional_attributes={\n        \"l10n\": True\n    }\n)\n</code></pre> <p>This would output (assuming <code>de</code> was your locale):</p> <pre><code>&lt;img src=\"/media/img/l10n/de/panda-500.png\"\n     srcset=\"/media/img/l10n/de/panda-500.png 500w,/media/img/l10n/de/panda-750.png 750w,/media/img/l10n/de/panda-1000.png 1000w\"\n     sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\" alt=\"\"&gt;'\n</code></pre> <p>Finally, you can also specify any other additional attributes you might need using <code>optional_attributes</code>:</p> <pre><code>resp_img(\n    url=\"img/panda-500.png\",\n    srcset={\n        \"img/panda-500.png\": \"500w\",\n        \"img/panda-750.png\": \"750w\",\n        \"img/panda-1000.png\": \"1000w\"\n    },\n    sizes={\n        \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n        \"default\": \"calc(100vw - 50px)\"\n    },\n    optional_attributes={\n        \"alt\": \"Red Panda\",\n        \"class\": \"panda-hero\",\n        \"height\": \"500\",\n        \"l10n\": True,\n        \"loading\": \"lazy\",\n        \"width\": \"500\"\n    }\n)\n</code></pre>"},{"location":"coding/#picture","title":"picture()","text":"<p>For responsive images, where we want to serve different images, or image types, to suit different display sizes.</p> <p>The example below shows how to serve a different image for desktop and mobile sizes screens:</p> <pre><code>picture(\n    url=\"img/panda-mobile.png\",\n    sources=[\n        {\n            \"media\": \"(max-width: 799px)\",\n            \"srcset\": {\n                \"img/panda-mobile.png\": \"default\"\n            }\n        },\n        {\n            \"media\": \"(min-width: 800px)\",\n            \"srcset\": {\n                \"img/panda-desktop.png\": \"default\"\n            }\n        }\n    ]\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;picture&gt;\n    &lt;source media=\"(max-width: 799px)\" srcset=\"/media/img/panda-mobile.png\"&gt;\n    &lt;source media=\"(min-width: 800px)\" srcset=\"/media/img/panda-desktop.png\"&gt;\n    &lt;img src=\"/media/img/panda-mobile.png\" alt=\"\"&gt;\n&lt;/picture&gt;\n</code></pre> <p>In the above example, the default image <code>src</code> is what we specifed using the <code>url</code> param. This is also what older browsers will fall back to using. We then used the <code>sources</code> parameter to specify one or more alternate image <code>&lt;source&gt;</code> elements, which modern browsers can take advantage of. For each <code>&lt;source&gt;</code>, <code>media</code> lets us specify a media query as a condition for when to load an image, and <code>srcset</code> lets us specify one or more sizes for each image.</p> <p>Note</p> <p>The value <code>default</code> in the <code>srcset</code> entry above should be used when you want to omit a descriptor. In this example we only have one entry in <code>srcset</code> (meaning it will be chosen immediately should the media query be satisfied), hence we omit a descriptor value.</p> <p>A more complex example might be when we want to load responsively sized, animated gifs, but also offer still images for users who set <code>(prefers-reduced-motion: reduce)</code>:</p> <pre><code>picture(\n    url=\"img/dancing-panda-500.gif\",\n    sources=[\n        {\n            \"media\": \"(prefers-reduced-motion: reduce)\",\n            \"srcset\": {\n                \"img/sleeping-panda-500.png\": \"500w\",\n                \"img/sleepinng-panda-750.png\": \"750w\",\n                \"img/sleeping-panda-1000.png\": \"1000w\"\n            },\n            \"sizes\": {\n                \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n                \"default\": \"calc(100vw - 50px)\"\n            }\n        },\n        {\n            \"media\": \"(prefers-reduced-motion: no-preference)\",\n            \"srcset\": {\n                \"img/dancing-panda-500.gif\": \"500w\",\n                \"img/dancing-panda-750.gif\": \"750w\",\n                \"img/dancing-panda-1000.gif\": \"1000w\"\n            },\n            \"sizes\": {\n                \"(min-width: 1000px)\": \"calc(50vw - 200px)\",\n                \"default\": \"calc(100vw - 50px)\"\n            }\n        }\n    ]\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;picture&gt;\n    &lt;source media=\"(prefers-reduced-motion: reduce)\"\n            srcset=\"/media/img/sleeping-panda-500.png 500w,/media/img/sleeping-panda-750.png 750w,/media/img/sleeping-panda-1000.png 1000w\"\n            sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\"&gt;\n    &lt;source media=\"(prefers-reduced-motion: no-preference)\"\n            srcset=\"/media/img/dancing-panda-500.gif 500w,/media/img/dancing-panda-750.gif 750w,/media/img/dancing-panda-1000.gif 1000w\"\n            sizes=\"(min-width: 1000px) calc(50vw - 200px),calc(100vw - 50px)\"&gt;\n    &lt;img src=\"/media/img/dancing-panda-500.gif\" alt=\"\"&gt;\n&lt;/picture&gt;\n</code></pre> <p>In the above example we would default to loading animated gifs, but if a user agent specified <code>(prefers-reduced-motion: reduce)</code> then the browser would load static png files instead. Multiple image sizes are also supported for each <code>&lt;source&gt;</code> using <code>srcset</code> and <code>sizes</code>.</p> <p>Another type of use case might be to serve different image formats, so capable browsers can take advantage of more efficient encoding:</p> <pre><code>picture(\n    url=\"img/red-panda.png\",\n    sources=[\n        {\n            \"type\": \"image/webp\",\n            \"srcset\": {\n                \"img/red-panda.webp\": \"default\"\n            }\n        }\n    ]\n)\n</code></pre> <p>This would output:</p> <pre><code>&lt;picture&gt;\n    &lt;source type=\"image/webp\" srcset=\"/media/img/red-panda.webp\"&gt;\n    &lt;img src=\"/media/img/red-panda.png\" alt=\"\"&gt;\n&lt;/picture&gt;\n</code></pre> <p>In the above example we use <code>sources</code> to specify an alternate image with a <code>type</code> attribute of <code>image/webp</code>. This lets browsers that support WebP to download <code>red-panda.webp</code>, whilst older browsers would download <code>red-panda.png</code>.</p> <p>Like <code>resp_img()</code>, the <code>picture()</code> helper also supports L10n images and other useful attributes via the <code>optional_attributes</code> parameter:</p> <pre><code>picture(\n    url=\"img/panda-mobile.png\",\n    sources=[\n        {\n            \"media\": \"(max-width: 799px)\",\n            \"srcset\": {\n                \"img/panda-mobile.png\": \"default\"\n            }\n        },\n        {\n            \"media\": \"(min-width: 800px)\",\n            \"srcset\": {\n                \"img/panda-desktop.png\": \"default\"\n            }\n        }\n    ],\n    optional_attributes={\n        \"alt\": \"Red Panda\",\n        \"class\": \"panda-hero\",\n        \"l10n\": True,\n        \"loading\": \"lazy\",\n    }\n)\n</code></pre>"},{"location":"coding/#which-image-helper-should-you-use","title":"Which image helper should you use?","text":"<p>This is a good question. The answer depends entirely on the image in question. A good rule of thumb is as follows:</p> <p>-</p> <pre><code>Is the image a vector format (e.g. `.svg`)?\n\n:   -   If yes, then for most cases you can simply use `static()`.\n</code></pre> <p>-</p> <pre><code>Is the image a raster format (e.g. `.png` or `.jpg`)?\n\n:   -   Is the same image displayed on both large and small\n        viewports? Does the image need to scale as the browser\n        resizes? If yes to both, then use `resp_img()` with both\n        `srcset` and `sizes`.\n    -   Is the image fixed in size (non-responsive)? Do you need to\n        serve a high resolution version? If yes to both, then use\n        `resp_img()` with just `srcset`.\n</code></pre> <ul> <li> <p>Does the source image need to change depending on a media query (e.g     serve a different image on both desktop and mobile)? If yes, then     use <code>picture()</code> with <code>media</code> and <code>srcset</code>.</p> </li> <li> <p>Is the image format only supported in certain browsers? Do you need     to provide a fallback? If yes to both, then use <code>picture()</code> with     <code>type</code> and <code>srcset</code>.</p> </li> </ul>"},{"location":"coding/#secondary-image-helpers","title":"Secondary image helpers","text":"<p>The following image helpers are less commonly used, but exist to support more specific use cases. Some are also encapsulated as features inside inside of primary helpers, such as <code>l1n_img()</code>.</p>"},{"location":"coding/#l10n_img","title":"l10n_img()","text":"<p>Images that have translatable text can be handled with <code>l10n_img()</code>:</p> <pre><code>&lt;img src=\"{{ l10n_img('firefox/os/have-it-all/messages.jpg') }}\"&gt;\n</code></pre> <p>The images referenced by <code>l10n_img()</code> must exist in <code>media/img/l10n/</code>, so for above example, the images could include <code>media/img/l10n/en-US/firefox/os/have-it-all/messages.jpg</code> and <code>media/img/l10n/es-ES/firefox/os/have-it-all/messages.jpg</code>.</p>"},{"location":"coding/#qrcode","title":"qrcode()","text":"<p>This is a helper function that will output SVG data for a QR Code at the spot in the template where it is called. It caches the results to the <code>data/qrcode_cache</code> directory, so it only generates the SVG data one time per data and box_size combination.</p> <pre><code>qrcode(\"https://accounts.firefox.com\", 30)\n</code></pre> <p>The first argument is the data you'd like to encode in the QR Code (usually a URL), and the second is the \"box size\". It's a parameter that tells the generator how large to set the height and width parameters on the XML SVG tag, the units of which are \"mm\". This can be overriden with CSS so you may not need to use it at all. The <code>box_size</code> parameter is optional.</p>"},{"location":"coding/#using-large-assets","title":"Using Large Assets","text":"<p>We don't want to (and if large enough GitHub won't let us) commit large files to the bedrock repo. Files such as large PDFs or very-high-res JPG files (e.g. leadership team photos), or videos are not well-tracked in git and will make every checkout after they're added slower and this diffs less useful. So we have another domain at which we upload these files: assets.mozilla.net</p> <p>This domain is simply an AWS S3 bucket with a CloudFront CDN in front of it. It is highly available and fast. We've made adding files to this domain very simple using git-lfs. You simply install git-lfs, clone our assets.mozilla.net repo, and then add and commit files under the <code>assets</code> directory there as usual. Open a pull request, and once it's merged it will be automatically uploaded to the S3 bucket and be available on the domain.</p> <p>For example, if you add a file to the repo under <code>assets/pdf/the-dude-abides.pdf</code>, it will be available as https://assets.mozilla.net/pdf/the-dude-abides.pdf. Once that is done you can link to that URL from bedrock as you would any other URL.</p>"},{"location":"coding/#writing-migrations","title":"Writing Migrations","text":"<p>Bedrock uses Django's built-in Migrations framework for its database migrations, and has no custom database routing, etc. So, no big surprises here -- write things as you regularly would.</p> <p>However, as with any complex system, care needs to be taken with schema changes that drop or rename database columns. Due to the way the rollout process works (ask for details directly from the team), an absent column can cause some of the rollout to enter a crashloop.</p> <p>To avoid this, split your changes across releases, such as below.</p> <p>For column renames:</p> <ul> <li>Release 1: Add your new column</li> <li>Release 2: Amend the codebase to use it instead of the old column</li> <li>Release 3: Clean up - drop the old, deprecated column, which should     not be referenced in code at this point.</li> </ul> <p>For column drops:</p> <ul> <li>Release 1: Update all code that uses the relevant column, so that     nothing interacts with it any more.</li> <li>Release 2: Clean up - drop the old, deprecated column.</li> </ul> <p>With both paths, check for any custom schema or data migrations that might reference the deprecated column.</p>"},{"location":"coding/#writing-views","title":"Writing Views","text":"<p>You should rarely need to write a view for mozilla.org. Most pages are static and you should use the <code>page</code> function documented above.</p> <p>If you need to write a view and the page is translated or translatable then it should use the <code>l10n_utils.render()</code> function to render the template.</p> <pre><code>from lib import l10n_utils\n\nfrom django.views.decorators.http import require_safe\n\n\n@require_safe\ndef my_view(request):\n    # do your fancy things\n    ctx = {\"template_variable\": \"awesome data\"}\n    return l10n_utils.render(request, \"app/template.html\", ctx)\n</code></pre> <p>Make sure to namespace your templates by putting them in a directory named after your app, so instead of templates/template.html they would be in templates/blog/template.html if <code>blog</code> was the name of your app.</p> <p>The <code>require_safe</code> ensures that only <code>GET</code> or <code>HEAD</code> requests will make it through to your view.</p> <p>If you prefer to use Django's Generic View classes we have a convenient helper for that. You can use it either to create a custom view class of your own, or use it directly in a <code>urls.py</code> file.</p> <pre><code># app/views.py\nfrom lib.l10n_utils import L10nTemplateView\n\nclass FirefoxRoxView(L10nTemplateView):\n    template_name = \"app/firefox-rox.html\"\n\n# app/urls.py\nurlpatterns = [\n    # from views.py\n    path(\"firefox/rox/\", FirefoxRoxView.as_view()),\n    # directly\n    path(\"firefox/sox/\", L10nTemplateView.as_view(template_name=\"app/firefox-sox.html\")),\n]\n</code></pre> <p>The <code>L10nTemplateView</code> functionality is mostly in a template mixin called <code>LangFilesMixin</code> which you can use with other generic Django view classes if you need one other than <code>TemplateView</code>. The <code>L10nTemplateView</code> already ensures that only <code>GET</code> or <code>HEAD</code> requests will be served.</p>"},{"location":"coding/#variation-views","title":"Variation Views","text":"<p>We have a generic view that allows you to easily create and use a/b testing templates. If you'd like to have either separate templates or just a template context variable for switching, this will help you out. For example.</p> <pre><code># urls.py\n\nfrom django.urls import path\n\nfrom bedrock.utils.views import VariationTemplateView\n\nurlpatterns = [\n    path(\"testing/\",\n         VariationTemplateView.as_view(template_name=\"testing.html\",\n                                       template_context_variations=[\"a\", \"b\"]),\n         name=\"testing\"),\n]\n</code></pre> <p>This will give you a context variable called <code>variation</code> that will either be an empty string if no param is set, or <code>a</code> if <code>?v=a</code> is in the URL, or <code>b</code> if <code>?v=b</code> is in the URL. No other options will be valid for the <code>v</code> query parameter and <code>variation</code> will be empty if any other value is passed in for <code>v</code> via the URL. So in your template code you'd simply do the following:</p> <pre><code>{% if variation == 'b' %}&lt;p&gt;This is the B variation of our test. Enjoy!&lt;/p&gt;{% endif %}\n</code></pre> <p>If you'd rather have a fully separate template for your test, you can use the <code>template_name_variations</code> argument to the view instead of <code>template_context_variations</code>.</p> <pre><code># urls.py\n\nfrom django.urls import path\n\nfrom bedrock.utils.views import VariationTemplateView\n\nurlpatterns = [\n    path(\"testing/\",\n         VariationTemplateView.as_view(template_name=\"testing.html\",\n                                       template_name_variations=[\"1\", \"2\"]),\n         name=\"testing\"),\n]\n</code></pre> <p>This will not provide any extra template context variables, but will instead look for alternate template names. If the URL is <code>testing/?v=1</code>, it will use a template named <code>testing-1.html</code>, if <code>v=2</code> it will use <code>testing-2.html</code>, and for everything else it will use the default. It simply puts a dash and the variation value between the template file name and file extension.</p> <p>It is theoretically possible to use the template name and template context versions of this view together, but that would be an odd situation and potentially inappropriate for this utility.</p> <p>You can also limit your variations to certain locales. By default the variations will work for any localization of the page, but if you supply a list of locales to the <code>variation_locales</code> argument to the view then it will only set the variation context variable or alter the template name (depending on the options explained above) when requested at one of said locales. For example, the template name example above could be modified to only work for English or German like so</p> <pre><code># urls.py\n\nfrom django.urls import path\n\nfrom bedrock.utils.views import VariationTemplateView\n\nurlpatterns = [\n    path(\"testing/\",\n         VariationTemplateView.as_view(template_name=\"testing.html\",\n                                       template_name_variations=[\"1\", \"2\"],\n                                       variation_locales=[\"en-US\", \"de\"]),\n         name=\"testing\"),\n]\n</code></pre> <p>Any request to the page in for example French would not use the alternate template even if a valid variation were given in the URL.</p> <p>Note</p> <p>If you'd like to add this functionality to an existing Class-Based View, there is a mixin that implements this pattern that should work with most views: <code>bedrock.utils.views.VariationMixin</code>.</p>"},{"location":"coding/#geo-template-view","title":"Geo Template View","text":"<p>Now that we have our CDN configured properly, we can also just swap out templates per request country. This is very similar to the above, but it will simply use the proper template for the country from which the request originated.</p> <pre><code>from bedrock.base.views import GeoTemplateView\n\nclass CanadaIsSpecialView(GeoTemplateView):\n    geo_template_names = {\n        \"CA\": \"mozorg/canada-is-special.html\",\n    }\n    template_name = \"mozorg/everywhere-else-is-also-good.html\"\n</code></pre> <p>For testing purposes while you're developing or on any deployment that is not accessed via the production domain (www.mozilla.org) you can append your URL with a <code>geo</code> query param (e.g. <code>/firefox/?geo=DE</code>) and that will take precedence over the country from the request header.</p>"},{"location":"coding/#other-geo-stuff","title":"Other Geo Stuff","text":"<p>There are a couple of other tools at your disposal if you need to change things depending on the location of the user. You can use the <code>bedrock.base.geo.get_country_from_request</code> function in a view and it will return the country code for the request (either from the CDN or the query param, just like above).</p> <pre><code>from bedrock.base.geo import get_country_from_request\n\ndef dude_view(request):\n    country = get_country_from_request(request)\n    if country == \"US\":\n        # do a thing for the US\n    else:\n        # do the default thing\n</code></pre> <p>The other convenience available is that the country code, either from the CDN or the query param, is avilable in any template in the <code>country_code</code> variable. This allows you to change anything about how the template renders based on the location of the user.</p> <pre><code>{% if country_code == \"US\" %}\n    &lt;h1&gt;GO MURICA!&lt;/h1&gt;\n{% else %}\n    &lt;h1&gt;Yay World!&lt;/h1&gt;\n{% endif %}\n</code></pre> <p>Reference:</p> <ul> <li>Officially assigned list of ISO country     codes.</li> </ul>"},{"location":"coding/#coding-style","title":"Coding Style","text":"<p>Bedrock uses the following open source tools to follow coding styles and conventions, as well as applying automatic code formatting:</p> <ul> <li>ruff for Python style, code quality     rules, and import ordering.</li> <li>black for Python code formatting.</li> <li>Prettier for JavaScript code formatting.</li> <li>ESLint for JavaScript code quality rules.</li> <li>Stylelint for Sass/CSS style and code     quality rules.</li> </ul> <p>For front-end HTML &amp; CSS conventions, bedrock uses Mozilla's Protocol design system for building components. You can read the Protocol documentation site for more information.</p> <p>Mozilla also has some more general coding styleguides available, although some of these are now rather outdated:</p> <ul> <li>Mozilla Python Style     Guide</li> <li>Mozilla HTML Style     Guide</li> <li>Mozilla JS Style     Guide</li> <li>Mozilla CSS Style     Guide</li> </ul>"},{"location":"coding/#test-coverage","title":"Test coverage","text":"<p>When the Python tests are run, a coverage report is generated, showing which lines of the codebase have tests that execute them, and which do not. You can view this report in your browser at <code>file:///path/to/your/checkout/of/bedrock/python_coverage/index.html</code>.</p> <p>When adding code, please aim to provide solid test coverage, using the coverage report as a guide. This doesn't necessarily mean every single line needs a test, and 100% coverage doesn't mean 0% defects.</p>"},{"location":"coding/#configuring-your-code-editor","title":"Configuring your Code Editor","text":"<p>Bedrock includes an <code>.editorconfig</code> file in the root directory that you can use with your code editor to help maintain consistent coding styles. Please see editorconfig.org. for a list of supported editors and available plugins.</p>"},{"location":"coding/#working-with-protocol-design-system","title":"Working with Protocol Design System","text":"<p>Bedrock uses the Protocol Design System to quickly produce consistent, stable components. There are different methods -- depending on the component -- to import a Protocol component into our codebase.</p> <p>One method involves two steps:</p> <ol> <li>Adding the correct markup or importing the     appropriate macro to the page's HTML file.</li> <li>Importing the necessary Protocol styles to a page's SCSS file.</li> </ol> <p>The other method is to import CSS bundles onto the HTML file. However, this only works for certain components, which are listed below in the respective section.</p>"},{"location":"coding/#styles-and-components","title":"Styles and Components","text":"<p>The base templates in Bedrock have global styles from Protocol that apply to every page. When we need to extend these styles on a page-specific basis, we set up Protocol in a page-specific SCSS file.</p> <p>For example, on a Firefox product page, we might want to use Firefox logos or wordmarks that do not exist on every page.</p> <p>To do this, we add Protocol <code>mzp-</code> classes to the HTML:</p> <pre><code>// bedrock/bedrock/firefox/templates/firefox/{specific-page}.html\n\n&lt;div class=\"mzp-c-wordmark mzp-t-wordmark-md mzp-t-product-firefox\"&gt;\n    Firefox Browser\n&lt;/div&gt;\n</code></pre> <p>Then we need to include those Protocol styles in the page's SCSS file:</p> <pre><code>/* bedrock/media/css/firefox/{specific-page}.scss */\n\n/* if we need to use protocol images, we need to set the $image-path variable */\n$image-path: '/media/protocol/img';\n/* mozilla is the default theme, so if we want a different one, we need to set the $brand-theme variable */\n$brand-theme: 'firefox';\n\n/* the lib import is always essential: it provides access to tokens, functions, mixins, and theming */\n@import '~@mozilla-protocol/core/protocol/css/includes/lib';\n/* then you add whatever specific protocol styling you need */\n@import '~@mozilla-protocol/core/protocol/css/components/logos/wordmark';\n@import '~@mozilla-protocol/core/protocol/css/components/logos/wordmark-product-firefox';\n</code></pre> <p>Note</p> <p>If you create a new SCSS file for a page, you will have to include it in that page's CSS bundle by updating static-bundles.json file.</p>"},{"location":"coding/#macros","title":"Macros","text":"<p>The team has created several Jinja macros out of Protocol components to simplify the usage of components housing larger blocks of code (i.e. Billboard). The code housing the custom macros can be found in our protocol macros file. These Jinja macros include parameters that are simple to define and customize based on how the component should look like on a given page.</p> <p>To use these macros in files, we simply import a macro to the page's HTML code and call it with the desired arguments, instead of manually adding Protocol markup. We can import multiple macros in a comma-separated fashion, ending the import with <code>with context</code>:</p> <pre><code>// bedrock/bedrock/firefox/templates/firefox/{specific-page}.html\n\n{% from \"macros-protocol.html\" import billboard with context %}\n\n{{ billboard(\n    title='This is Firefox.',\n    ga_title='This is Firefox',\n    desc='Firefox is an awesome web browser.',\n    link_cta='Click here to install',\n    link_url=url('firefox.new')\n  )}}\n</code></pre> <p>Because not all component styles are global, we still have to import the page-specific Protocol styles in SCSS:</p> <pre><code>/* bedrock/media/css/firefox/{specific-page}.scss */\n\n$brand-theme: 'firefox';\n\n@import '~@mozilla-protocol/core/protocol/css/includes/lib';\n@import '~@mozilla-protocol/core/protocol/css/components/billboard';\n</code></pre>"},{"location":"coding/#import-css-bundles","title":"Import CSS Bundles","text":"<p>We created pre-built CSS bundles to be used for some components due to their frequency of use. This method only requires an import into the HTML template. Since it's a separate CSS bundle, we don't need to import that component in the respective page CSS. The CSS bundle import only works for the following components:</p> <ul> <li>Split</li> <li>Card</li> <li>Picto</li> <li>Callout</li> <li>Article</li> <li>Newsletter form</li> <li>Emphasis box</li> </ul> <p>Include a CSS bundle in the template's <code>page_css</code> block along with any other page-specific bundles, like so:</p> <pre><code>{% block page_css %}\n    {{ css_bundle('protocol-split') }}\n    {{ css_bundle('protocol-card') }}\n    {{ css_bundle('page-specific-bundle') }}\n{% endblock %}\n</code></pre>"},{"location":"content-cards/","title":"Using External Content Cards Data","text":"<p>The www-admin repo contains data files and images that are synced to bedrock and available for use on any page. The docs for updating said data is available via that repo, but this page will explain how to use the cards data once it's in the bedrock database.</p>"},{"location":"content-cards/#add-to-a-view","title":"Add to a View","text":"<p>The easiest way to make the data available to a page is to add the <code>page_content_cards</code> variable to the template context:</p> <pre><code>from bedrock.contentcards.models import get_page_content_cards\n\ndef view_with_cards(request):\n    locale = l10n_utils.get_locale(request)\n    ctx = {'page_content_cards': get_page_content_cards('home', locale)}\n    return l10n_utils.render(request, 'sweet-words.html', ctx)\n</code></pre> <p>The <code>get_page_content_cards</code> returns a dict of card data dicts for the given page (<code>home</code> in this case) and locale. The dict keys are the names of the cards (e.g. <code>card_1</code>). If the <code>page_content_cards</code> context variable is available in the template, then the <code>content_card()</code> macro will discover it automatically.</p> <p>Note</p> <p>The <code>get_page_content_cards</code> function is not all that clever as far as l10n is concerned. If you have translated the cards in the www-admin repo that is great, but you should have cards for every locale for which the page is active or the function will return an empty dict. This is especially tricky if you have multiple English locales enabled (en-US, en-CA, en-GB, etc.) and want the same cards to be used for all of them. You'd need to do something like <code>if locale.startswith('en-'):</code> then use <code>en-US</code> in the function call.</p> <p>Alternately you could just wrap the section of the template using cards to be optional in an <code>{% if page_content_cards %}</code> statement, and that way it will not show the section at all if the dict is empty if there are no cards for that page and locale combination.</p>"},{"location":"content-cards/#add-to-the-template","title":"Add to the Template","text":"<p>Once you have the data in the template context, using a card is simple:</p> <pre><code>{% from \"macros-protocol.html\" import content_card with context %}\n\n{{ content_card('card_1') }}\n</code></pre> <p>This will insert the data from the <code>card_1.en-US.md</code> file from the www-admin repo into the template via the <code>card()</code> macro normally used for protocol content cards.</p> <p>If you don't have the <code>page_content_cards</code> variable in the template context and you don't want to create or modify a view, you can fetch the cards via a helper function in the template itself, but you have to pass the result to the macro:</p> <pre><code>{% from \"macros-protocol.html\" import content_card with context %}\n{% set content_cards = get_page_content_cards('home', LANG) %}\n\n{{ content_card('card_1', content_cards) }}\n</code></pre>"},{"location":"contentful/","title":"Contentful CMS Integration","text":""},{"location":"contentful/#overview","title":"Overview","text":"<p>Contentful is a headless CMS. It stores content for our website in a structured format. We request the content from Contentful using an API. Then the content gets made into Protocol components for display on the site.</p> <p>We define the structure Contentful uses to store the data in content models. The content models are used to create a form for editors to fill out when they want to enter new content. Each chunk of content is called an entry.</p> <p>For example: we have a content model for our \"card\" component. That model creates a form with fields like heading, link, blurb, and image. Each card that is created from the model is its own entry.</p> <p>We have created a few different types of content models. Most are components that correspond to components in our design system. The smallest create little bits of code like buttons. The larger ones group together several entries for the smaller components into a bigger component or an entire page.</p> <p>For example: The Page: General model allows editors to include a hero entry, body entry, and callout entry. The callout layout entry, in turn, includes a CTA entry.</p> <p>One advantage of storing the content in small chunks like this is that is can be reused in many different pages. A callout which focuses on the privacy related reasons to download Firefox could end up on the Private Browsing, Ad Tracker Blocking, and Fingerprinter Blocking pages. If our privacy focused tagline changes from \"Keep it secret with Firefox\" to \"Keep it private with Firefox\" it only needs to be updated in one entry.</p> <p>So, when looking at a page on the website that comes from Contentful you are typically looking at several different entries combined together.</p> <p>On the bedrock side, the data for all entries is periodically requested from the API and stored in a database.</p> <p>When a Contentful page is requested the code in [api.py]{.title-ref} transforms the information from the database into a group of Python dictionaries (these are like key/value pairs or an object in JS).</p> <p>This data is then passed to the page template (either Mozilla or for Firefox themed as appropriate). The page template includes some files which take the data and feed it into macros to create Protocol components. These are the same macros we use on non-Contentful pages. There are also includes which will import the appropriate JS and CSS files to support the components.</p> <p>Once rendered the pages get cached on the CDN as usual.</p>"},{"location":"contentful/#contentful-apps","title":"Contentful Apps","text":"<p>Installed on Environment level. Make sure you are in the environment you want to edit before accessing an app. Use Apps link in top navigation of Contentful Web App to find an environment's installed apps.</p>"},{"location":"contentful/#compose","title":"Compose","text":"<p>Compose provides a nicer editing experience. It creates a streamlined view of pages by combining multiple entries into a single edit screen and allowing field groups for better organization.</p> <p>Any changes made to Compose page entries in a specific environment are limited to that environment. If you are in a sandbox environment, you should see an <code>/environments/sandbox-name</code> path at the end of your Compose URL.</p>"},{"location":"contentful/#known-limitations","title":"Known Limitations","text":"<ul> <li>Comments are not available on Compose entries</li> <li>It is not possible to edit embedded entries in Rich Text fields in     Compose app. Selecting the \"edit\" option in the dropdown opens the     entry in the Contentful web app.</li> </ul>"},{"location":"contentful/#merge","title":"Merge","text":"<p>Merge provides a UI for comparing the state of Content Models across two environments. You can select what changes you would like to migrate to a new environment.</p>"},{"location":"contentful/#known-limitations_1","title":"Known Limitations","text":"<ul> <li>Does not migrate Help Text (under Appearance Tab)</li> <li>Does not migrate any apps used with those Content Models</li> <li>Does not migrate Content Entries or Assets</li> <li>It can identify when Content Models should be available in Compose,     but it cannot migrate the field groups</li> </ul>"},{"location":"contentful/#others","title":"Others","text":"<ul> <li>Launch     allows creation of \"releases\", which can help coordinate     publishing of multiple entries</li> <li>Workflows     standardizes process for a specific Content Model. You can specify     steps and permissions to regulate how content moves from draft to     published.</li> </ul>"},{"location":"contentful/#content-models","title":"Content Models","text":""},{"location":"contentful/#emoji-legend-for-content-models","title":"Emoji legend for content models","text":"<ul> <li>\ud83d\udcc4 this component is a page, it will include meta data for the page,     a folder, and slug</li> <li>\ud83c\udf81 this is a layout wrapper for another component</li> <li>\u270f\ufe0f this component includes editable content, not just layout config</li> <li>\u265f this component is suitable for inclusion as an inline entry in a     rich text field</li> <li>\u27a1\ufe0f this component can be embedded without a layout wrapper</li> </ul>"},{"location":"contentful/#naming-conventions-for-content-models","title":"Naming conventions for content models","text":"<p>Note</p> <p>For some fields it is important to be consistent because of how they are processed in bedrock. For all it is important to make the editor's jobs easier.</p> Name <p>This is for the internal name of the entry. It should be set as the Entry title, required, and unique.</p> Preview (and Preview Title, Preview Blurb, Preview Image) <p>These will be used in search results and social media sites. There's also the potential to use them for aggregate pages on our own sites. Copy configuration and validation from an existing page.</p> Heading (and Heading Level) <p>Text on a page which provides context for information that follows it. Usually made into a H1-H4 in bedrock. Not: header, title, or name.</p> Image (and Image Size, Image Width) <p>Not: picture, photo, logo, or icon (unless we are specifically talking about a logo or icon.)</p> Content <p>Multi-reference</p> Product Icon <p>Copy configuration and validation from an existing page.</p> Theme <p>Copy configuration and validation from an existing page.</p> Body (Body Width, Body Vertical Alignment, Body Horizontal Alignment) <p>Rich text field in a Component. Do not use this for multi reference fields, even if the only content on the page is other content entries. Do not use MarkDown for body fields, we can't restrict the markup. Copy configuration and validation from an existing page.</p> Rich Text Content <p>Rich text field in a Compose Page</p> CTA <p>The button/link/dropdown that we want a user to interact with following some content. Most often appearing in Split and Callout components.</p>"},{"location":"contentful/#page","title":"\ud83d\udcc4 Page","text":"<p>Pages in bedrock are created from page entries in Contentful's Compose App.</p> Homepage <p>The homepage needs to be connected to bedrock using a Connect component (see Legacy) and page meta data like title, blurb, image, etc come from bedrock.</p> General <p>Includes hero, text, and callout. The simplified list and order of components is intended to make it easier for editors to put a page together.</p> Versatile <p>No pre-defined template. These pages can be constructed from any combination of layout and component entries.</p> Resource Center <p>Includes product, category, tags, and a rich text editor. These pages follow a recognizable format that will help orient users looking for more general product information (i.e. VPN).</p> <p>The versatile and general templates do not need bedrock configuration to be displayed. Instead, they should appear automatically at the folder and slug specified in the entry. These templates do include fields for meta data.</p>"},{"location":"contentful/#layout","title":"\ud83c\udf81 Layout","text":"<p>These entries bring a group of components together. For example: 3 picto blocks in a picto block layout. They also include layout and theme options which are applied to all of the components they bring together. For example: centering the icons in all 3 picto blocks.</p> <p>These correspond roughly to Protocol templates.</p> <p>The one exception to the above is the Layout: Large Card, which exists to attach a large display image to a regular card entry. The large card must still be included in the Layout: 5 Cards.</p>"},{"location":"contentful/#component","title":"\u270f\ufe0f Component","text":"<p>We're using this term pretty loosely. It corresponds roughly to a Protocol atom, molecule, or organism.</p> <p>These entries include the actual content, the bits that people write and the images that go with it.</p> <p>If they do not require a layout wrapper there may also be some layout and theme options. For example, the text components include options for width and alignment.</p>"},{"location":"contentful/#embed","title":"\u265f Embed","text":"<p>These pre-configured content pieces can go in rich text editors when allowed (picto, split, multi column text...).</p> <p>Embeds are things like logos, where we want tightly coupled style and content that will be consistent across entries. If a logo design changes, we only need to update it in one place, and all uses of that embed will be updated.</p>"},{"location":"contentful/#adding-a-new-page","title":"Adding a new \ud83d\udcc4 Page","text":"<ul> <li> <p>Create the content model</p> <ul> <li> <p>Ensure the content model name starts with page (i.e.     pageProductJournalismStory)</p> </li> <li> <p>Add an SEO reference field which requires the SEO Metadata     content type</p> </li> <li> <p>In Compose, go to Page Types and click \"Manage Page Types\" to     make your new content model available to the Compose editor.</p> <ul> <li>If you have referenced components, you can choose     whether they will be displayed as expanded by default.</li> <li>Select \"SEO\" field for \"Page Settings\" field</li> </ul> </li> <li> <p>If the page is meant to be localised, ensure all fields that     need localisation have the \"Enable localization of this field\"     checkbox checked in content model field settings</p> </li> </ul> </li> <li> <p>Update <code>bedrock/contentful/constants</code></p> <ul> <li>Add content type constant</li> <li>Add constant to default array</li> <li>If page is for a single locale only, add to     SINGLE_LOCALE_CONTENT_TYPES</li> <li>If page is localised, add to     LOCALISATION_COMPLETENESS_CHECK_CONFIG with an array of     localised fields that need to be checked before the page's     translation can be considered complete</li> </ul> </li> <li> <p>Update <code>bedrock/contentful/api.py</code></p> <ul> <li>If you're adding new embeddable content types, expand list of     renderer helpers configured for the RichTextRenderer in the     <code>ContentfulAPIWrapper</code></li> <li>Update <code>ContentfulAPIWrapper.get_content()</code> to have a clause     to handle the new page type</li> </ul> </li> <li> <p>Create a custom view to pass the     Contentful data to a template</p> </li> </ul>"},{"location":"contentful/#adding-a-new-component","title":"Adding a new \u270f\ufe0f Component","text":"<p>Example: Picto</p> <ol> <li>Create the content model in Contentful.<ul> <li>Follow the naming conventions.</li> <li>You may need two models if you are configuring layout     separately.</li> </ul> </li> <li>Add the new content model to the list of allowed references in other     content models (At the moment this is just the \"content\" reference     field on pages).</li> <li>In bedrock create CSS and JS entries in static-bundles for the new     component.</li> <li>In api.py write a def for the component.</li> <li>In api.py add the component name, def, and bundles to the     CONTENT_TYPE_MAP.</li> <li>Find or add the macro to macros-protocol.</li> <li>Import the macro into all.html and add a call to it in the entries     loop.</li> </ol> <p>Tips</p> <ul> <li>can't define defaults in Contentful, so set those in your Python     def.</li> <li>for any optional fields make sure you check the field exists before     referencing the content.</li> </ul>"},{"location":"contentful/#adding-a-new-embed","title":"Adding a new \u265f Embed","text":"<p>Example: Wordmark.</p> <ol> <li>Create the content model in Contentful.<ul> <li>Follow the naming conventions.</li> </ul> </li> <li>Add the new content model to rich text fields (like split and text).</li> <li>In bedrock include the CSS in the Sass file for any component which     may use it (yeah, this is not ideal, hopefully we will have better     control in the future).</li> <li>Add a def to api.py to render the piece (like <code>_make_wordmark</code>).</li> </ol> <p>Tips</p> <ul> <li>can't define defaults in Contentful, so set those in your Python     def.</li> <li>for any optional fields make sure you check the field exists before     referencing the content.</li> </ul>"},{"location":"contentful/#adding-a-rich-text-field-in-a-component","title":"Adding a rich text field in a component","text":"<p>Disable everything then enable: B, I, UL, OL, Link to URL, and Inline entry. You will want to enable some some Headings as well, H1 should be enabled very rarely. Enable H2-H4 using your best judgement.</p>"},{"location":"contentful/#adding-support-for-a-new-product-icon-size-folder","title":"Adding support for a new product icon, size, folder","text":"<p>Many content models have drop downs with identical content. For example: the Hero, Callout, and Wordmark models all include a \"product icon\". Other common fields are width and folder.</p> <p>There are two ways to keep these lists up to date to reflect Protocol updates:</p> <ol> <li>By opening and editing the content models individually in Contentful</li> <li>Scripting updates using the API</li> </ol> <p>At the moment it's not too time consuming to do by hand, just make sure you are copy and pasting to avoid introducing spelling errors.</p> <p>We have not tried scripting updates with the API yet. One thing to keep in mind if attempting this is that not all widths are available on all components. For example: the \"Text: Four columns\" component cannot be displayed in small content widths.</p>"},{"location":"contentful/#rich-text-rendering","title":"Rich Text Rendering","text":"<p>Contentful provides a helper library to transform the rich text fields in the API into HTML content.</p> <p>In places were we disagree with the rendering or want to enhance the rendering we can provide our own renderers on the bedrock side. They can be as simple as changing [\\&lt;b&gt;]{.title-ref} tags to [\\&lt;strong&gt;]{.title-ref} tags or as complex as inserting a component.</p> <p>A list of our custom renderers is passed to the [RichTextRenderer]{.title-ref} helper at the start of the [ContentfulPage]{.title-ref} class in api.py. The renderers themselves are also defined in api.py</p> <p>Note</p> <ul> <li>Built-in nodes cannot be extended or customized: Custom node types     and marks are not allowed. Embed entry types are required to extend     rich text functionality. (i.e. if you need more than one style of     blockquote)</li> </ul>"},{"location":"contentful/#l10n","title":"L10N","text":""},{"location":"contentful/#smartling-our-selected-approach","title":"Smartling - our selected approach","text":"<p>When setting up a content model in Contentful, fields can be designated as available for translation.</p> <p>Individual users can be associated with different languages, so when they edit entries they see duplicate fields for each language they can translate into. In addition - and in the most common case - these fields are automatically sent to Smartling to be translated there.</p> <p>Once text for translation lands in Smartling, it is batched up into jobs for human translation. When the work is complete, Smartling automatically updates the relevant Contentful entries with the translations, in the appropriate fields.</p> <p>Note that those translations are only visible in Contentful if you select to view that locale's fields, but if they are present in Contentful's datastore (and that locale is enabled in the API response) they will be synced down by Bedrock.</p> <p>On the Bedrock side, the translated content is pulled down the same way as the default locale's content is, and is stored in a locale-specific ContentfulEntry in the database.</p> <p>In terms of 'activation', or \"Do we have all the parts to show this Contentful content\"?, Contentful content is not evaluated in the same way as Fluent strings (where we will show a page in a given locale if 80% of its Fluent strings have been translated, falling back to en-US where not).</p> <p>Instead, we check that all of the required fields present in the translated Entry have non-null data, and if so, then the entire page is viable to show in the given locale. (ie, we look at fields, not strings. It's a coarser level of granularity compared to Fluent, because the data is organised differently -most of Contentful-sourced content will be rich text, not individual strings).</p> <p>The check about whether or not a Contentful entry is 'active' or 'localisation complete' happens during the main sync from Contentful. Note that there is no fallback locale for Contentful content other than a redirect to the en-US version of the page - either the page is definitely available in a locale, or it's not at all available in that locale.</p> <p>Notes</p> <ul> <li>The batching of jobs in Smartling is still manual, even though the     data flow is automated. We need to keep an eye on how onerous this     is, plus what the cost exposure could be like if we fully automate     it.</li> <li>The Smartling integration is currently only set to use     Mozilla.org's 10 most popular locales, in addition to en-US.</li> <li>No localisation of Contentful content happens via Pontoon.</li> <li>The Smartling setup is most effectively leveraged with     Compose-based pages rather than Connect-based components, and the     latter may require some code tweaks.</li> <li>Our Compose: SEO field in Contentful is configured for translation     (and in use on the VPN Resource Center). All Compose pages require     this field. If a Compose page type is not meant to be localised,     we need to stop these SEO-related fields from going on to     Smartling.</li> </ul>"},{"location":"contentful/#fluent","title":"Fluent","text":"<p>NB: Not selected for use, but notes retained for reference</p> <p>Instead of using the language translation fields in Contentful to store translations we could designate one of the locales to contain a fluent string ID. Bedrock could then use the string IDs and the English content to create Fluent files for submission into our current translation system.</p> <p>Creation of the string IDs could be automated using Contentful's write API.</p> <p>To give us the ability to use fallback strings the Contentful field could accept a comma separated list of values.</p> <p>This approach requires significant integration code on the bedrock side but comes with the benefit of using our current translation system, including community contributions.</p>"},{"location":"contentful/#no-english-equivalent","title":"No English Equivalent","text":"<p>NB: Not selected for use, but notes retained for reference</p> <p>Components could be created in the language they are intended to display in. The localized content would be written in the English content fields.</p> <p>The down sides of this are that we do not know what language the components are written in and could accidentally display the wrong language on any page. It also means that localized content cannot be created automatically by English editors and translations would have to be manually associated with URLs.</p> <p>This is the approach that will likely be used for the German and French homepages since that content is not going to be used on English pages and creating a separate homepage with different components is valuable to the German and French teams.</p>"},{"location":"contentful/#assets","title":"Assets","text":"<p>Images that are uploaded in Contentful will be served to site visitors from the Contentful CDN. The cost of using the CDN are not by request so we don't have to worry about how many times an image will be requested.</p> <p>Using the Contentful CDN lets us use their Images API to format our images.</p> <p>In theory, a large high quality image is uploaded in Contentful and then bedrock inserts links to the CDN for images which are cropped to fit their component and resized to fit their place on the page.</p> <p>Because we cannot rely on the dimensions of the image uploaded to Contentful as a guide for displaying the image - bedrock needs to be opinionated about what size images it requests based on the component and its configuration. For example, hero images are fixed at 800px wide. In the future this could be a user configurable option.</p>"},{"location":"contentful/#preview","title":"Preview","text":"<p>Content previews are configured under Settings &gt; Content preview on a per-content model basis. At the moment previews are only configured for pages, and display on demo5.</p> <p>Once the code is merged into bedrock they should be updated to use the dev server.</p> <p>Specific URLs will only update every 5 minutes as the data is pulled from the API but pages can be previewed up to the second at the [contentful-preview]{.title-ref} URL. This preview will include \"changed\" and \"draft\" changes (even if there is an error in the data) not just published changes.</p> <p>For previewing on localhost, see Development Practices, below.</p>"},{"location":"contentful/#rolespermissions","title":"Roles/Permissions","text":"<p>In general we are trusting people to check their work before publishing and very few guard rails have been installed. We have a few roles with different permissions.</p> Admin <p>Organization</p> <ul> <li>Define roles and permission</li> <li>Manage users</li> <li>Change master and sandbox environment aliases</li> <li>Create new environments</li> </ul> <p>Master environment</p> <ul> <li>Edit content model</li> <li>Create, Edit, Publish, Archive, Delete content</li> <li>Install/Uninstall apps</li> </ul> Developer <p>Organization</p> <ul> <li>Create new environments</li> </ul> <p>Master environment</p> <ul> <li>Create, Edit, Publish, Archive content</li> </ul> <p>Sandbox environments (any non-master environment)</p> <ul> <li>Edit content model</li> <li>Create, Edit, Publish, Archive, Delete content</li> <li>Install/Uninstall apps</li> </ul> Editor (WIP) <p>Master environment (through Compose)</p> <ul> <li>Create, Edit, Publish, Archive content</li> </ul>"},{"location":"contentful/#development-practices","title":"Development practices","text":"<p>This section outlines tasks generally required if developing features against Contentful.</p>"},{"location":"contentful/#get-bedrock-set-up-locally-to-work-with-contentful","title":"Get bedrock set up locally to work with Contentful","text":"<p>In your <code>.env</code> file for Bedrock, make sure you have the followign environment variables set up.</p> <ul> <li><code>CONTENTFUL_SPACE_ID</code> - this is the ID of our Contentful integration</li> <li><code>CONTENTFUL_SPACE_KEY</code> - this is the API key that allows you access     to our space. Note that two types of key are available: a Preview     key allows you to load in draft content; the Delivery key only loads     published contnet. For local dev, you want a Preview key.</li> <li><code>SWITCH_CONTENTFUL_HOMEPAGE_DE</code> should be set to <code>True</code> if you are     working on the German Contentful-powered homepage</li> <li><code>CONTENTFUL_ENVIRONMENT</code> Contentful has 'branches' which it calls     environments. [master]{.title-ref} is what we use in production, and     [sandbox]{.title-ref} is generally what we use in development. It's     also possible to reference a specific environment - e.g.     <code>CONTENTFUL_ENVIRONMENT=sandbox-2021-11-02</code></li> </ul> <p>To get values for these vars, please check with someone on the backend team.</p> <p>If you are working on the Contentful Sync backed by the message-queue (and if you don't know what this is, you don't need it for local dev), you will also need to set the following env vars:</p> <ul> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_URL</code></li> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_REGION</code></li> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_ACCESS_KEY_ID</code></li> <li><code>CONTENTFUL_NOTIFICATION_QUEUE_SECRET_ACCESS_KEY</code></li> </ul>"},{"location":"contentful/#how-to-preview-your-changes-on-localhost","title":"How to preview your changes on localhost","text":"<p>When viewing a page in Contentful, it's possible to trigger a preview of the draft page. This is typically rendered on www-dev.allizom.org. However, that's only useful for code that's already in <code>main</code>. If you want to preview Contentful content on your local machine - e.g. you're working on a feature branch that isn't ready for merging - do the following:</p>"},{"location":"contentful/#existing-master-content-types","title":"Existing (master) Content Types","text":"<p>In the right-hand sidebar of the editor page in Contentful:</p> <ul> <li>Find the Preview section</li> <li>Select <code>Change</code> and pick <code>Localhost Preview</code></li> <li>Click <code>Open preview</code></li> </ul>"},{"location":"contentful/#new-non-master-content-types","title":"New (non-master) Content Types","text":"<p>In bedrock:</p> <ul> <li>Update <code>class ContentfulPreviewView(L10nTemplateView)</code> in Mozorg     Views     with a render case for your new content type</li> </ul> <p>In the right-hand sidebar of the editor page in Contentful:</p> <ul> <li>Click Info tab</li> <li>Find <code>Entry ID</code> section and copy the value</li> </ul> <p>Manually create preview URL in browser:</p> <ul> <li>[http://localhost:8000/en-US/contentful-preview/{entry_id}/]{.title-ref}</li> </ul> <p>Note that previewing a page will require it to be pulled from Contentful's API, so you will need <code>CONTENTFUL_SPACE_ID</code> and <code>CONTENTFUL_SPACE_KEY</code> set in your <code>.env</code>. It may take a few seconds to get the data.</p> <p>Also note that when you select <code>Localhost preview</code>, the choice sticks, so you should set it back to <code>Preview on web</code> when you're done.</p>"},{"location":"contentful/#how-to-updaterefresh-the-sandbox-environment","title":"How to update/refresh the sandbox environment","text":"<p>It helps to think of Contentful 'environments' as simply branches of a git-like repo full of content. You can take a particular environment and branch off it to make a new environment for WIP or experimental content, using the original one as your starting point. On top of this, Contentful has the concept of aliases for environments and we use two aliases in our setup:</p> <ul> <li><code>master</code> is used for production and is an alias currently pointing     to the [V1]{.title-ref} environment. It is pretty stable and access     to it is limited.</li> <li><code>sandbox</code> is used for development and more team members have access     to edit content. Again, it's an alias and is pointed at an     environment (think, branch) with a name in the format     <code>sandbox-YYYY-MM-DD</code>.</li> </ul> <p>While updating <code>master</code> is something that we generally don't do (at the moment only a product owner and/or admin would do this), updating the sandbox happens more often, typically to populate it with data more recently added to master. To do this:</p> <ul> <li>Go to <code>Settings &gt; Environments</code></li> <li>Ensure we have at least one spare environment slot. If we don't     delete the oldest <code>sandbox-XXXX-XX-XX</code> environment.</li> <li>Click the blue Add Environment button, to the right. Name it using     the <code>sandbox-YYYY-MM-DD</code> pattern and base it on whatever environment     is aliased to <code>master</code> - this will basically create a new 'branch'     with the content currently in master.</li> <li>In the Environment Aliases section of the main page, find     [sandbox]{.title-ref} and click Change alias target, then select the     <code>sandbox-XXXX-XX-XX</code> environment you just made.</li> </ul>"},{"location":"contentful/#which-environment-is-connected-to-where","title":"Which environment is connected to where?","text":"<p><code>master</code> is the environment used in Bedrock production, stage, dev and test <code>sandbox</code> may, in the future, be made the default environment for dev. It's also the one we should use for local development.</p> <p>If you develop a new feature that adds to Contentful (e.g. page or component) and you author it in the sandbox, you will need to re-create it in master before the corresponding bedrock changes hit production.</p>"},{"location":"contentful/#troubleshooting","title":"Troubleshooting","text":"<p>If you run into trouble on an issue, be sure to check in these places first and include the relevant information in requests for help (i.e. environment).</p>"},{"location":"contentful/#contentful-content-model-entries","title":"Contentful Content Model &amp; Entries","text":"<ul> <li>What environment are you using?</li> <li>Do you have the necessary permissions to make changes?</li> <li>Do you see all the entry fields you need? Do those fields have the     correct value options?</li> </ul>"},{"location":"contentful/#bedrock-api-apipy","title":"Bedrock API (api.py)","text":"<ul> <li>What environment are you using?</li> <li>Can you find a Python function definition for the content type you     need?</li> <li>Does it structure data as expected?</li> </ul> <pre><code># example content type def\n\ndef get_section_data(self, entry_obj):\n    fields = entry_obj.fields()\n    # run `print(fields)` here to verify field values from Contentful\n\n    data = {\n        \"component\": \"sectionHeading\",\n        \"heading\": fields.get(\"heading\"),\n    }\n\n    # run `print(data)` here to verify data values from Bedrock API\n    return data\n</code></pre>"},{"location":"contentful/#bedrock-render-allhtml","title":"Bedrock Render (all.html)","text":"<ul> <li>Can you find a render condition for the component you need?</li> </ul> <pre><code>/* example component condition */\n\n{% elif entry.component == 'sectionHeading' %}\n</code></pre> <p>-</p> <pre><code>If the component calls a macro:\n\n:   -   Does it have all the necessary parameters?\n    -   Is it passing the expected values as arguments?\n</code></pre> <p>-</p> <pre><code>If the component is custom HTML:\n\n:   -   Is the HTML structure correct?\n    -   Are Protocol-specific class names spelled correctly?\n</code></pre> <ul> <li> <p>Is the component     CSS     available?</p> </li> <li> <p>Is the component JS available?</p> </li> </ul> <p>Note</p> <p>Component CSS and JS are defined in a <code>CONTENT_TYPE_MAP</code> from the Bedrock API (<code>api.py</code>).</p>"},{"location":"contentful/#bedrock-database","title":"Bedrock Database","text":"<p>Once content is synced into your local database, it can be found in the contentful_contentfulentry table. All the dependencies to explore the data are installed by default for local development.</p> <p>Using sqlite (with an example query to get some info about en-US pages):</p> <pre><code>./manage.py dbshell\n</code></pre> <pre><code>select id, slug, data from contentful_contentfulentry where locale='en-US';\n</code></pre> <p>Close the sqlite shell with <code>.exit</code></p> <p>Using Django shell (with an example query to get data from first entry of \"pageProductJournalismStory\" type):</p> <pre><code>./manage.py shell\n</code></pre> <pre><code>from bedrock.contentful.models import ContentfulEntry\n\nproduct_stories = ContentfulEntry.objects.filter(content_type=\"pageProductJournalismStory\", localisation_complete=True, locale=\"en-US\")\n\nproduct_stories[0].data  # to see the data stored for the first story in the results\n</code></pre> <p>Close the Djanjo shell with <code>exit()</code> or <code>CTRL+D</code></p>"},{"location":"contentful/#useful-contentful-docs","title":"Useful Contentful Docs","text":"<p>https://www.contentful.com/developers/docs/references/images-api/#/reference/resizing-&amp;-cropping/specify-focus-area</p> <p>https://www.contentful.com/developers/docs/references/content-delivery-api/</p> <p>https://contentful.github.io/contentful.py/#filtering-options</p> <p>https://github.com/contentful/rich-text-renderer.py https://github.com/contentful/rich-text-renderer.py/blob/a1274a11e65f3f728c278de5d2bac89213b7470e/rich_text_renderer/block_renderers.py</p>"},{"location":"contentful/#assumptions-we-still-need-to-deal-with","title":"Assumptions we still need to deal with","text":"<ul> <li>image sizes</li> </ul>"},{"location":"contentful/#legacy","title":"Legacy","text":"<p>Since we decided to move forward the the Compose App, we no longer need the Connect content model. The EN-US homepage is currently still using Connect. Documentation is here for reference.</p> <ul> <li>\ud83d\udd17 this component is referenced by ID in bedrock (at the moment that     is just the homepage but could be used to connect single components     for display on non-contentful pages. For example: the latest feature     box on /new)</li> </ul>"},{"location":"contentful/#connect","title":"\ud83d\udd17 Connect","text":"<p>These are the highest level component. They should be just a name and entry reference.</p> <p>The purpose of the connect is to create a stable ID that can be referenced in bedrock to be included in a jinja template. Right now we only do this for the homepage. This is because the homepage has some conditional content above and below the Contentful content.</p> <p>Using a connect component to create the link between jinja template and the Contentful Page entry means an entire new page can be created and proofed in Contentful before the bedrock homepage begins pulling that content in.</p> <p>In other contexts a connect content model could be created to link to entries where the ID may change. For example: the \"Latest Firefox Features: section of /new could be moved to Contentful using a connect component which references 3 picto blocks.</p> <p>Because the ID must be added to a bedrock by a dev, only devs should be able to make new connect entries.</p>"},{"location":"contribute/","title":"How to contribute","text":"<p>Before diving into code it might be worth reading through the Developing on Bedrock documentation, which contains useful information and links to our coding guidelines for Python, Django, JavaScript and CSS.</p>"},{"location":"contribute/#git-workflow","title":"Git workflow","text":"<p>When you want to start contributing, you should create a branch from main. This allows you to work on different project at the same time:</p> <pre><code>$ git switch main\n</code></pre> <pre><code>$ git switch -c topic-branch\n</code></pre> <p>To keep your branch up-to-date, assuming the mozilla repository is the remote called mozilla:</p> <pre><code>$ git switch main\n</code></pre> <pre><code>$ git pull --ff-only\n</code></pre> <p>More on Why you should use --ff-only. To make this the default update your Git config as described in the article.</p> <pre><code>$ git switch topic-branch\n</code></pre> <pre><code>$ git rebase main\n</code></pre> <p>If you need more Git expertise, a good resource is the Git book.</p> <p>Once you're done with your changes, you'll need to describe those changes in the commit message.</p>"},{"location":"contribute/#git-commit-messages","title":"Git commit messages","text":"<p>Commit messages are important when you need to understand why something was done.</p> <ul> <li>First, learn how to write good git commit     messages.</li> <li>All commit messages must include a bug number. You can put the bug     number on any line, not only the first one.</li> <li>If you use the syntax <code>bug xxx</code>, Github will reference the commit     into Bugzilla. With <code>fix bug xxx</code>, it will even close the bug once     it goes into main.</li> </ul> <p>If you're asked to change your commit message, you can use these commands:</p> <pre><code>$ git commit --amend\n</code></pre> <p>-f is doing a force push because you modified the history</p> <pre><code>$ git push -f my-remote topic-branch\n</code></pre>"},{"location":"contribute/#submitting-your-work","title":"Submitting your work","text":"<p>In general, you should submit your work with a pull request to main. If you are working with other people or you want to put your work on a demo server, then you should be working on a common topic branch.</p> <p>Once your code has been positively reviewed, it will be deployed shortly after. So if you want feedback on your code but it's not ready to be deployed, you should note it in the pull request, or use a Draft PR. Also make use of an appropriate label, such as <code>Do Not Merge</code>.</p>"},{"location":"contribute/#squashing-your-commits","title":"Squashing your commits","text":"<p>Should your pull request contain more than one commit, sometimes we may ask you to squash them into a single commit before merging. You can do this with [git rebase]{.title-ref}.</p> <p>As an example, let's say your pull request contains two commits. To squash them into a single commit, you can follow these instructions:</p> <pre><code>$ git rebase -i HEAD~2\n</code></pre> <p>You will then get an editor with your two commits listed. Change the second commit from [pick]{.title-ref} to [fixup]{.title-ref}, then save and close. You should then be able to verify that you only have one commit now with [git log]{.title-ref}.</p> <p>To push to GitHub again, because you \"altered the history\" of the repo by merging the two commits into one, you'll have to [git push -f]{.title-ref} instead of just [git push]{.title-ref}.</p>"},{"location":"contribute/#deploying-your-code","title":"Deploying your code","text":"<p>These are the websites that Bedrock is usually deployed to as part of development.</p>"},{"location":"contribute/#demo-sites","title":"Demo sites","text":"<p>Bedrock as a platform can run in two modes: Mozorg Mode (for content that will appear on mozilla.org) and Pocket Mode (for content that will end up on getpocket.com).</p> <p>To support this, we have two separate sets of URLs we use for demos. To get code up to one of those URLs, push it to the specified branch on <code>github.com/mozilla/bedrock</code>:</p> <ul> <li>Mozorg:<ul> <li>Branch <code>mozorg-demo-1</code> -&gt; https://www-demo1.allizom.org/</li> <li>Branch <code>mozorg-demo-2</code> -&gt; https://www-demo2.allizom.org/</li> <li>Branch <code>mozorg-demo-3</code> -&gt; https://www-demo3.allizom.org/</li> <li>Branch <code>mozorg-demo-4</code> -&gt; https://www-demo4.allizom.org/</li> <li>Branch <code>mozorg-demo-5</code> -&gt; https://www-demo5.allizom.org/</li> <li>Branch <code>mozorg-demo-6</code> -&gt; https://www-demo6.allizom.org/</li> <li>Branch <code>mozorg-demo-7</code> -&gt; https://www-demo7.allizom.org/</li> <li>Branch <code>mozorg-demo-8</code> -&gt; https://www-demo8.allizom.org/</li> <li>Branch <code>mozorg-demo-9</code> -&gt; https://www-demo9.allizom.org/</li> </ul> </li> <li>Pocket:<ul> <li>Branch <code>pocket-demo-1</code> -&gt; https://www-demo1.tekcopteg.com/</li> <li>Branch <code>pocket-demo-2</code> -&gt; https://www-demo2.tekcopteg.com/</li> <li>Branch <code>pocket-demo-3</code> -&gt; https://www-demo3.tekcopteg.com/</li> <li>Branch <code>pocket-demo-4</code> -&gt; https://www-demo4.tekcopteg.com/</li> <li>Branch <code>pocket-demo-5</code> -&gt; https://www-demo5.tekcopteg.com/</li> </ul> </li> </ul> <p>For example, for Mozorg:</p> <pre><code>$ git push -f mozilla my-demo-branch:mozorg-demo-2\n</code></pre> <p>Or for Pocket:</p> <pre><code>$ git push -f mozilla my-demo-branch:pocket-demo-1\n</code></pre> <p>Deployment notification and logs</p> <p>At the moment, there is no way to view logs for the deployment unless you have access to Google Cloud Platform.</p> <p>If you do have access, the Cloud Build dashboard shows the latest builds, and Cloud Run will link off to the relevant logs.</p> <p>There are Mozilla Slack notifications in <code>#www-notify</code> that show the status of demo builds. (Work is ticketed to make those notifications richer in data.)</p> <p>Env vars</p> <p>Rather than tweak env vars via a web UI, they are set in config files. Both Mozorg and Pocket mode have specific demo-use-only env var files, which are only used by our GCP demo setup. They are:</p> <ul> <li><code>bedrock/gcp/bedrock-demos/cloudrun/mozorg-demo.env.yaml</code></li> <li><code>bedrock/gcp/bedrock-demos/cloudrun/pocket-demo.env.yaml</code></li> </ul> <p>If you need to set/add/remove an env var, you can edit the relevant file on your feature branch, commit it and push it along with the rest of the code, as above. There is a small risk of clashes, but these can be best avoided if you keep up to date with <code>bedrock/main</code> and can be resolved easily.</p> <p>Secret values</p> <p>Remember that the env vars files are public because they are in the Bedrock codebase, so sensitive values should not be added there, even temporarily.</p> <p>If you need to add a secret value, this currently needs to be added at the GCP level by someone with appropriate permissions to edit and apply the Terraform configuration, and to edit the trigger YAML spec to pass through the new secret. Currently Web-SRE and the backend team have appropriate GCP access and adding a secret is relatively quick. (We can make this easier in the future if there's sufficient need, of course.)</p> <p>Always-on vs auto-sleep demo servers</p> <p>The demo servers are on GCP Cloud Run, and by default they will be turned off if there is no traffic for 15 minutes. After this time, the demo app will be woken up if it receives a request.</p> <p>Normally, a 'cold start' will not be a problem. However, if the branch you are demoing does things that alter the database (i.e contains migrations), then you may find the restarted demo app crashes because the new migrations have not been applied after a cold start.</p> <p>The best current way to avoid that happening is:</p> <ul> <li> <p>In your branch's demo-env-vars YAML file, set     <code>LOCAL_DB_UPDATE=True</code> so that the Dev DB is not pulled down to the     demo app</p> </li> <li> <p>Ask one of the backend team to set the Demo app to always be awake     by setting 'Minimum instances' to 1 for the relevant Cloud Run     service and restarting it. The app will always be on and will not     sleep, so won't need a cold start. Once you have completed the     feature work, please ask the backenders to restore the default     sleepy behaviour. As an example with <code>mozorg-demo-1</code>:</p> <ul> <li>To make it always-on:     <code>gcloud run services update mozorg-demo-1 --min-instances 1</code></li> <li>To revert it to auto-sleeping:     <code>gcloud run services update mozorg-demo-1 --min-instances 0</code></li> </ul> </li> </ul> <p>(We'll try to make this a self-serve thing as soon as we can).</p>"},{"location":"contribute/#deprecated-heroku-demo-servers","title":"DEPRECATED: Heroku Demo Servers","text":"<p>Demos are now powered by Google Cloud Platform (GCP), and no longer by Heroku.</p> <p>However, the Github Action we used to push code to Heroku may still be enabled. Pushing a branch to one of the [demo/*]{.title-ref} branches of the [mozilla/bedrock]{.title-ref} repo will trigger this. However, note that URLs that historically used to point to Heroku will be pointed to the new GCP demos services instead, so you will have to look at Heroku's web UI to see what the URL of the relevant Heroku app is.</p> <p>To push to launch a demo on Heroku:</p> <pre><code>$ git push -f mozilla my-demo-branch:demo/1\n</code></pre>"},{"location":"contribute/#pushing-to-production","title":"Pushing to production","text":"<p>We're doing pushes as soon as new work is ready to go out.</p> <p>Code flows automatically to Dev, amd manually to Stage and to Production. See pipeline docs for details.</p> <p>After doing a push, those who are responsible for implementing changes need to update the bugs that have been pushed with a quick message stating that the code was deployed.</p> <p>If you'd like to see the commits that will be deployed before the push run the following command:</p> <pre><code>$ ./bin/open-compare.py\n</code></pre> <p>This will discover the currently deployed git hash, and open a compare URL at github to the latest main. Look at <code>open-compare.py -h</code> for more options.</p> <p>We automate pushing to production via tagged commits (see pipeline)</p>"},{"location":"download-buttons/","title":"Firefox Download Buttons","text":"<p>There are two Firefox download button helpers in bedrock to choose from. The first is a lightweight button that links directly to the <code>/firefox/download/thanks/</code> page. Its sole purpose is to facilitate downloading the main release version of Firefox.</p> <pre><code>{{ download_firefox_thanks() }}\n</code></pre> <p>The second type of button is more heavy weight, and can be configured to download any build of Firefox (e.g. Release, Beta, Developer Edition, Nightly). It can also offer functionality such as direct (in-page) download links, so it comes with a lot more complexity and in-page markup.</p> <pre><code>{{ download_firefox() }}\n</code></pre>"},{"location":"download-buttons/#which-button-should-i-use","title":"Which button should I use?","text":"<p>A good rule of thumb is to always use <code>download_firefox_thanks()</code> for regular landing pages (such as <code>/firefox/new/</code>) where the main release version of Firefox is the product being offered. For pages pages that require direct download links, or promote pre-release products (such as <code>/firefox/channel/</code>) then <code>download_firefox()</code> should be used instead.</p>"},{"location":"download-buttons/#documentation","title":"Documentation","text":"<p>See helpers.py for documentation and supported parameters for both buttons.</p>"},{"location":"download-buttons/#external-referrers","title":"External referrers","text":"<p>Generally we encourage other websites in the Mozilla ecosystem to link to the /firefox/new/ page when prompting visitors to download Firefox, since it provides a consistent user experience and also benefits SEO. In some circumstances however sites may want to provide a download button that initiates a file download automatically when clicked. For cases like this, sites can link to the following URL:</p> <pre><code>https://www.mozilla.org/firefox/download/thanks/?s=direct\n</code></pre> <p>Important</p> <p>Including the <code>s=direct</code> query parameter here will ensure that Windows download attribution is collected and recorded correctly in Telemetry. Also, make sure to not include the locale in the URL, so that bedrock can serve the most suitable language based on the visitor's browser preference.</p> <p>Note</p> <p>This download URL will not automatically trigger a download in older Internet Explorer browsers. If that's important to your visitors, then you can use a conditional comment to provide a different link.</p> <pre><code>&lt;!--[if !IE]&gt;&lt;!--&gt;\n    &lt;a href=\"https://www.mozilla.org/firefox/download/thanks/?s=direct\"&gt;Download Firefox&lt;/a&gt;\n&lt;!--&lt;![endif]--&gt;\n\n&lt;!--[if IE]&gt;\n    &lt;a href=\"https://www.mozilla.org/firefox/new/\"&gt;Download Firefox&lt;/a&gt;\n&lt;![endif]--&gt;\n</code></pre>"},{"location":"funnelcake/","title":"Funnel cakes and Partner Builds","text":""},{"location":"funnelcake/#funnel-cakes","title":"Funnel cakes","text":"<p>In addition to being an American delicacy funnel cakes are what we call special builds of Firefox. They can come with extensions preinstalled and/or a custom first-run experience.</p> <p>\"The whole funnelcake system is so marred by history at this point I don't know if anyone fully understands what it's supposed to do in all situations\" - pmac</p> <p>Funnelcakes are configured by the Release Engineering team. You can see the configs in the funnelcake git repo</p> <p>Currently bedrock only supports funnelcakes for \"stub installer platforms\". Which means they are windows only. However, funnelcakes can be made for all platforms so bedrock support may expand.</p> <p>We signal to bedrock that we want a funnelcake when linking to the download page by appending the query variable [f]{.title-ref} with a value equal to the funnelcake number being requested.</p> <pre><code>https://www.mozilla.org/en-US/firefox/download/thanks/?f=137\n</code></pre> <p>Bedrock checks to see if the funnelcake is configured (this is handled in the www-config repo)</p> <pre><code>FUNNELCAKE_135_LOCALES=en-US\nFUNNELCAKE_135_PLATFORMS=win,win64\n</code></pre> <p>Bedrock then converts that into a request to download a file like so:</p> <p>Windows:</p> <pre><code>https://download.mozilla.org/?product=firefox-stub-f137&amp;os=win&amp;lang=en-US\n</code></pre> <p>Mac (You can see the mac one does not pass the funnelcake number along.):</p> <pre><code>https://download.mozilla.org/?product=firefox-latest-ssl&amp;os=osx&amp;lang=en-US\n</code></pre> <p>Someone in Release Engineering needs to set up the redirects on their side to take the request from here.</p>"},{"location":"funnelcake/#places-things-can-go-wrong","title":"Places things can go wrong","text":"<p>As with many technical things, the biggest potential problems are with people:</p> <ul> <li>Does it have executive approval?</li> <li>Did legal sign off?</li> <li>Has it had a security review?</li> </ul> <p>On the technical side:</p> <ul> <li>Is the switch enabled?</li> <li>Is the variable being passed?</li> </ul>"},{"location":"funnelcake/#partner-builds","title":"Partner builds","text":"<p>Bedrock does not have an automated way of handling these, so you'll have to craft your own download button:</p> <pre><code>&lt;a href=\"https://download.mozilla.org/?product=firefox-election-edition&amp;os=win&amp;lang=en-US\"&gt;\nDownload&lt;/a&gt;\n</code></pre> <p>Bugs that might have useful info:</p> <ul> <li>https://bugzilla.mozilla.org/show_bug.cgi?id=1450463</li> <li>https://bugzilla.mozilla.org/show_bug.cgi?id=1495050</li> </ul> <p>PRs that might have useful code:</p> <ul> <li>https://github.com/mozilla/bedrock/pull/5555</li> </ul>"},{"location":"install/","title":"Installing Bedrock","text":""},{"location":"install/#installation-methods","title":"Installation Methods","text":"<p>There are two primary methods of installing bedrock: Docker and Local. Whichever you choose you'll start by getting the source</p> <pre><code>$ git clone https://github.com/mozilla/bedrock.git\n</code></pre> <pre><code>$ cd bedrock\n</code></pre> <p>After these basic steps you can choose your install method below. Docker is the easiest and recommended way, but local is also possible and may be preferred by people for various reasons.</p> <p>You should also install our git pre-commit hooks. Our setup uses the pre-commit framework. Install the framework using the instructions on their site depending on your platform, then run <code>pre-commit install</code>. After that it will check your Python, JS, and CSS files before you commit to save you time waiting for the tests to run in our CI before noticing a linting error.</p>"},{"location":"install/#docker-installation","title":"Docker Installation","text":"<p>Note</p> <p>This method assumes you have Docker installed for your platform. If not please do that now or skip to the <code>Local Installation</code> section.</p> <p>This is the simplest way to get started developing for bedrock. If you're on Linux or Mac (and possibly Windows 10 with the Linux subsystem) you can run a script that will pull our production and development docker images and start them:</p> <pre><code>$ make clean run\n</code></pre> <p>Note</p> <p>You can start the server any other time with:</p> <pre><code>$ make run\n</code></pre> <p>You should see a number of things happening, but when it's done it will output something saying that the server is running at localhost:8000. Go to that URL in a browser and you should see the mozilla.org home page. In this mode the site will refresh itself when you make changes to any template or media file. Simply open your editor of choice and modify things and you should see those changes reflected in your browser.</p> <p>Note</p> <p>It's a good idea to run <code>make pull</code> from time to time. This will pull down the latest Docker images from our repository ensuring that you have the latest dependencies installed among other things. If you see any strange errors after a <code>git pull</code> then <code>make pull</code> is a good thing to try for a quick fix.</p> <p>If you don't have or want to use Make you can call the docker and compose commands directly</p> <pre><code>$ docker-compose pull\n</code></pre> <pre><code>$ [[ ! -f .env ]] &amp;&amp; cp .env-dist .env\n</code></pre> <p>Then starting it all is simply</p> <pre><code>$ docker-compose up app assets\n</code></pre> <p>All of this is handled by the <code>Makefile</code> script and called by Make if you follow the above directions. You DO NOT need to do both.</p> <p>These directions pull and use the pre-built images that our deployment process has pushed to the Docker Hub. If you need to add or change any dependencies for Python or Node then you'll need to build new images for local testing. You can do this by updating the requirements files and/or package.json file then simply running:</p> <pre><code>$ make build\n</code></pre> <p>Note</p> <p>For Apple Silicon / M1 users</p> <p>If you find that when you're building you hit issues with Puppeteer not installing, these will help:</p> <ul> <li>Set up a Rosetta     Terminal.</li> <li>Follow these Puppeter installation     tips:.</li> </ul> <p>Asset bundles</p> <p>If you make a change to <code>media/static-bundles.json</code>, you'll need to restart Docker.</p> <p>Note</p> <p>Sometimes stopping Docker doesn't actually kill the images. To be safe, after stopping docker, run <code>docker ps</code> to ensure the containers were actually stopped. If they have not been stopped, you can force them by running <code>docker-compose kill</code> to stop all containers, or <code>docker kill &lt;container_name&gt;</code> to stop a single container, e.g. <code>docker kill bedrock_app_1</code>.</p>"},{"location":"install/#local-installation","title":"Local Installation","text":"<p>These instructions assume you have Python, pip, and NodeJS installed. If you don't have [pip]{.title-ref} installed (you probably do) you can install it with the instructions in the pip docs.</p> <p>Bedrock currently uses Python 3.9.10. The recommended way to install and use that version is with pyenv and to create a virtualenv using pyenv-virtualenv that will isolate Bedrock's dependencies from other things installed on the system.</p> <p>The following assumes you are on MacOS, using <code>zsh</code> as your shell and Homebrew as your package manager. If you are not, there are installation instructions for a variety of platforms and shells in the READMEs for the two pyenv projects.</p> <p>Install Python 3.9.10 with pyenv</p> <ol> <li>Install <code>pyenv</code> itself :<pre><code>$ brew install pyenv\n</code></pre> </li> </ol> <p>2. Configure your shell to init <code>pyenv</code> on start - this is noted in the project's own docs, in more detail, but omits that setting [PYENV_ROOT]{.title-ref} and adding it to the path is needed:</p> <pre><code>$ echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' &gt;&gt; ~/.zshrc\n$ echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' &gt;&gt; ~/.zshrc\n$ echo 'eval \"$(pyenv init -)\"' &gt;&gt; ~/.zshrc\n</code></pre> <p>3. Restart your login session for the changes to profile files to take effect - if you're not using <code>zsh</code>, the <code>pyenv</code> docs have other routes :</p> <pre><code>$ zsh -l\n</code></pre> <ol> <li> <p>Install the latest Python 3.9.x (eg 3.9.10), then test it's there:</p> <pre><code>$ pyenv install 3.9.10\n</code></pre> <p>If you'd like to make Python 3.9.10 your default globally, you can do so with:</p> <pre><code>$ pyenv global 3.9.10\n</code></pre> <p>If you only want to make Python 3.9.10 available in the current shell, while you set up the Python virtualenv (below), you can do so with:</p> <pre><code>$ pyenv shell 3.9.10\n</code></pre> </li> <li> <p>Verify that you have the correct version of Python installed:</p> <pre><code>$ python --version\nPython 3.9.10\n</code></pre> </li> </ol> <p>Info</p> <p>At the time of writing, Python 3.9.10 was the 3.9 release that worked with least complication across the core team's local-development platforms, incl both Intel and Apple Silicon Macs. It's also the version of 3.9 in the <code>slim-bullseye</code> image used for the Dockerized version.</p> <p>Install a plugin to manage virtualenvs via pyenv and create a virtualenv for Bedrock's dependencies</p> <ol> <li> <p>Install <code>pyenv-virtualenv</code> :</p> <pre><code>$ brew install pyenv-virtualenv\n</code></pre> </li> <li> <p>Configure your shell to init <code>pyenv-virtualenv</code> on start - again, this is noted in the <code>pyenv-virtualenv</code> project's own documentation, in more detail. The following will slot in a command that will work as long as you have pyenv-virtualenv installed:</p> <p>$ echo 'eval \"$(pyenv virtualenv-init -)\"' &gt;&gt; ~/.zshrc</p> </li> <li> <p>Restart your login session for the changes to profile files to take    effect :</p> <p>$ zsh -l</p> </li> <li> <p>Make a virtualenv we can use - in this example we'll call it     <code>bedrock</code> but use whatever you want :</p> <p>$ pyenv virtualenv 3.9.10 bedrock</p> </li> </ol> <p>Use the virtualenv</p> <ol> <li> <p>Switch to the virtualenv - this is the command you will use any time    you need this virtualenv :</p> <p>$ pyenv activate bedrock</p> </li> <li> <p>If you'd like to auto activate the virtualenv when you cd into the bedrock directory, and deactivate it when you exit the directory, you can do so with:</p> <p>$ echo 'bedrock' &gt; .python-version</p> </li> <li> <p>Securely upgrade pip :</p> <p>$ pip install --upgrade pip</p> </li> <li> <p>Install / update dependencies :</p> <p>$ make install-local-python-deps</p> </li> </ol> <p>Info</p> <p>If you are on OSX and some of the compiled dependencies fails to compile, try explicitly setting the arch flags and try again. The following are relevant to Intel Macs only. If you're on Apple Silicon, 3.9.10 should 'just work':</p> <pre><code>$ export ARCHFLAGS=\"-arch i386 -arch x86_64\"\n</code></pre> <pre><code>$ make install-local-python-deps\n</code></pre> <p>If you are on Linux, you may need at least the following packages or their equivalent for your distro:</p> <pre><code>python3-dev libxslt-dev\n</code></pre> <p>Sync the database and all of the external data locally. This gets product-details, security-advisories, credits, release notes, localizations, legal-docs etc:</p> <pre><code>$ bin/bootstrap.sh\n</code></pre> <p>Install the node dependencies to run the site. This will only work if you already have Node.js and npm installed:</p> <pre><code>$ npm install\n</code></pre> <p>Note</p> <p>Bedrock uses npm to ensure that Node.js packages that get installed are the exact ones we meant (similar to pip hash checking mode for python). Refer to the npm documentation for adding or upgrading Node.js dependencies.</p> <p>Note</p> <p>As a convenience, there is a <code>make preflight</code> command which automatically brings your installed Python and NPM dependencies up to date and also fetches the latest DB containing the latest site content. This is a good thing to run after pulling latest changes from the <code>main</code> branch.</p>"},{"location":"install/#run-the-tests","title":"Run the tests","text":"<p>Now that we have everything installed, let's make sure all of our tests pass. This will be important during development so that you can easily know when you've broken something with a change.</p>"},{"location":"install/#docker","title":"Docker","text":"<p>We manage our local docker environment with docker-compose and Make. All you need to do here is run:</p> <pre><code>$ make test\n</code></pre> <p>If you don't have Make you can simply run <code>docker-compose run test</code>.</p> <p>If you'd like to run only a subset of the tests or only one of the test commands you can accomplish that with a command like the following:</p> <pre><code>$ docker-compose run test py.test bedrock/firefox\n</code></pre> <p>This example will run only the unit tests for the <code>firefox</code> app in bedrock. You can substitute <code>py.test bedrock/firefox</code> with most any shell command you'd like and it will run in the Docker container and show you the output. You can also just run <code>bash</code> to get an interactive shell in the container which you can then use to run any commands you'd like and inspect the file system:</p> <pre><code>$ docker-compose run test bash\n</code></pre>"},{"location":"install/#local","title":"Local","text":"<p>From the local install instructions above you should still have your virtualenv activated, so running the tests is as simple as:</p> <pre><code>$ py.test lib bedrock\n</code></pre> <p>To test a single app, specify the app by name in the command above. e.g.:</p> <pre><code>$ py.test bedrock/firefox\n</code></pre>"},{"location":"install/#make-it-run","title":"Make it run","text":""},{"location":"install/#docker_1","title":"Docker","text":"<p>You can simply run the <code>make run</code> script mentioned above, or use docker-compose directly:</p> <pre><code>$ docker-compose up app assets\n</code></pre>"},{"location":"install/#local_1","title":"Local","text":"<p>To make the server run, make sure your virtualenv is activated, and then run the server:</p> <pre><code>$ npm start\n</code></pre> <p>If you are not inside a virtualenv, you can activate it by doing:</p> <pre><code>$ pyenv activate bedrock\n</code></pre>"},{"location":"install/#prod-mode","title":"Prod Mode","text":"<p>There are certain things about the site that behave differently when running locally in dev mode using Django's development server than they do when running in the way it runs in production. Static assets that work fine locally can be a problem in production if referenced improperly, and the normal error pages won't work unless <code>DEBUG=False</code> and doing that will make the site throw errors since the Django server doesn't have access to all of the built static assets. So we have a couple of extra Docker commands (via make) that you can use to run the site locally in a more prod-like way.</p> <p>First you should ensure that your <code>.env</code> file is setup the way you need. This usually means adding <code>DEBUG=False</code> and <code>DEV=False</code>, though you may want <code>DEV=True</code> if you want the site to act more like www-dev.allizom.org in that all feature switches are <code>On</code> and all locales are active for every page. After that you can run the following:</p> <pre><code>$ make run-prod\n</code></pre> <p>This will run the latest bedrock image using your local bedrock files and templates, but not your local static assets. If you need an updated image just run <code>make pull</code>.</p> <p>If you need to include the changes you've made to your local static files (images, css, js, etc.) then you have to build the image first:</p> <pre><code>$ make build-prod run-prod\n</code></pre>"},{"location":"install/#pocket-mode","title":"Pocket Mode","text":"<p>By default, Bedrock will serve the content of <code>www.mozilla.org</code>. However, it is also possible to make Bedrock serve the content pages for Pocket (<code>getpocket.com</code>). This is done, ultimately, by setting a <code>SITE_MODE</code> env var to the value of <code>Pocket</code>.</p> <p>For local development, setting this env var is already supported in the standard ways to run the site:</p> <ul> <li>Docker: <code>make run-pocket</code> and <code>make run-pocket prod</code></li> <li>Local run/Node/webpack and Django runserver:     <code>npm run in-pocket-mode</code></li> <li><code>SITE_MODE=Pocket ./manage.py runserver</code> for plain ol' Django     runserver, in Pocket mode</li> </ul> <p>For demos on servers, remember to set the SITE_MODE env var to be the value you need (<code>Pocket</code> or <code>Mozorg</code> -- or nothing, which is the same as setting <code>Mozorg</code>)</p>"},{"location":"install/#documentation","title":"Documentation","text":"<p>This is a great place for coders and non-coders alike to contribute! Please note most of the documentation is currently in reStructuredText but we also support Markdown files.</p> <p>If you see a typo or similarly small change, you can use the \"Edit in GitHub\" link to propose a fix through GitHub. Note: you will not see your change directly committed to the main branch. You will commit the change to a separate branch so it can be reviewed by a staff member before merging to main.</p> <p>If you want to make a bigger change or find a Documentation issue on the repo, it is best to edit and preview locally before submitting a pull request. You can do this with Docker or Local installations. Run the commands from your root folder. They will build documentation and start a live server to auto-update any changes you make to a documentation file.</p> <p>Docker:</p> <pre><code>$ make docs\n</code></pre> <p>Local:</p> <pre><code>$ pip install -r requirements/docs.txt\n</code></pre> <pre><code>$ make livedocs\n</code></pre>"},{"location":"install/#localization","title":"Localization","text":"<p>Localization (or L10n) files were fetched by the [bootstrap.sh]{.title-ref} command your ran earlier and are included in the docker images. If you need to update them or switch to a different repo or branch after changing settings you can run the following command:</p> <pre><code>$ ./manage.py l10n_update\n</code></pre> <p>You can read more details about how to localize content here.</p>"},{"location":"install/#feature-flipping-aka-switches","title":"Feature Flipping (aka Switches)","text":"<p>Environment variables are used to configure behavior and/or features of select pages on bedrock via a template helper function called <code>switch()</code>. It will take whatever name you pass to it (must be only numbers, letters, and dashes), convert it to uppercase, convert dashes to underscores, and lookup that name in the environment. For example: <code>switch('the-dude')</code> would look for the environment variable <code>SWITCH_THE_DUDE</code>. If the value of that variable is any of \"on\", \"true\", \"1\", or \"yes\", then it will be considered \"on\", otherwise it will be \"off\".</p> <p>You can also supply a list of locale codes that will be the only ones for which the switch is active. If the page is viewed in any other locale the switch will always return <code>False</code>, even in <code>DEV</code> mode. This list can also include a \"Locale Group\", which is all locales with a common prefix (e.g. \"en-US, en-GB\" or \"zh-CN, zh-TW\"). You specify these with just the prefix. So if you used <code>switch('the-dude', ['en', 'de'])</code> in a template, the switch would be active for German and any English locale the site supports.</p> <p>You may also use these switches in Python in <code>views.py</code> files (though not with locale support). For example:</p> <pre><code>from bedrock.base.waffle import switch\n\ndef home_view(request):\n    title = 'Staging Home' if switch('staging-site') else 'Prod Home'\n    ...\n</code></pre>"},{"location":"install/#testing","title":"Testing","text":"<p>If the environment variable <code>DEV</code> is set to a \"true\" value, then all switches will be considered \"on\" unless they are explicitly \"off\" in the environment. <code>DEV</code> defaults to \"true\" in local development and demo servers.</p> <p>To test switches locally:</p> <ol> <li>Set <code>DEV=False</code> in your <code>.env</code> file.</li> <li>Enable the switch in your <code>.env</code> file.</li> <li>Restart your web server.</li> </ol> <p>To configure switches/env vars for a demo branch. Follow the demo-site instructions here.</p>"},{"location":"install/#traffic-cop","title":"Traffic Cop","text":"<p>Currently, these switches are used to enable/disable Traffic Cop experiments on many pages of the site. We only add the Traffic Cop JavaScript snippet to a page when there is an active test. You can see the current state of these switches and other configuration values in our configuration repo.</p> <p>To work with/test these experiment switches locally, you must add the switches to your local environment. For example:</p> <pre><code># to switch on firstrun-copy-experiment you'd add the following to your ``.env`` file\nSWITCH_FIRSTRUN_COPY_EXPERIMENT=on\n</code></pre> <p>To do the equivalent in one of the bedrock apps see the www-config documentation.</p>"},{"location":"install/#notes","title":"Notes","text":"<p>A shortcut for activating virtual envs in zsh or bash is [. venv/bin/activate]{.title-ref}. The dot is the same as [source]{.title-ref}.</p> <p>There's a project called pew that provides a better interface for managing/activating virtual envs, so you can use that if you want. Also if you need help managing various versions of Python on your system, the pyenv project can help.</p>"},{"location":"l10n/","title":"Localization","text":"<p>The site is fully localizable. Localization files are not shipped with the code distribution, but are available in separate GitHub repositories. The proper repos can be cloned and kept up-to-date using the <code>l10n_update</code> management command:</p> <pre><code>$ ./manage.py l10n_update\n</code></pre> <p>If you don't already have a <code>data/www-l10n</code> directory, this command will clone the git repo containing the .ftl translation files (either the dev or prod files depending on your <code>DEV</code> setting). If the folder is already present, it will update the repository to the latest version.</p>"},{"location":"l10n/#fluent","title":"Fluent","text":"<p>Bedrock's Localization (l10n) system is based on Project Fluent. This is a departure from a standard Django project that relies on a gettext work flow of string extraction from template and code files, in that it relies on developers directly editing the default language (English in our case) Fluent files and using the string IDs created there in their templates and views.</p> <p>The default files for the Fluent system live in the <code>l10n</code> directory in the root of the bedrock project. This directory houses directories for each locale the developers directly implement (mostly simplified English \"en\", and \"en-US\"). The simplified English files are the default fallback for every string ID on the site and should be strings that are plain and easy to understand English, as free from colloquialisms as possible. The translators are able to easily understand the meaning of the string, and can then add their own local flair to the ideas.</p> <p>Note</p> <p>Much of this documentation also applies to the use of Fluent with Pocket templates, with the main differences being that:</p> <ul> <li>the English Pocket Fluent directory is called <code>l10n-pocket/</code></li> <li>there are no activation-threshold checks for Pocket templates - we     expect all strings to be translated in one go, because they are done     via a vendor</li> </ul>"},{"location":"l10n/#ftl-files","title":".ftl files","text":"<p>When adding translatable strings to the site you start by putting them all into an .ftl file in the <code>l10n/en/</code> directory with a path that matches or is somehow meaningful for the expected location of the template or view in which they'll be used. For example, strings for the <code>mozorg/mission.html</code> template would go into the <code>l10n/en/mozorg/mission.ftl</code> file. Locales are activated for a particular .ftl file, not template or URL, so you should use a unique file for most URLs, unless they're meant to be translated and activated for new locales simultaneously.</p> <p>You can have shared .ftl files that you can load into any template render, but only the first .ftl file in the list of the ones for a page render will determine whether the page is active for a locale.</p> <p>Activation of a locale happens automatically once certain rules are met. A developer can mark some string IDs as being \"Required\", which means that the file won't be activated for a locale until that locale has translated all of those required strings. The other rule is a percentage completion rule: a certain percentage (configurable) of the strings IDs in the \"en\" file must be translated in the file for a locale before it will be marked as active. We'll get into how exactly this works later.</p>"},{"location":"l10n/#translating-with-ftl-files","title":"Translating with .ftl files","text":"<p>The Fluent file syntax is well documented on the Fluent Project's site. We use \"double hash\" or \"group\" comments to indicate strings required for activation. A group comment only ends when another group comment starts however, so you should either group your required strings at the bottom of a file, or also have a \"not required\" group comment. Here's an example:</p> <pre><code>### File for example.html\n\n## Required\nexample-page-title = The Page Title\n# this is a note the applies only to example-page-desc\nexample-page-desc = This page is a test.\n\n##\nexample-footer = This string isn't as important\n</code></pre> <p>Any group comment (a comment that starts with \"##\") that starts with \"Required\" (case does not matter) will start a required strings block, and any other group comment will end it.</p> <p>Once you have your strings in your .ftl file you can place them in your template. We'll use the above .ftl file for a simple Jinja template example:</p> <pre><code>&lt;!doctype html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;{{ ftl('example-page-title') }}&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;{{ ftl('example-page-title') }}&lt;/h1&gt;\n    &lt;p&gt;{{ ftl('example-page-desc') }}&lt;/p&gt;\n    &lt;footer&gt;\n        &lt;p&gt;{{ ftl('example-footer') }}&lt;/p&gt;\n    &lt;/footer&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"l10n/#ftl-string-ids","title":"FTL String IDs","text":"<p>Our convention for string ID creation is the following:</p> <ol> <li>String IDs should be all lower-case alphanumeric characters.</li> <li>Words should be separated with hyphens.</li> <li>IDs should be prefixed with the name of the template file (e.g.     <code>firefox-new-skyline</code> for <code>firefox-new-skyline.html</code>)</li> <li>If you need to create a new string for the same place on a page and     to transition to it as it is translated, you can add a version     suffix to the string ID: e.g.     <code>firefox-new-skyline-main-page-title-v2</code>.</li> <li>The ID should be as descriptive as possible to make sense to the     developer, but could be anything as long as it adheres to the rules     above.</li> </ol>"},{"location":"l10n/#using-brand-names","title":"Using brand names","text":"<p>Common Mozilla brand names are stored in a global brands.ftl file, in the form of terms. Terms are useful for keeping brand names separated from the rest of the translations, so that they can be managed in a consistent way across all translated files, and also updated easily in a global context. In general the brand names in this file remain in English and should not be translated, however locales still have the choice and control to make adjustments should it suit their particular language.</p> <p>Only our own brands should be managed this way, brands from other companies should not. If you are concerned that the brand is a common word and may be translated, leave a comment for the translators.</p> <p>Note</p> <p>We are trying to phase out use of <code>{ -brand-name-firefox-browser }</code> please use <code>{ -brand-name-firefox } browser</code>.</p> <pre><code>-brand-name = Firefox\n\nexample-about = About { -brand-name }.\nexample-update-successful = { -brand-name } has been updated.\n# \"Safari\" here refers to the competing web browser\nexample-compare = How does { -brand-name } compare to Safari?\n</code></pre> <p>Important</p> <p>When adding a new term to <code>brands.ftl</code>, the new term should also be manually added to the mozilla-l10n/www-l10n repo for all locales. The reason for this is that if a term does not exist for a particular locale, then it does not fall back to English like a regular string does. Instead, the term variable name is displayed on the page.</p>"},{"location":"l10n/#variables","title":"Variables","text":"<p>Single hash comments are applied only to the string immediately following them. They should be used to provide additional context for the translators including:</p> <ol> <li>What the values of variables are.</li> <li>Context about where string appears on the page if it is not visible     or references other elements on the page.</li> <li>Explanations of English idioms and jargon that may be confusing to     non-native speakers.</li> </ol> <pre><code># Variables:\n#   $savings (string) - the percentage saved from the regular price, not including the % Examples: 50, 70\nexample-bundle-savings = Buy now for { $savings }% off.\n\n# Context: Used as an accessible text alternative for an image\nexample-bookmark-manager-alt = The bookmark manager window in { -brand-name-firefox }.\n# Context: This lists the various websites and magazines who have mentioned Firefox Relay.\n# Example: \"As seen in: FORBES magainze and LifeHacker\"\nexample-social-proof = As seen in:\n\nexample-privacy-on-every = Want privacy on every device?\n# \"You got it\" here is a casual answer to the previous question, \"Want privacy on every device?\"\nexample-you-got-it = You got it. Get { -brand-name-firefox } for mobile.\n</code></pre>"},{"location":"l10n/#html-with-attributes","title":"HTML with attributes","text":"<p>When passing HTML tags with attributes into strings for translation, remove as much room for error as possible by putting all the attributes and their values in a single variable. (This is most common with links and their href attributes but we do occasionally pass classes with other tags.)</p> <pre><code># Variables:\n#   $attrs (attrs) - link to https://www.mozilla.org/about/\nexample-created = { -brand-name-firefox } was created by &lt;a {$attrs}&gt;{ -brand-name-mozilla }&lt;/a&gt;.\n\n# Variables:\n#   $class (string) - CSS class used to replace brand name with wordmark logo\nexample-firefox-relay = Add &lt;span { $class }\"&gt;{ -brand-name-firefox-relay }&lt;/span&gt;\n</code></pre> <pre><code>{% set created_attrs = 'href=\"%s\" data-cta-type=\"link\" data-cta-text=\"created by Mozilla\"'|safe|format(url('mozorg.about.index')) %}\n&lt;p&gt;{{ ftl('example-created', attrs=created_attrs) }}&lt;/p&gt;\n\n{{ ftl('example-firefox-relay', class_name='class=\"mzp-c-wordmark mzp-t-wordmark-md mzp-t-product-relay\"') }}\n</code></pre>"},{"location":"l10n/#obsolete-strings","title":"Obsolete strings","text":"<p>When new strings are added to a page sometimes they update or replace old strings. Obsolete strings &amp; IDs should be removed from ftl files immediately if they are not being used as a fallback. If they are being kept as a fallback they should be removed after 1-2 months.</p>"},{"location":"l10n/#fallback","title":"Fallback","text":"<p>If you need to create a new string for the same place on a page and would like to keep the old one as a fallback, you can add a version suffix to the new string ID: e.g. <code>firefox-new-skyline-main-page-title-v2</code>.</p> <pre><code>example-block-title-v2 = Security, reliability and speed \u2014 on every device, anywhere you go.\n# Obsolete string\nexample-block-title = Security, reliability and speed \u2014 from name you can trust.\n</code></pre> <p>The <code>ftl</code> helper function has the ability to accept a fallback string ID and is described in the next section.</p>"},{"location":"l10n/#remove","title":"Remove","text":"<p>If the new string is fundamentally different a new string ID should be created and the old one deleted.</p> <p>For example, if the page is going from talking about the Google Translate extension to promoting our own Firefox Translate feature the old strings are not appropriate fall backs.</p> <p>The old strings and IDs should be deleted:</p> <pre><code>example-translate-title = The To Google Translate extension makes translating the page you\u2019re on easier than ever.\nexample-translate-content = Google Translate, with over 100 languages* at the ready, is used by millions of people around the world.\n</code></pre> <p>The new strings should have different IDs and not be versioned:</p> <pre><code>example-translate-integrated-title = { -brand-name-firefox } now comes with an integrated translation tool.\nexample-translate-integrated-content =  Unlike some cloud-based alternatives, { -brand-name-firefox } translates text locally, so the content you\u2019re translating doesn\u2019t leave your machine.\n</code></pre> <p>The <code>ftl_has_messages</code> jinja helper would be useful here and is described in the next section.</p>"},{"location":"l10n/#the-ftl-helper-function","title":"The <code>ftl</code> helper function","text":"<p>The <code>ftl()</code> function takes a string ID and returns the string in the current language, or simplified english if the string isn't translated. If you'd like to use a different string ID in the case that the primary one isn't translated you can specify that like this:</p> <pre><code>ftl('primary-string-id', fallback='fallback-string-id')\n</code></pre> <p>When a fallback is specified it will be used only if the primary isn't translated in the current locale. English locales (e.g. en-US, en-GB) will never use the fallback and will print the simplified english version of the primary string if not overridden in the more specific locale.</p> <p>You can also pass in replacement variables into the <code>ftl()</code> function for use with fluent variables. If you had a variable in your fluent file like this:</p> <pre><code>welcome = Welcome, { $user }!\n</code></pre> <p>You could use that in a template like this:</p> <pre><code>&lt;h2&gt;{{ ftl('welcome', user='Dude') }}&lt;h2&gt;\n</code></pre> <p>For our purposes these are mostly useful for things that can change, but which shouldn't involve retranslation of a string (e.g. URLs or email addresses).</p> <p>You may also request any other translation of the string (or the original English string of course) regardless of the current locale.</p> <pre><code>&lt;h2&gt;{{ ftl('welcome', locale='en', user='Dude') }}&lt;h2&gt;\n</code></pre> <p>This helper is available in Jinja templates and Python code in views. For use in a view you should always call it in the view itself:</p> <pre><code># views.py\nfrom lib.l10n_utils import render\nfrom lib.l10n_utils.fluent import ftl\n\ndef about_view(request):\n    ftl_files = 'mozorg/about'\n    hello_string = ftl('about-hello', ftl_files=ftl_files)\n    render(request, 'about.html', {'hello': hello_string}, ftl_files=ftl_files)\n</code></pre> <p>If you need to use this string in a view, but define it outside of the view itself, you can use the <code>ftl_lazy</code> variant which will delay evaluation until render time. This is mostly useful for defining messages shared among several views in constants in a <code>views.py</code> or <code>models.py</code> file.</p> <p>Whether you use this function in a Python view or a Jinja template it will always use the default list of Fluent files defined in the <code>FLUENT_DEFAULT_FILES</code> setting. If you don't specify any additional Fluent files via the <code>fluent_files</code> keyword argument, then only those default files will be used.</p>"},{"location":"l10n/#the-ftl_has_messages-helper-function","title":"The <code>ftl_has_messages</code> helper function","text":"<p>Another useful template tool is the <code>ftl_has_messages()</code> function. You pass it any number of string IDs and it will return <code>True</code> only if all of those message IDs exist in the current translation. This is useful when you want to add a new block of HTML to a page that is already translated, but don't want it to appear untranslated on any page.</p> <pre><code>{% if ftl_has_messages('new-title', 'new-description') %}\n  &lt;h3&gt;{{ ftl('new-title') }}&lt;/h3&gt;\n  &lt;p&gt;{{ ftl('new-description') }}&lt;/p&gt;\n{% else %}\n  &lt;h3&gt;{{ ftl('title') }}&lt;/h3&gt;\n  &lt;p&gt;{{ ftl('description') }}&lt;/p&gt;\n{% endif %}\n</code></pre> <p>If you'd like to have it return true when any of the given message IDs exist in the translation instead of requiring all of them, you can pass the optional <code>require_all=False</code> parameter and it will do just that.</p> <p>There is a version of this function for use in views called <code>has_messages</code>. It works exactly the same way but is meant to be used in the view Python code.</p> <pre><code># views.py\nfrom lib.l10n_utils import render\nfrom lib.l10n_utils.fluent import ftl, has_messages\n\ndef about_view(request):\n    ftl_files = 'mozorg/about'\n    if has_messages('about-hello-v2', 'about-title-v2',\n                    ftl_files=ftl_files):\n        hello_string = ftl('about-hello-v2', ftl_files=ftl_files)\n        title_string = ftl('about-title-v2', ftl_files=ftl_files)\n    else:\n        hello_string = ftl('about-hello', ftl_files=ftl_files)\n        title_string = ftl('about-title', ftl_files=ftl_files)\n\n    render(request, 'about.html', {'hello': hello_string, 'title': title_string}, ftl_files=ftl_files)\n</code></pre>"},{"location":"l10n/#specifying-fluent-files-specifying_fluent_files","title":"Specifying Fluent files {#specifying_fluent_files}","text":"<p>You have to tell the system which Fluent files to use for a particular template or view. This is done in either the <code>page()</code> helper in a <code>urls.py</code> file, or in the call to <code>l10n_utils.render()</code> in a view.</p>"},{"location":"l10n/#using-the-page-function","title":"Using the <code>page()</code> function","text":"<p>If you just need to render a template, which is quite common for bedrock, you will probably just add a line like the following to your <code>urls.py</code> file:</p> <pre><code>urlpatterns = [\n    page('about', 'about.html'),\n    page('about/contact', 'about/contact.html'),\n]\n</code></pre> <p>To tell this page to use the Fluent framework for l10n you just need to tell it which file(s) to use:</p> <pre><code>urlpatterns = [\n    page('about', 'about.html', ftl_files='mozorg/about'),\n    page('about/contact', 'about/contact.html', ftl_files=['mozorg/about/contact', 'mozorg/about']),\n]\n</code></pre> <p>The system uses the first (or only) file in the list to determine which locales are active for that URL. You can pass a string or list of strings to the <code>ftl_files</code> argument. The files you specify can include the <code>.ftl</code> extension or not, and they will be combined with the list of default files which contain strings for global elements like navigation and footer. There will also be files for reusable widgets like the newsletter form, but those should always come last in the list.</p>"},{"location":"l10n/#using-the-class-based-view","title":"Using the class-based view","text":"<p>Bedrock includes a generic class-based view (CBV) that sets up l10n for you. If you need to do anything fancier than just render the page, then you can use this:</p> <pre><code>from lib.l10n_utils import L10nTemplateView\n\nclass AboutView(L10nTemplateView):\n    template_name = 'about.html'\n    ftl_files = 'mozorg/about'\n</code></pre> <p>Using that CBV will do the right things for l10n, and then you can override other useful methods (e.g. <code>get_context_data</code>) to do what you need. Also, if you do need to do anything fancy with the context, and you find that you need to dynamically set the fluent files list, you can easily do so by setting <code>ftl_files</code> in the context instead of the class attribute.</p> <pre><code>from lib.l10n_utils import L10nTemplateView\n\nclass AboutView(L10nTemplateView):\n    template_name = 'about.html'\n\n    def get_context_data(self, **kwargs):\n        ctx = super().get_context_data(**kwargs)\n        ftl_files = ['mozorg/about']\n        if request.GET.get('fancy'):\n            ftl_files.append('fancy')\n\n        ctx['ftl_files'] = ftl_files\n        return ctx\n</code></pre> <p>A common case is needing to use FTL files when one template is used, but not with another. In this case you would have some logic to decide which template to use in the <code>get_template_names()</code> method. You can set the <code>ftl_files_map</code> class variable to a dict containing a map of template names to the list of FTL files for that template (or a single file name if that's all you need).</p> <pre><code># views.py\nfrom lib.l10n_utils import L10nTemplateView\n\n# class-based view example\nclass AboutView(L10nTemplateView):\n    ftl_files_map = {\n        'about_es.html': ['about_es']\n        'about_new.html': ['about']\n    }\n\n    def get_template_names(self):\n        if self.request.locale.startswith('en'):\n            template_name = 'about_new.html'\n        elif self.request.locale.startswith('es'):\n            template_name = 'about_es.html'\n        else:\n            # FTL system not used\n            template_name = 'about.html'\n\n        return [template_name]\n</code></pre> <p>If you need for your URL to use multiple Fluent files to determine the full list of active locales, for example when you are redesigning a page and have multiple templates in use for a single URL depending on locale, you can use the [activation_files]{.title-ref} parameter. This should be a list of FTL filenames that should all be used when determining the full list of translations for the URL. Bedrock will gather the full list for each file and combine them into a single list so that the footer language switcher works properly.</p> <p>Another common case is that you want to keep using an old template for locales that haven't yet translated the strings for a new one. In that case you can provide an <code>old_template_name</code> to the class and include both that template and <code>template_name</code> in the <code>ftl_files_map</code>. Once you do this the view will use the template in <code>template_name</code> only for requests for an active locale for the FTL files you provided in the map.</p> <pre><code>from lib.l10n_utils import L10nTemplateView\n\nclass AboutView(L10nTemplateView):\n    template_name = 'about_new.html'\n    old_template_name = \"about.html\"\n    ftl_files_map = {\n        \"about_new.html\": [\"about_new\", \"about_shared\"],\n        \"about.html\": [\"about\", \"about_shared\"],\n    }\n</code></pre> <p>In this example when the <code>about_new</code> FTL file is active for a locale, the <code>about_new.html</code> template will be rendered. Otherwise the <code>about.html</code> template would be used.</p>"},{"location":"l10n/#using-in-a-view-function","title":"Using in a view function","text":"<p>Lastly there's the good old function views. These should use <code>l10n_utils.render</code> directly to render the template with the context. You can use the <code>ftl_files</code> argument with this function as well.</p> <pre><code>from lib.l10n_utils import render\n\ndef about_view(request):\n    render(request, 'about.html', {'name': 'Duder'}, ftl_files='mozorg/about')\n</code></pre>"},{"location":"l10n/#fluent-file-configuration","title":"Fluent File Configuration","text":"<p>In order for a Fluent file to be extracted through automation and sent out for localization, it must first be configured to go through one or more distinct pipelines. This is controlled via a set of configuration files:</p> <ul> <li>Vendor,     locales translated by an agency, and paid for by Marketing (locales     covered by staff are also included in this group).</li> <li>Pontoon,     locales translated by Mozilla contributors.</li> <li>Special     templates,     for locales with dedicated templates that don't go through the     localization process (not currently used).</li> </ul> <p>Each configuration file consists of a pre-defined set of locales for which each group is responsible for translating. The locales defined in each file should not be changed without first consulting the with L10n team, and such changes should not be a regular occurrence.</p> <p>To establish a localization strategy for a Fluent file, it needs to be included as a path in one or more configuration files. For example:</p> <pre><code>[[paths]]\n    reference = \"en/mozorg/mission.ftl\"\n    l10n = \"{locale}/mozorg/mission.ftl\"\n</code></pre> <p>You can read more about configuration files in the L10n Project Configuration docs.</p> <p>Important</p> <p>Path definitions in Fluent configuration files are not source order dependent. A broad definition using a wild card can invalidate all previous path definitions for example. Paths should be defined carefully to avoid exposing .ftl files to unintended locales.</p> <p>Using a combination of vendor and pontoon configuration offers a flexible but specific set of options to choose from when it comes to defining an l10n strategy for a page. The available choices are:</p> <ol> <li>Staff locales.</li> <li>Staff + select vendor locales.</li> <li>Staff + all vendor locales.</li> <li>Staff + vendor + pontoon.</li> <li>All pontoon locales (for non-marketing content only).</li> </ol> <p>When choosing an option, it's important to consider that vendor locales have a cost associated with them, and pontoon leans on the goodwill of our volunteer community. Typically, only non-marketing content should go through Pontoon for all locales. Everything that is marketing related should feature one of the staff/vendor/pontoon configurations.</p>"},{"location":"l10n/#fluent-file-activation","title":"Fluent File Activation","text":"<p>Fluent files are activated automatically when processed from the l10n team's repo into our own based on a couple of rules.</p> <ol> <li>If a fluent file has a group of required strings, all of those     strings must be present in the translation in order for it to be     activated.</li> <li>A translation must contain a minimum percent of the string IDs from     the English file to be activated.</li> </ol> <p>If both of these conditions are met the locale is activated for that particular Fluent file. Any view using that file as its primary (first in the list) file will be available in that locale.</p>"},{"location":"l10n/#deactivation","title":"Deactivation","text":"<p>If the automated system activates a locale but we for some reason need to ensure that this page remains unavailable in that locale, we can add this locale to a list of deactivated locales in the metadata file for that FTL file. For example, say we needed to make sure that the [mozorg/mission.ftl]{.title-ref} file remained inactive for German, even though the translation is already done. We would add <code>de</code> to the <code>inactive_locales</code> list in the <code>metadata/mozorg/mission.json</code> file:</p> <pre><code>{\n\"active_locales\": [\n\"de\",\n\"fr\",\n\"en-GB\",\n\"en-US\",\n],\n\"inactive_locales\": [\n\"de\"\n],\n\"percent_required\": 85\n}\n</code></pre> <p>This would ensure that even though <code>de</code> appears in both lists, it will remain deactivated on the site. We could just remove it from the active list, but automation would keep attempting to add it back, so for now this is the best solution we have, and is an indication of the full list of locales that have satisfied the rules.</p>"},{"location":"l10n/#alternate-rules","title":"Alternate Rules","text":"<p>It's also possible to change the percentage of string completion required for activation on a per-file basis. In the same metadata file as above, if a <code>percent_required</code> key exists in the JSON data (see above) it will be used as the minimum percent of string completion required for that file in order to activate new locales.</p> <p>Note</p> <p>Once a locale is activated for a Fluent file it will NOT be automatically deactivated, even if the rules change. If you need to deactivate a locale you should follow the Deactivation instructions.</p>"},{"location":"l10n/#activation-status","title":"Activation Status","text":"<p>You can determine and use the activation status of a Fluent file in a view to make some decisions; what template to render for example. The way you would do that is with the <code>ftl_file_is_active</code> function. For example:</p> <pre><code># views.py\nfrom lib.l10n_utils import L10nTemplateView\nfrom lib.l10n_utils.fluent import ftl_file_is_active\n\n# class-based view example\nclass AboutView(L10nTemplateView):\n    ftl_files_map = {\n        'about.html': ['about']\n        'about_new.html': ['about_new', 'about']\n    }\n    def get_template_names(self):\n        if ftl_file_is_active('mozorg/about_new'):\n            template_name = 'about_new.html'\n        else:\n            template_name = 'about.html'\n\n        return [template_name]\n\n# function view example\ndef about_view(request):\n    if ftl_file_is_active('mozorg/about_new'):\n        template = 'mozorg/about_new.html'\n        ftl_files = ['mozorg/about_new', 'mozorg/about']\n    else:\n        template = 'about.html'\n        ftl_files = ['mozorg/about']\n\n    render(request, template, ftl_files=ftl_files)\n</code></pre>"},{"location":"l10n/#active-locales","title":"Active Locales","text":"<p>To see which locales are active for a particular .ftl file you can either look in the metadata file for that .ftl file, which is the one with the same path but in the <code>metadata</code> folder instead of a locale folder in the www-l10n repository. Or if you'd like something a bit nicer looking and more convenient there is the <code>active_locales</code> management command:</p> <pre><code>$ ./manage.py l10n_update\n</code></pre> <pre><code>$ ./manage.py active_locales mozorg/mission\n</code></pre> <pre><code>There are 91 active locales for mozorg/mission.ftl:\n- af\n- an\n- ar\n- ast\n- az\n- be\n- bg\n- bn\n...\n</code></pre> <p>You get an alphabetically sorted list of all of the active locales for that .ftl file. You should run <code>./manage.py l10n_update</code> as shown above for the most accurate and up-to-date results.</p>"},{"location":"l10n/#string-extraction","title":"String extraction","text":"<p>The string extraction process for both new .ftl content and updates to existing .ftl content is handled through automation. On each commit to <code>main</code> a command is run that looks for changes to the <code>l10n/</code> and <code>l10n-pocket/</code> directories. If a change is detected, it will copy those files into a new branch in mozilla-l10n/www-l10n and then a bot will open a pull request containing those changes. Once the pull request has been reviewed and merged by the L10n team, everything is done.</p> <p>To view the state of the latest automated attempt to open an L10N PR, see:</p> <ul> <li>Mozorg L10N PR     action</li> <li>Pocket L10N PR     action</li> </ul> <p>(We also just try to open L10N PRs every 3 hours, to catch any failed jobs that are triggered by a commit to <code>main</code>)</p>"},{"location":"l10n/#css","title":"CSS","text":"<p>If a localized page needs some locale-specific style tweaks, you can add the style rules to the page's stylesheet like this:</p> <pre><code>html[lang=\"it\"] #features li {\nfont-size: 20px;\n}\n\nhtml[dir=\"rtl\"] #features {\nfloat: right;\n}\n</code></pre> <p>If a locale needs site-wide style tweaks, font settings in particular, you can add the rules to <code>/media/css/l10n/{{LANG}}/intl.css</code>. Pages on Bedrock automatically includes the CSS in the base templates with the [l10n_css]{.title-ref} helper function. The CSS may also be loaded directly from other Mozilla sites with such a URL: <code>//mozorg.cdn.mozilla.net/media/css/l10n/{{LANG}}/intl.css</code>.</p> <p>Open Sans, the default font on mozilla.org, doesn't offer non-Latin glyphs. <code>intl.css</code> can have <code>@font-face</code> rules to define locale-specific fonts using custom font families as below:</p> <ul> <li>X-LocaleSpecific-Light: Used in combination with Open Sans     Light. The font can come in 2 weights: normal and optionally bold</li> <li>X-LocaleSpecific: Used in combination with Open Sans Regular.     The font can come in 2 weights: normal and optionally bold</li> <li>X-LocaleSpecific-Extrabold: Used in combination with Open Sans     Extrabold. The font weight is 800 only</li> </ul> <p>Here's an example of <code>intl.css</code>:</p> <pre><code>@font-face {\nfont-family: X-LocaleSpecific-Light;\nfont-weight: normal;\nfont-display: swap;\nsrc: local(mplus-2p-light), local(Meiryo);\n}\n\n@font-face {\nfont-family: X-LocaleSpecific-Light;\nfont-weight: bold;\nfont-display: swap;\nsrc: local(mplus-2p-medium), local(Meiryo-Bold);\n}\n\n@font-face {\nfont-family: X-LocaleSpecific;\nfont-weight: normal;\nfont-display: swap;\nsrc: local(mplus-2p-regular), local(Meiryo);\n}\n\n@font-face {\nfont-family: X-LocaleSpecific;\nfont-weight: bold;\nfont-display: swap;\nsrc: local(mplus-2p-bold), local(Meiryo-Bold);\n}\n\n@font-face {\nfont-family: X-LocaleSpecific-Extrabold;\nfont-weight: 800;\nfont-display: swap;\nsrc: local(mplus-2p-black), local(Meiryo-Bold);\n}\n</code></pre> <p>Localizers can specify locale-specific fonts in one of the following ways:</p> <ul> <li>Choose best-looking fonts widely used on major platforms, and     specify those with the <code>src: local(name)</code> syntax</li> <li>Find a best-looking free Web font, add the font files to     <code>/media/fonts/</code>, and specify those with the <code>src: url(path)</code> syntax</li> <li>Create a custom Web font to complement missing glyphs in Open     Sans, add the font files to <code>/media/fonts/l10n/</code>, and specify those     with the <code>src: url(path)</code> syntax. M+     2c offers various     international glyphs and looks similar to Open Sans, while Noto     Sans is good for the bold and     italic variants. You can create subsets of these alternative fonts     in the WOFF and WOFF2 formats using a tool found on the Web. See     Bug 1360812     for the Fulah (ff) locale's example</li> </ul> <p>Developers should use the <code>.open-sans</code> mixin instead of <code>font-family: 'Open Sans'</code> to specify the default font family in CSS. This mixin has both Open Sans and X-LocaleSpecific so locale-specific fonts, if defined, will be applied to localized pages. The variant mixins, <code>.open-sans-light</code> and <code>.open-sans-extrabold</code>, are also available.</p>"},{"location":"l10n/#all","title":"All","text":""},{"location":"l10n/#locale-specific-templates","title":"Locale-specific Templates","text":"<p>While the <code>ftl_has_messages</code> template function is great in small doses, it doesn't scale particularly well. A template filled with conditional copy can be difficult to comprehend, particularly when the conditional copy has associated CSS and/or JavaScript.</p> <p>In instances where a large amount of a template's copy needs to be changed, or when a template has messaging targeting one particular locale, creating a locale-specific template may be a good choice.</p> <p>Locale-specific templates function simply by naming convention. For example, to create a version of <code>/firefox/new.html</code> specifically for the <code>de</code> locale, you would create a new template named <code>/firefox/new.de.html</code>. This template can either extend <code>/firefox/new.html</code> and override only certain blocks, or be entirely unique.</p> <p>When a request is made for a particular page, bedrock's rendering function automatically checks for a locale-specific template, and, if one exists, will render it instead of the originally specified (locale-agnostic) template.</p> <p>Note</p> <p>Creating a locale-specific template for en-US was not possible when this feature was introduced, but it is now. So you can create your en-US-only template and the rest of the locales will continue to use the default.</p>"},{"location":"l10n/#specifying-active-locales-in-views","title":"Specifying Active Locales in Views","text":"<p>Normally we rely on activation tags in our translation files (.lang files) to determine in which languages a page will be available. This will almost always be what we want for a page. But sometimes we need to explicitly state the locales available for a page. The [impressum]{.title-ref} page for example is only available in German and the template itself has German hard-coded into it since we don't need it to be translated into any other languages. In cases like these we can send a list of locale codes with the template context and it will be the final list. This can be accomplished in a few ways depending on how the view is coded.</p> <p>For a plain view function, you can simply pass a list of locale codes to [l10n_utils.render]{.title-ref} in the context using the name [active_locales]{.title-ref}. This will be the full list of available translations. Use [add_active_locales]{.title-ref} if you want to add languages to the existing list:</p> <pre><code>def french_and_german_only(request):\n    return l10n_utils.render(request, 'home.html', {'active_locales': ['de', 'fr'])\n</code></pre> <p>If you don't need a custom view and are just using the [page()]{.title-ref} helper function in your [urls.py]{.title-ref} file, then you can similarly pass in a list:</p> <pre><code>page('about', 'about.html', active_locales=['en-US', 'es-ES']),\n</code></pre> <p>Or if your view is even more fancy and you're using a Class-Based-View that inherits from [LangFilesMixin]{.title-ref} (which it must if you want it to be translated) then you can specify the list as part of the view Class definition:</p> <pre><code>class MyView(LangFilesMixin, View):\n    active_locales = ['zh-CN', 'hi-IN']\n</code></pre> <p>Or in the [urls.py]{.title-ref} when using a CBV:</p> <pre><code>url(r'about/$', MyView.as_view(active_locales=['de', 'fr'])),\n</code></pre> <p>The main thing to keep in mind is that if you specify [active_locales]{.title-ref} that will be the full list of localizations available for that page. If you'd like to add to the existing list of locales generated from the lang files then you can use the [add_active_locales]{.title-ref} name in all of the same ways as [active_locales]{.title-ref} above. It's a list of locale codes that will be added to the list already available. This is useful in situations where we would have needed the l10n team to create an empty .lang file with an active tag in it because we have a locale-specific-template with text in the language hard-coded into the template and therefore do not otherwise need a .lang file.</p>"},{"location":"l10n/#adding-new-l10n-integrations","title":"Adding new L10N integrations","text":"<p>Bedrock, as a platform, can operate in different modes, and it is possible (necessary, even) to support multiple L10N pipelines, so that each mode of operation can have its own distinct Fluent files and translation strategy.</p> <p>As of Summer 2022, there are two separate L10N integrations within Bedrock:</p> <ul> <li>Mozilla.org (\"Mozorg mode\")</li> <li>Pocket Marketing Pages (\"Pocket mode\")</li> </ul> <p>These integrations are similar in their approach, but not identical in how they run. They use different translations strategies, which requires slightly different data flows.</p> <p>Moving L10N data (essentially Fluent <code>.ftl</code> files) happens via various automation steps, which aren't captured here, as they are more about infrastructure and operations. However, what follows outlines the steps needed to add a new L10N integration (for \"<code>newintegration</code>\") to Bedrock.</p> <ol> <li>FILE SETUP (Bedrock developer)</li> </ol> <p>Add a directory for the source (<code>en</code>) Fluent strings that will need translation.</p> <p>Note</p> <p>For source Fluent files currently...</p> <ul> <li>...Mozorg uses <code>./l10n/</code></li> <li>...Pocket uses <code>./l10n-pocket/</code></li> </ul> <p>Add the following files:</p> <pre><code>./l10n-newintegration/\n./l10n-newintegration/en/  # This is where source Fluent templates go for 'newintegration'\n./l10n-newintegration/en/configs/pontoon.toml  # If using community/Pontoon translations at all\n./l10n-newintegration/en/configs/vendor.toml  # If using a paid-for translation service such as Smartling\n./l10n-newintegration/en/configs/special-templates.toml   # Only needed to exclude certain files from all community AND vendor translation. e.g. we use staff translation only.\n\n./l10n-newintegration/l10n-pontoon.toml  # If using community/Pontoon translations at all\n./l10n-newintegration/l10n-vendor.toml  # If using a paid-for translation service such as Smartling\n\n./data/l10n-newintegration-team/  # leave this empty - it will be populated via a git sync using data FROM the l10n team\n</code></pre> <p>For the exact content of each [.toml]{.title-ref} or [.json]{.title-ref} file, see the examples in <code>./l10n/</code> and <code>./l10n-pocket/</code> for inspiration - they're not too hard to work out. The <code>.toml</code> files outside of <code>/en/</code> basically point to the ones in <code>/en/configs/</code> and are a 'gateway' through which we spec which config files are relevant to which translation stragegy (community or vendor - or neither if it's staff-only translation).</p> <ol> <li>REPO SETUP (Bedrock and/or L10N team admin)</li> </ol> <p>You will need to set up one or two new repos, to hold the translation files as part of the pipeline.</p> <p>i. A repo in where the files are sent to in <code>https://github.com/mozilla-l10n/</code> for the L10N team's automation to pick up.</p> <p>For example, Mozorg uses <code>github.com/mozilla-l10n/www-l10n/</code> and Pocket uses <code>github.com/mozilla-l10n/www-pocket-l10n/</code>. Your new <code>github.com/mozilla-l10n/www-newintegration-l10n/</code> repo will be needed regardless of who does the actual translation work.</p> <p>ii. An optional repo where files are post-processed following     translation.</p> <p>If relevant, this will live in <code>github.com/mozmeao/</code> - for example <code>github.com/mozmeao/www-newintegration-l10n/</code></p> <p>Important</p> <p>If you are not using Pontoon/community translations, you do NOT need to create this repo. Why? If the translations are done by the community (via Pontoon), there is a possibility that not enough of the strings will be translated in order to render the content in the relevant locale. We run a CI task to determine whether a locale has enough translated strings to be considered 'active'. At the moment, only Mozorg uses this pattern. The Pocket-mode translations do not have their activation measured because their translations come entirely from a vendor and we expect the Pocket strings to be 100% translated.</p> <ol> <li>CI SETUP (Bedrock dev)</li> </ol> <p>Only relevant if using Pontoon community translations. Details of how MozMarRobot is hooked are best gleaned from looking at <code>https://gitlab.com/mozmeao/www-fluent-update</code>.</p> <p>In short, once new translations land in the string-source repo (e.g. <code>github.com/mozilla-l10n/www-newintegration-l10n</code>) they are cloned over to the activation-check repo <code>github.com/mozmeao/www-newintegration-l10n/</code> by CI and later pulled into Bedrock from there.</p> <ol> <li>CONFIGURE SETTINGS (Bedrock dev).</li> </ol> <p>You'll also have to update settings so that when the site is in 'newintegration' mode, it knows which L10N-related local folders and remote repos to use. Look in <code>settings/__init__.py</code> to see what we did for Pocket mode.</p> <p>You'll also have to set up new env vars to provide the new repo and filepath settings' values, which will mean updating <code>github.com/mozmeao/www-config/</code> and possibly getting new secrets provisioned in Kubernetes if you need to use a separate auth token for <code>github.com/mozilla-l10n/</code>. (You may not.)</p> <p>Note that if you are not using community/Pontoon translations - and therefore you don't need to use an intermediary repo to calculate activation status - you can just use the <code>mozilla-l10n/www-newintegration-l10n</code> repo for both outbound and inbound translations - look at the Pocket Mode setting for an example of this.</p> <ol> <li>EXPAND L10N UPDATE SCRIPT (Bedrock dev).</li> </ol> <p>Uploading strings for translation</p> <p>Uploading <code>`en</code>-locale source strings from Bedrock to the <code>github.com/mozilla-l10n/</code> repos is handled by <code>bedrock/bin/open-ftl-pr.sh</code>. This file requires no specific code changes to support a new integration as long as you have already set up a <code>SITE_MODE</code> for 'newintegration'.</p> <p>However, you do need to add a new entry to <code>bedrock/.gitlab-ci.yml</code> -- copy the <code>update-l10n</code> step, in a similar way to how it's been duplicated for <code>update-pocket-l10n</code>.</p> <p>Downloading translated strings</p> <p>Update the configuration dict at the top of <code>bedrock/lib/l10n_utils/management/commands/l10n_update.py</code> so that when that management command is run, it will pull down the appropriate translations for \"newintegration\".</p> <p>Tip: to test drive things, you can fork the real repos and test against your forks by specifying them via local env vars.</p> <ol> <li>VENDOR SETUP (L10N Team)</li> </ol> <p>The vendor (e.g. Smartling) will need to add the new string-source repo (<code>github.com/mozilla-l10n/www-newintegration-l10n</code>) to its configuration. Once this is done new translations from the vendor will be added to that repo, and synced down to Bedrock. This step is out of our hands, but the vendor's technical contact should be able to make it happen.</p> <ol> <li>PONTOON SETUP (L10N Team)</li> </ol> <p>Details to come for setting up community translations using Pontoon. (Contributions about this aspect are welcome!)</p>"},{"location":"mozilla-accounts/","title":"Mozilla accounts helpers","text":"<p>Note</p> <p>Since a rebranding in October 2023, we now refer to \"Mozilla accounts\" in our web pages instead of \"Firefox accounts\". This rebranding is so far superficial, and sign up flows still go to <code>accounts.firefox.com</code>. Because of this, our internal code and helpers still use <code>FxA</code> or <code>fxa</code> as a common abbreviation. However the language used around them should now be \"Mozilla accounts\" going forward.</p> <p>Marketing pages often promote the creation of a Mozilla account as a common call to action (CTA). This is typically accomplished using either a sign-up form, or a prominent link/button. Other products such as Mozilla VPN use similar account auth flows to manage subscriptions. To accomplish these tasks, bedrock templates can take advantage of a series of Python helpers which can be used to standardize product referrals, and make supporting these auth flows easier.</p> <p>Note</p> <p>See the attribution docs for more of a detailed description of the analytics functions these helpers provide.</p>"},{"location":"mozilla-accounts/#mozilla-account-sign-up-form","title":"Mozilla account sign-up form","text":"<p>Use the <code>fxa_email_form</code> macro to display a Mozilla account sign-up form on a page.</p>"},{"location":"mozilla-accounts/#usage","title":"Usage","text":"<p>To use the form in a Jinja template, first import the <code>fxa_email_form</code> macro:</p> <pre><code>{% from \"macros.html\" import fxa_email_form with context %}\n</code></pre> <p>The form can then be invoked using:</p> <pre><code>{{ fxa_email_form(entrypoint='mozilla.org-firefox-accounts') }}\n</code></pre> <p>The macro's respective JavaScript and CSS dependencies should also be imported in the page:</p> <p>Javascript:</p> <pre><code>import FxaForm from './path/to/fxa-form.es6.js';\n\nFxaForm.init();\n</code></pre> <p>The above JS is also available as a pre-compiled bundle, which can be included directly in a template:</p> <pre><code>{{ js_bundle('fxa_form') }}\n</code></pre> <p>CSS:</p> <pre><code>@import '../path/to/fxa-form';\n</code></pre> <p>The JavaScript files will automatically handle things such as adding metrics parameters for Firefox desktop browsers. The CSS file contains some default styling for the sign-up form.</p>"},{"location":"mozilla-accounts/#configuration","title":"Configuration","text":"<p>The sign-up form macro accepts the following parameters (* indicates a required parameter)</p> Parameter name Definition Format Example entrypoint* Unambiguous identifier for which page of the site is the referrer. mozilla.org-directory-page \u2018mozilla.org-firefox-accounts\u2019 entrypoint_experiment Used to identify experiments. Experiment ID \u2018whatsnew-headlines\u2019 entrypoint_variation Used to track page variations in multivariate tests. Usually just a number or letter but could be a short keyword. Variant identifier \u2018b\u2019 style An optional parameter used to invoke an alternatively styled page at accounts.firefox.com. String \u2018trailhead\u2019 class_name Applies a CSS class name to the form. Defaults to: \u2018fxa-email-form\u2019 String \u2018fxa-email-form\u2019 form_title The main heading to be used in the form (optional with no default). Localizable string \u2018Join Firefox\u2019 . intro_text Introductory copy to be used in the form. Defaults to a well localized string. Localizable string \u2018Enter your email address to get started.\u2019 . button_text Button copy to be used in the form. Defaults to a well localized string. Localizable string \u2018Sign Up\u2019 . button_class CSS class names to be applied to the submit button. String of one or more CSS class names \u2018mzp-c-button mzp-t-primary mzp-t-product\u2019 utm_campaign Used to identify specific marketing campaigns. Defaults to fxa-embedded-form Campaign name prepended to default value \u2018trailhead-fxa-embedded-form\u2019 utm_term Used for paid search keywords. Brief keyword \u2018existing-users\u2019 utm_content Declared when more than one piece of content (on a page or at a URL) links to the same place, to distinguish between them. Description of content, or name of experiment treatment \u2018get-the-rest-of-firefox\u2019 <p>Invoking the macro will automatically include a set of default UTM parameters as hidden form input fields:</p> <ul> <li><code>utm_source</code> is automatically assigned the value of the <code>entrypoint</code>     parameter.</li> <li><code>utm_campaign</code> is automatically set as the value of     <code>fxa-embedded-form</code>. This can be prefixed with a custom value by     passing a <code>utm_campaign</code> value to the macro. For example,     <code>utm_campaign='trailhead'</code> would result in a value of     <code>trailhead-fxa-embedded-form</code>.</li> <li><code>utm_medium</code> is automatically set as the value of <code>referral</code>.</li> </ul> <p>Note</p> <p>When signing into a Mozilla account using this form on a Firefox Desktop browser, it will also activate the Sync feature.</p>"},{"location":"mozilla-accounts/#mozilla-account-links","title":"Mozilla account links","text":"<p>Use the <code>fxa_button</code> helper to create a CTA button or link to https://accounts.firefox.com/.</p>"},{"location":"mozilla-accounts/#usage_1","title":"Usage","text":"<pre><code>{{ fxa_button(entrypoint='mozilla.org-firefox-sync-page', button_text='Sign In') }}\n</code></pre> <p>Note</p> <p>There is also a <code>fxa_link_fragment</code> helper which will construct a valid <code>href</code> property. This is useful when constructing an inline link inside a paragraph, for example.</p> <p>Note</p> <p>When signing into a Mozilla account using this link on a Firefox Desktop browser, it will also activate the Sync feature.</p> <p>For more information on the available parameters, read the \"Common Parameters\" section further below.</p>"},{"location":"mozilla-accounts/#mozilla-monitor-links","title":"Mozilla Monitor links","text":"<p>Use the <code>monitor_fxa_button</code> helper to link to https://monitor.firefox.com/ via a Mozilla accounts auth flow.</p>"},{"location":"mozilla-accounts/#usage_2","title":"Usage","text":"<pre><code>{{ monitor_fxa_button(entrypoint=_entrypoint, button_text='Sign Up for Monitor') }}\n</code></pre> <p>For more information on the available parameters, read the \"Common Parameters\" section further below.</p>"},{"location":"mozilla-accounts/#pocket-links","title":"Pocket links","text":"<p>Use the <code>pocket_fxa_button</code> helper to link to https://getpocket.com/ via a Mozilla accounts auth flow.</p>"},{"location":"mozilla-accounts/#usage_3","title":"Usage","text":"<pre><code>{{ pocket_fxa_button(entrypoint='mozilla.org-firefox-pocket', button_text='Try Pocket Now', optional_parameters={'s': 'ffpocket'}) }}\n</code></pre> <p>For more information on the available parameters, read the \"Common Parameters\" section below.</p>"},{"location":"mozilla-accounts/#common-parameters","title":"Common Parameters","text":"<p>The <code>fxa_button</code>, <code>pocket_fxa_button</code>, and <code>monitor_fxa_button</code> helpers all support the same standard parameters:</p> Parameter name Definition Format Example entrypoint* Unambiguous identifier for which page of the site is the referrer. This also serves as a value for \u2018utm_source\u2019. \u2018www.mozilla.org-page-name\u2019 \u2018www.mozilla.org-vpn-product-page\u2019 link_text* The link copy to be used in the call to action. Localizable string \u2018Get Mozilla VPN\u2019 class_name A class name to be applied to the link (typically for styling with CSS). String of one or more class names \u2018vpn-button\u2019 lang Page locale code. Used to query the right subscription plan ID in conjunction to country code. Locale string \u2018de\u2019 country_code Country code provided by the CDN. Used to determine the appropriate subscription plan ID. Two digit, uppercase country code \u2018DE\u2019 bundle_relay Generate a link that will bundle both Mozilla VPN and Firefox Relay in a single subscription. Defaults to False. Boolean True, False optional_parameters An dictionary of key value pairs containing additional parameters to append the the href. Dictionary {\u2018utm_campaign\u2019: \u2018vpn-product-page\u2019} optional_attributes An dictionary of key value pairs containing additional data attributes to include in the button. Dictionary {\u2018data-cta-text\u2019: \u2018VPN Sign In\u2019, \u2018data-cta-type\u2019: \u2018fxa-vpn\u2019, \u2018data-cta-position\u2019: \u2018navigation\u2019} <p>Note</p> <p>The <code>fxa_button</code> helper also supports an additional <code>action</code> parameter, which accepts the values <code>signup</code>, <code>signin</code>, and <code>email</code> for configuring the type of authentication flow.</p>"},{"location":"mozilla-accounts/#mozilla-vpn-links","title":"Mozilla VPN Links","text":"<p>Use the <code>vpn_subscribe_link</code> helpers to create a VPN subscription link via a Mozilla accounts auth flow.</p>"},{"location":"mozilla-accounts/#usage_4","title":"Usage","text":"<pre><code>{{ vpn_subscribe_link(entrypoint='www.mozilla.org-vpn-product-page', link_text='Get Mozilla VPN') }}\n</code></pre>"},{"location":"mozilla-accounts/#common-vpn-parameters","title":"Common VPN Parameters","text":"<p>Both helpers for Mozilla VPN support the same parameters (* indicates a required parameter)</p> Parameter name Definition Format Example entrypoint* Unambiguous identifier for which page of the site is the referrer. This also serves as a value for \u2018utm_source\u2019. \u2018www.mozilla.org-page-name\u2019 \u2018www.mozilla.org-vpn-product-page\u2019 link_text* The link copy to be used in the call to action. Localizable string \u2018Get Mozilla VPN\u2019 class_name A class name to be applied to the link (typically for styling with CSS). String of one or more class names \u2018vpn-button\u2019 lang Page locale code. Used to query the right subscription plan ID in conjunction to country code. Locale string \u2018de\u2019 country_code Country code provided by the CDN. Used to determine the appropriate subscription plan ID. Two digit, uppercase country code \u2018DE\u2019 bundle_relay Generate a link that will bundle both Mozilla VPN and Firefox Relay in a single subscription. Defaults to False. Boolean True, False optional_parameters An dictionary of key value pairs containing additional parameters to append the the href. Dictionary {\u2018utm_campaign\u2019: \u2018vpn-product-page\u2019} optional_attributes An dictionary of key value pairs containing additional data attributes to include in the button. Dictionary {\u2018data-cta-text\u2019: \u2018VPN Sign In\u2019, \u2018data-cta-type\u2019: \u2018fxa-vpn\u2019, \u2018data-cta-position\u2019: \u2018navigation\u2019} <p>The <code>vpn_subscribe_link</code> helper has an additional <code>plan</code> parameter to support linking to different subscription plans.</p> Parameter name Definition Format Example plan Subscription plan ID. Defaults to 12-month plan. \u201812-month\u2019 \u201812-month\u2019 or \u2018monthly\u2019"},{"location":"mozilla-accounts/#firefox-sync-and-uitour","title":"Firefox Sync and UITour","text":"<p>Since Firefox 80 the accounts link and email form macros use UITour to show the Mozilla accounts page and log the browser into Sync or an account. For non-Firefox browsers or if UITour is not available, the flow uses normal links that allow users to log into the Mozilla accounts website only, without connecting the Firefox Desktop client. This UITour flow allows the Firefox browser to determine the correct Mozilla accounts server and authentication flow (this includes handling the China Repack build of Firefox). This transition was introduced to later migrate Firefox Desktop to an OAuth based client authentication flow.</p> <p>The script that handles this logic is <code>/media/js/base/fxa-link.js</code>, and will automatically apply to any link with a <code>js-fxa-cta-link</code> class name. The current code automatically detects if you are in the supported browser for this flow and updates links to drive them through the UITour API. The UITour <code>showFirefoxAccounts</code> action supports flow id parameters, UTM parameters and the email data field.</p>"},{"location":"mozilla-accounts/#testing-sign-up-flows","title":"Testing Sign-up Flows","text":"<p>Testing the Mozilla account sign-up flows on a non-production environment requires some additional configuration.</p> <p>Configuring bedrock:</p> <p>Set the following in your local <code>.env</code> file:</p> <pre><code>FXA_ENDPOINT=https://accounts.stage.mozaws.net/\n</code></pre> <p>For Mozilla VPN links you can also set:</p> <pre><code>VPN_ENDPOINT=https://stage.guardian.nonprod.cloudops.mozgcp.net/\nVPN_SUBSCRIPTION_URL=https://accounts.stage.mozaws.net/\n</code></pre> <p>Note</p> <p>The above values for staging are already set by default when <code>Dev=True</code>, which will also apply to demo servers. You may only need to configure your <code>.env</code> file if you wish to change a setting to something else.</p>"},{"location":"newsletters/","title":"Newsletters","text":"<p>Bedrock includes support for signing up for and managing subscriptions and preferences for Mozilla newsletters.</p> <p>Many pages have a form to sign-up for the default newsletters, \"Mozilla Foundation\" and \"Firefox &amp; You\". Other pages have more specific sign up forms, such as the contribute page, or Mozilla VPN wait-list page.</p>"},{"location":"newsletters/#features","title":"Features","text":"<ul> <li>Ability to subscribe to a newsletter from a web form. Many pages on     the site might include this form.</li> <li>Whole pages devoted to subscribing to one newsletter, often with     custom text, branding, and layout.</li> <li>Newsletter preference center - allow user to change their email     preferences (e.g. language, HTML vs. text), as well as which     newsletters they're subscribed to, etc. Access is limited by     requiring a user-specific token in the URL (it's a UUID). The full     URL is included as a link in each newsletter sent to the user. Users     can also recover a link to their token by visiting the newsletter     recovery page and entering their email address.</li> </ul>"},{"location":"newsletters/#newsletters-newsletters-1","title":"Newsletters {#newsletters-1}","text":"<p>Newsletters have a variety of characteristics. Some of these are implemented in Bedrock, others are transparent to Bedrock but implemented in the basket back-end that provides our interface to the newsletter vendor.</p> <ul> <li> <p>Public name - the name that is displayed to users, e.g. \"Firefox     Weekly Tips\".</p> </li> <li> <p>Internal name - a short string that is used internal to Bedrock and     basket to identify a newsletter. Typically these are lowercase     strings of words joined by hyphens, e.g. \"firefox-tips\". This is     what we send to basket to identify a newsletter, e.g. to subscribe a     user to it.</p> </li> <li> <p>Show publicly - pages like the newsletter preferences center show a     list of unsubscribed newsletters and allow subscribing to them. Some     newsletters aren't included in that list by default (though they     are shown if the user is already subscribed, to let them     unsubscribe). If the user has a Mozilla account, there are also some     other related newsletters that will always be shown in the list.</p> </li> <li> <p>Languages - newsletters are available in a particular set of     languages. Typically when subscribing to a newsletter, a user can     choose their preferred language. We should try not to let them     subscribe to a newsletter in a language that it doesn't support.</p> <p>The backend only stores one language for the user though, so whenever the user submits one of our forms, whatever language they last submitted is what is saved for their preference for everything.</p> </li> <li> <p>Welcome message - each newsletter can have a canned welcome message     that is sent to a user when they subscribe to it. Newsletters should     have both an HTML and a text version of this.</p> </li> <li> <p>Drip campaigns - some newsletters implement so-called drip     campaigns, in which a series of canned messages are dribbled out to     the user over a period of time. E.g. 1 week after subscribing, they     might get message 1; a week later, message 2, and so on until all     the canned messages have been sent.</p> <p>Because drip campaigns depend on the sign-up date of the user, we're careful not to accidentally change the sign-up date, which could happen if we sent redundant subscription commands to our backend.</p> </li> </ul>"},{"location":"newsletters/#bedrock-and-basket","title":"Bedrock and Basket","text":"<p>Bedrock is the user-facing web application. It presents an interface for users to subscribe and manage their subscriptions and preferences. It does not store any information. It gets all newsletter and user-related information, and makes updates, via web requests to the Basket server. These requests are made typically made by Bedrock's front-end JavaScript modules.</p> <p>The Basket server implements an HTTP API for the newsletters. The front-end (Bedrock) can make calls to it to retrieve or change users' preferences and subscriptions, and information about the available newsletters. Basket implements some of that itself, and other functions by calling the newsletter vendor's API. Details of that are outside the scope of this document, but it's worth mentioning that both the user token (UUID) and the newsletter internal name mentioned above are used only between Bedrock and Basket.</p> <p>See the Basket docs for more information.</p>"},{"location":"newsletters/#urls","title":"URLs","text":"<p>Here are a few important mozorg newsletter URLs. Some of these were established before Bedrock came along, and so are unlikely to be changed.</p> <ul> <li><code>/newsletter/</code> - Subscribe to 'mozilla-and-you' newsletter (public     name: \"Firefox &amp; You\")</li> <li><code>/newsletter/existing/{USERTOKEN}/</code> - User management of their     preferences and subscriptions.</li> <li><code>/newsletter/confirm/{USERTOKEN}/</code> - URL someone lands on when they     confirm their email address after initially subscribing.</li> <li><code>/newsletter/country/{USERTOKEN}/</code> - Allows users to change their     country.</li> <li><code>/newsletter/recovery/</code> - Allows users to recover a link containing     their token so they can manage their subscriptions.</li> <li><code>/newsletter/updated/</code> - A page users are redirected to after     updating their details, or unsubscribing.</li> </ul> <p>Note</p> <p>URLs that contain <code>{USERTOKEN}</code> will have their path rewritten on page load so that they no longer contain the token e.g. <code>/newsletter/existing/{USERTOKEN}/</code> will be rewritten to just <code>/newsletter/existing/</code>. This helps to prevent accidental sharing of user tokens in URLS and also against referral information leakage.</p>"},{"location":"newsletters/#footer-sign-up","title":"Footer sign-up","text":"<p>In some common templates, you can customize the footer sign-up form by overriding the email_form template block. For example, to have no sign-up form:</p> <pre><code>{% block email_form %}{% endblock %}\n</code></pre> <p>The default is:</p> <pre><code>{% block email_form %}{{ email_newsletter_form() }}{% endblock %}\n</code></pre> <p>This will render a sign-up for \"Firefox &amp; You\". You can pass parameters to the macro <code>email_newsletter_form</code> to change that. For example, the <code>newsletters</code> parameter controls which newsletter is signed up for, and <code>title</code> can override the text:</p> <pre><code>{% block email_form %}\n{{ email_newsletter_form('app-dev',\n                             'Sign up for more news about the Firefox Marketplace.') }}\n{% endblock %}\n</code></pre> <p>The [newsletters]{.title-ref} parameter, the first positional argument, can be either a list of newsletter IDs or a comma separated list of newsletters IDs:</p> <pre><code>{% block email_form %}\n{{ email_newsletter_form('mozilla-foundation, mozilla-and-you') }}\n{% endblock %}\n</code></pre> <p>Pages can control whether country or language fields are included by passing <code>include_language=[True|False]</code> and/or <code>include_country=[True|False]</code>.</p>"},{"location":"pipeline/","title":"Continuous Integration & Deployment","text":"<p>Bedrock runs a series of automated tests as part of continuous integration workflow and deployment pipeline. You can learn more about each of the individual test suites by reading their respective pieces of documentation:</p> <ul> <li>Python unit tests (see Run the tests).</li> <li>JavaScript unit tests (see Frontend testing).</li> <li>Redirect tests (see Testing redirects).</li> <li>Functional tests (see Frontend testing).</li> </ul>"},{"location":"pipeline/#deployed-site-urls","title":"Deployed site URLs","text":"<p>Note that a deployment of Bedrock will actually trigger two separate deployments: one serving all of <code>mozilla.org</code> and another serving certain parts of <code>getpocket.com</code></p>"},{"location":"pipeline/#dev","title":"Dev","text":"<ul> <li>Mozorg URL: https://www-dev.allizom.org/</li> <li>Pocket Marketing pages URL: https://dev.tekcopteg.com/</li> <li>Bedrock locales: dev repo</li> <li>Bedrock Git branch: main, deployed on git push</li> </ul>"},{"location":"pipeline/#staging","title":"Staging","text":"<ul> <li>Mozorg URL: https://www.allizom.org/</li> <li>Pocket Marketing pages URL: https://www.tekcopteg.com/</li> <li>Bedrock locales: prod repo</li> <li>Bedrock Git branch: stage, deployed on git push</li> </ul>"},{"location":"pipeline/#production","title":"Production","text":"<ul> <li>Mozorg URL: https://www.mozilla.org/</li> <li>Pocket Marketing pages URL: https://getpocket.com/</li> <li>Bedrock locales: prod repo</li> <li>Bedrock Git branch: prod, deployed on git push with date-tag</li> </ul> <p>You can check the currently deployed git commit by checking /revision.txt on any of these URLs.</p>"},{"location":"pipeline/#tests-in-the-lifecycle-of-a-change","title":"Tests in the lifecycle of a change","text":"<p>Below is an overview of the tests during the lifecycle of a change to bedrock:</p>"},{"location":"pipeline/#local-development","title":"Local development","text":"<p>The change is developed locally, and page specific integration tests can be executed against a locally running instance of the application. If testing changes to the website as a whole is required, then pushing changes to the special <code>run-integration-tests</code> branch (see below) is much faster than running the full test suite locally.</p>"},{"location":"pipeline/#pull-request","title":"Pull request","text":"<p>Once a pull request is submitted, a Unit Tests Github Action will run both the Python and JavaScript unit tests, as well as the suite of redirect headless HTTP(s) response checks.</p>"},{"location":"pipeline/#push-to-main-branch","title":"Push to main branch","text":"<p>Whenever a change is pushed to the main branch, a new image is built and deployed to the dev environment, and the full suite of headless and UI tests are run. This is handled by the pipeline, and is subject to change according to the settings in the Github Action workflow defined in <code>bedrock/.github/workflows/integration_tests.yml</code>.</p> <p>The tests for the dev environment are currently configured as follows:</p> <ul> <li>Chrome (latest) via local Selenium grid.</li> <li>Firefox (latest) via local Selenium grid.</li> <li>Internet Explorer 11 (smoke tests) via Sauce     Labs.</li> <li>Internet Explorer 9 (sanity tests) via Sauce     Labs.</li> <li>Headless tests.</li> </ul> <p>Note that now we have Mozorg mode and Pocket mode, we actually stand up two dev, two stage and two test deployments and we run the appropriate integration tests against each deployment: most tests are written for Mozorg, but there are some for Pocket mode that also get run.</p> <p>The deployment workflow runs like this</p> <ol> <li>A push to the <code>main</code>/<code>stage</code>/<code>prod</code>/<code>run-integration-tests</code> branch of <code>mozilla/bedrock</code> triggers a webhook ping to the (private) <code>mozilla-sre-deploy/deploy-bedrock</code> repo.</li> <li>A Github Action (GHA) in <code>mozilla-sre-deploy/deploy-bedrock</code> builds a \"release\"-ready Bedrock container image, which it stores in a private container registry (private because our infra requires container-image access to be locked down). Using the same commit, the workflow also builds an equivalent set of public Bedrock container images, which are pushed to Docker Hub.</li> <li>The GHA deploys the relevant container image to the appropriate environment.</li> <li>The GHA pings a webhook back in <code>mozilla/bedrock</code> to run integration tests against the environment that has just been deployed.</li> </ol>"},{"location":"pipeline/#push-to-stage-branch","title":"Push to stage branch","text":"<p>Whenever a change is pushed to the stage branch, a production docker image is built, published to Docker Hub, and deployed to a public staging environment. Once the new image is deployed, the full suite of UI tests is run against it again, but this time with the addition of the [headless download tests]{.title-ref}.</p>"},{"location":"pipeline/#push-to-prod-branch-tagged-tagged-commit","title":"Push to prod branch (tagged) {#tagged-commit}","text":"<p>When a tagged commit is pushed to the <code>prod</code> branch, a production container image (private, see above) is built, and a set of public images is also built and pushed to Docker Hub if needed (usually this will have already happened as a result of a push to the <code>main</code> or <code>stage</code> branch). The production image is deployed to each production deployment.</p> <p>Push to prod cheat sheet</p> <ol> <li> <p>Check out the <code>main</code> branch</p> </li> <li> <p>Make sure the <code>main</code> branch is up to date with     <code>mozilla/bedrock main</code></p> </li> <li> <p>Check that dev deployment is green:</p> <ol> <li>View the Integration Tests Github     Action     and look at the run labelled     <code>Run Integration tests for main</code></li> </ol> </li> <li> <p>Check that stage deployment is also green     (<code>Run Integration tests for stage</code>)</p> </li> <li> <p>Tag and push the deployment by running <code>bin/tag-release.sh --push</code></p> </li> </ol> <p>Note</p> <p>By default the <code>tag-release.sh</code> script will push to the <code>origin</code> git remote. If you'd like for it to push to a different remote name you can either pass in a <code>-r</code> or <code>--remote</code> argument, or set the <code>MOZ_GIT_REMOTE</code> environment variable. So the following are equivalent:</p> <pre><code>$ bin/tag-release.sh --push -r mozilla\n</code></pre> <pre><code>$ MOZ_GIT_REMOTE=mozilla bin/tag-release.sh --push\n</code></pre> <p>And if you'd like to just tag and not push the tag anywhere, you may omit the <code>--push</code> parameter.</p>"},{"location":"pipeline/#what-is-currently-deployed","title":"What Is Currently Deployed?","text":"<p>You can look at the git log of the <code>main</code> branch to find the last commit with a date-tag on it (e.g. 2022-05-05): this commit will be the last one that was deployed to production. You can also use the whatsdeployed.io service to get a nice view of what is actually currently deployed to Dev, Stage, and Prod:</p> <p></p>"},{"location":"pipeline/#instance-configuration-switches","title":"Instance Configuration &amp; Switches","text":"<p>We have a separate repo for configuring our primary instances (dev, stage, and prod). The docs for updating configurations in that repo are on their own page, but there is a way to tell what version of the configuration is in use on any particular instance of bedrock. You can go to the <code>/healthz-cron/</code> URL on an instance (see prod for example) to see the current commit of all of the external Git repos in use by the site and how long ago they were updated. The info on that page also includes the latest version of the database in use, the git revision of the bedrock code, and how long ago the database was updated. If you recently made a change to one of these repos and are curious if the changes have made it to production, this is the URL you should check.</p>"},{"location":"pipeline/#updating-selenium","title":"Updating Selenium","text":"<p>There are several components for Selenium, which are independently versioned. The first is the Python client, and this can be updated via the test dependencies. The other components are the Selenium versions used in both SauceLabs and the local Selenium grid. These versions are selected automatically based on the required OS / Browser configuration, so they should not need to be updated or specified independently.</p>"},{"location":"pipeline/#adding-test-runs","title":"Adding test runs","text":"<p>Test runs can be added by creating a new job in <code>bedrock/.github/workflows/integration_tests.yml</code> with the desired variables and pushing that branch to Github. For example, if you wanted to run the smoke tests in IE10 (using Saucelabs) you could add the following clause to the matrix:</p> <pre><code>- LABEL: test-ie10-saucelabs\nBROWSER_NAME: internet explorer\nBROWSER_VERSION: \"10.0\"\nDRIVER: SauceLabs\nPYTEST_PROCESSES: \"8\"\nPLATFORM: Windows 8\nMARK_EXPRESSION: smoke\n</code></pre> <p>You can use Sauce Labs platform configurator to help with the parameter values.</p>"},{"location":"pipeline/#pushing-to-the-integration-tests-branch","title":"Pushing to the integration tests branch","text":"<p>If you have commit rights to our Github repo (mozilla/bedrock) you can simply push your branch to the branch named <code>run-integration-tests</code>, and the app will be deployed and the full suite of integration tests for that branch will be run. Please announce in our Slack channel (#www on mozilla.slack.com) that you'll be doing this so that we don't get conflicts. Also remember that you'll likely need to force push, as there may be commits on that branch which aren't in yours -- so, if you have the <code>mozilla/bedrock</code> remote set as <code>mozilla</code>:</p> <pre><code>$ git push -f mozilla $(git branch --show-current):run-integration-tests\n</code></pre>"},{"location":"redirects/","title":"Managing Redirects","text":"<p>We have a redirects app in bedrock that makes it easier to add and manage redirects. Due to the size, scope, and history of mozilla.org we have quite a lot of redirects. If you need to add or manage redirects read on.</p>"},{"location":"redirects/#add-a-redirect","title":"Add a redirect","text":"<p>You should add redirects in the app that makes the most sense. For example, if the source URL is <code>/firefox/...</code> then the <code>bedrock.firefox</code> app is the best place. Redirects are added to a <code>redirects.py</code> file within the app. If the app you want to add redirects to doesn't have such a file, you can create one and it will automatically be discovered and used by bedrock as long as said app is in the <code>INSTALLED_APPS</code> setting (see <code>bedrock/mozorg/redirects.py</code> as an example).</p> <p>Once you decide where it should go you can add your redirect. To do this you simply add a call to the <code>bedrock.redirects.util.redirect</code> helper function in a list named <code>redirectpatterns</code> in <code>redirects.py</code>. For example:</p> <pre><code>from bedrock.redirects.util import redirect\n\n\nredirectpatterns = [\n    redirect(r'^rubble/barny/$', '/flintstone/fred/'),\n]\n</code></pre> <p>This will make sure that requests to <code>/rubble/barny/</code> (or with the locale like <code>/pt-BR/rubble/barny/</code>) will get a 301 response sending users to <code>/flintstone/fred/</code>.</p> <p>The <code>redirect()</code> function has several options. Its signature is as follows:</p> <pre><code>def redirect(pattern, to, permanent=True, locale_prefix=True, anchor=None, name=None,\n             query=None, vary=None, cache_timeout=12, decorators=None):\n\"\"\"\n    Return a url matcher suited for urlpatterns.\n\n    pattern: the regex against which to match the requested URL.\n    to: either a url name that `reverse` will find, a url that will simply be returned,\n        or a function that will be given the request and url captures, and return the\n        destination.\n    permanent: boolean whether to send a 301 or 302 response.\n    locale_prefix: automatically prepend `pattern` with a regex for an optional locale\n        in the URL. This locale (or None) will show up in captured kwargs as 'locale'.\n    anchor: if set it will be appended to the destination URL after a '#'.\n    name: if used in a `urls.py` the redirect URL will be available as the name\n        for use in calls to `reverse()`. Does _NOT_ work if used in a `redirects.py` file.\n    query: a dict of query params to add to the destination URL.\n    vary: if you used an HTTP header to decide where to send users you should include that\n        header's name in the `vary` arg.\n    cache_timeout: number of hours to cache this redirect. just sets the proper `cache-control`\n        and `expires` headers.\n    decorators: a callable (or list of callables) that will wrap the view used to redirect\n        the user. equivalent to adding a decorator to any other view.\n\n    Usage:\n    urlpatterns = [\n        redirect(r'projects/$', 'mozorg.product'),\n        redirect(r'^projects/seamonkey$', 'mozorg.product', locale_prefix=False),\n        redirect(r'apps/$', 'https://marketplace.firefox.com'),\n        redirect(r'firefox/$', 'firefox.new', name='firefox'),\n        redirect(r'the/dude$', 'abides', query={'aggression': 'not_stand'}),\n    ]\n    \"\"\"\n</code></pre>"},{"location":"redirects/#differences","title":"Differences","text":"<p>This all differs from <code>urlpatterns</code> in <code>urls.py</code> files in some important ways. The first is that these happen first. If something matches in a <code>redirects.py</code> file it will always win the race if another URL in a <code>urls.py</code> file would also have matched. Another is that these are matched before any locale prefix stuff happens. So what you're matching against in the redirects files is the original URL that the user requested. By default (unless you set <code>locale_prefix=False</code>) your patterns will match either the plain URL (e.g. <code>/firefox/os/</code>) or one with a locale prefix (e.g. <code>/fr/firefox/os/</code>). If you wish to include this locale in the destination URL you can simply use python's string <code>format()</code> function syntax. It is passed to the <code>format</code> method as the keyword argument <code>locale</code> (e.g. <code>redirect('^stuff/$', '{locale}whatnot/')</code>). If there was no locale in the URL the <code>{locale}</code> substitution will be an empty string. Similarly if you wish to include a part of the original URL in the destination, just capture it with the regex using a named capture (e.g. <code>r'^stuff/(?P&lt;rest&gt;.*)$'</code> will let you do <code>'/whatnot/{rest}'</code>).</p>"},{"location":"redirects/#utilities","title":"Utilities","text":"<p>There are a couple of utility functions for use in the <code>to</code> argument of <code>redirect</code> that will return a function to allow you to match something in an HTTP header.</p>"},{"location":"redirects/#ua_redirector","title":"ua_redirector","text":"<p><code>bedrock.redirects.util.ua_redirector</code> is a function to be used in the <code>to</code> argument that will use a regex to match against the <code>User-Agent</code> HTTP header to allow you to decide where to send the user. For example:</p> <pre><code>from bedrock.redirects.util import redirect, ua_redirector\n\n\nredirectpatterns = [\n    redirect(r'^rubble/barny/$',\n             ua_redirector('firefox(os)?', '/firefox/', '/not-firefox/'),\n             cache_timeout=0),\n]\n</code></pre> <p>You simply pass it a regex to match, the destination URL (substitutions from the original URL do work) if the regex matches, and another destination URL if the regex does not match. The match is not case sensitive unless you add the optional <code>case_sensitive=True</code> argument.</p> <p>Important</p> <p>Be sure to include the <code>cache_timeout=0</code> so that you won't be bitten by any caching proxies sending all users one way or the other. Do not set the <code>Vary: User-Agent</code> header; this will not work in production.</p>"},{"location":"redirects/#header_redirector","title":"header_redirector","text":"<p>This is basically the same as <code>ua_redirector</code> but works against any header. The arguments are the same as above except that thre is an additional first argument for the name of the header:</p> <pre><code>from bedrock.redirects.util import redirect, header_redirector\n\n\nredirectpatterns = [\n    redirect(r'^rubble/barny/$',\n             header_redirector('cookie', 'been-here', '/firefox/', '/firefox/new/'),\n             vary='cookie'),\n]\n</code></pre>"},{"location":"redirects/#testing-redirects","title":"Testing redirects","text":"<p>A suite of tests exists for redirects, which is intended as a reference of the redirects we expect to work on www.mozilla.org. This will become a base for implementing these redirects in the bedrock app and allow us to test them before release.</p>"},{"location":"redirects/#installation","title":"Installation","text":"<p>First follow the installation instructions for bedrock, which will guide you through installing pip and setting up a virtual environment for the tests. The additional requirements can then be installed by using the following commands:</p> <pre><code>$ source venv/bin/activate\n</code></pre> <pre><code>$ pip install -r requirements/dev.txt\n</code></pre>"},{"location":"redirects/#running-the-tests","title":"Running the tests","text":"<p>If you wish to run the full set of tests, which requires a deployed instance of the site (e.g. www.mozilla.org) you can set the <code>--base-url</code> command line option:</p> <pre><code>$ py.test --base-url https://www.mozilla.org tests/redirects/\n</code></pre> <p>By default, tests will run one at a time. If you intend to run the suite against a remote instance of the site (e.g. production) it will run a lot quicker by running the tests in parallel. To do this, you can add <code>-n auto</code> to the command line. Replace <code>auto</code> with an integer if you want to set the maximum number of concurrent processes.</p>"},{"location":"send-to-device/","title":"Send to Device Widget","text":"<p>The Send to Device widget is a single form which facilitates the sending of a download link from a desktop browser to a mobile device. The form allows sending via email.</p> <p>Important</p> <p>This widget should only be shown to a limited set of locales who are set up to receive the emails. For those locales not in the list, direct links to the respective app stores should be shown instead. If a user is on iOS or Android, CTA buttons should also link directly to respective app stores instead of showing the widget. This logic should be handled on a page-by-page basis to cover individual needs.</p> <p>Note</p> <p>A full list of supported locales can be found in <code>settings/base.py</code> under <code>SEND_TO_DEVICE_LOCALES</code>, which can be used in the template logic for each page to show the form.</p>"},{"location":"send-to-device/#usage","title":"Usage","text":"<ol> <li> <p>Make sure necessary files are in your CSS/JS bundles:</p> </li> <li> <p><code>'css/protocol/components/send-to-device.scss'</code></p> </li> <li> <p><code>'js/base/send-to-device.es6.js'</code></p> </li> <li> <p>Include the macro in your page template:</p> <p>{{ send_to_device() }}</p> </li> <li> <p>Initialize the widget:</p> </li> </ol> <p>In your page JS, initialize the widget using:</p> <pre><code>import SendToDevice from '/media/js/base/send-to-device.es6';\n\nconst form = new SendToDevice();\nform.init();\n</code></pre> <p>By default the <code>init()</code> function will look for a form with an HTML id of <code>send-to-device</code>. If you need to pass another id, you can do so directly:</p> <pre><code>const form = new SendToDevice('my-custom-form-id');\nform.init();\n</code></pre>"},{"location":"send-to-device/#configuration","title":"Configuration","text":"<p>The Jinja macro supports parameters as follows (* indicates a required parameter)</p> Parameter name Definition Format Example platform* Platform ID for the receiving device. Defaults to \u2018all\u2019. String \u2018all\u2019, \u2018android\u2019, \u2018ios\u2019 message_set* ID for the email that should be received. Defaults to \u2018default\u2019. String \u2018default\u2019, \u2018fx-mobile-download-desktop\u2019, \u2018download-firefox-rocket\u2019 dom_id* HTML form ID. Defaults to \u2018send-to-device\u2019. String \u2018send-to-device\u2019 class_name CSS class name for form orientation. Defaults to \u2018vertical\u2019 String \u2018horizontal\u2019, \u2018vertical\u2019 include_title Should the widget contain a title. Defaults to \u2018True\u2019. Boolean \u2018True\u2019, \u2018False\u2019 title_text Provides a custom string for the form title, overriding the default. Localizable string \u2018Send Firefox Lite to your smartphone or tablet\u2019 . input_label Provides a custom label for the input field, overriding the default. Localizable string \u2018Enter your email\u2019 . legal_note_email Provides a custom legal note for email use. Localizable String. \u2018The intended recipient of the email must have consented.\u2019 spinner_color Hex color for the form spinner. Defaults to \u2018#000\u2019. String \u2018#fff\u2019 button_class Optional button CSS class string. Defaults to \u2018mzp-t-product\u2019 String \u2018mzp-t-product mzp-t-dark\u2019"},{"location":"sitemap/","title":"Sitemaps","text":"<p><code>bedrock</code> serves a root sitemap at <code>/sitemap.xml</code>, which links to localised sitemaps for each supported locale.</p> <p>The sitemap data is (re)generated on a schedule by www-sitemap-generator and then is pulled into <code>bedrock</code>'s database, from which the XML sitemaps are rendered.</p>"},{"location":"sitemap/#quick-summary","title":"Quick summary","text":""},{"location":"sitemap/#what-does-www-sitemap-generator-do","title":"What does <code>www-sitemap-generator</code> do?","text":"<p><code>www-sitemap-generator</code>, ultimately, produces an updated <code>sitemap.json</code> file if it detects changes in pages since the last time the sitemap was generated. It does this by loading every page and checking its ETag. This <code>sitemap.json</code> data is key to sitemap rendering by <code>bedrock</code>.</p> <p>The update process is run on a schedule via our Gitlab CI setup.</p> <p><code>www-sitemap-generator</code> uses the main <code>bedrock</code> release Docker image as its own base container image, which means it has access to all of <code>bedrock</code>'s code and data-loading utils.</p> <p>Bear this in mind when looking at management commands in <code>bedrock</code>; <code>update_sitemaps</code> is actually only called by <code>www-sitemap-generator</code> even though it (currently) lives in <code>bedrock</code></p>"},{"location":"sitemap/#when-is-the-sitemap-data-pulled-into-bedrock","title":"When is the sitemap data pulled into <code>bedrock</code>?","text":"<p>Bedrock's clock pod regularly runs <code>bin/run-db-update.sh</code>, which calls the <code>update_sitemaps_data</code> management command. This is what pulls in data from the <code>www-sitemap-generator</code> git repo and refreshes the <code>SitemapURL</code> records in Bedrock's database. It is from these <code>SitemapURL</code> records that the XML sitemap tree is rendered by <code>bedrock</code>.</p>"},{"location":"testing/","title":"Front-end testing","text":"<p>Bedrock runs a suite of front-end Jasmine behavioral/unit tests, which use Jasmine Browser Runner as a test runner. We also have a suite of functional tests using Selenium and pytest. This allows us to emulate users interacting with a real browser. All these test suites live in the <code>tests</code> directory. To run the tests locally, you must also first download geckodriver and chromedriver and make it available in your system path. You can alternatively specify the path to geckodriver and chromedriver using the command line (see the pytest-selenium documentation for more information).</p> <p>The <code>tests</code> directory comprises of:</p> <ul> <li><code>/functional</code> contains pytest tests.</li> <li><code>/pages</code> contains Python page objects.</li> <li><code>/unit</code> contains the Jasmine tests and Jasmine Browser Runner config     file.</li> </ul>"},{"location":"testing/#installation","title":"Installation","text":"<p>First follow the installation instructions for bedrock, which will install the dependencies required to run the various front-end test suites.</p> <p>To download geckodriver and chromedriver and have it ready to run in your system, there are a couple of ways:</p> <ul> <li> <p>Download     geckdriver     and add it to your system path:</p> <pre><code>cd /path/to/your/downloaded/files/\nmv geckodriver /usr/local/bin/\n</code></pre> </li> <li> <p>If you're on MacOS, download geckodriver directly using Homebrew,     which automatically places it in your system path:</p> <pre><code>brew install geckodriver\n</code></pre> </li> <li> <p>Download chromedriver     and add it to your system path:</p> <pre><code>cd /path/to/your/downloaded/files/\nmv chromedriver /usr/local/bin/\n</code></pre> </li> <li> <p>If you're on MacOS, download chromedriver directly using     Homebrew/Cask, which automatically places it in your system path:</p> <pre><code>brew tap homebrew/cask\n\nbrew cask install chromedriver\n</code></pre> </li> </ul>"},{"location":"testing/#running-jasmine-tests-using-jasmine-browser-runner","title":"Running Jasmine tests using Jasmine Browser Runner","text":"<p>To perform a single run of the Jasmine test suite using Firefox and Chrome, first make sure you have both browsers installed locally, and then activate your bedrock virtual env.</p> <pre><code>$ pyenv activate bedrock\n</code></pre> <p>You can then run the tests with the following command:</p> <pre><code>$ npm run test\n</code></pre> <p>This will run all our front-end linters and formatting checks before running the Jasmine test suite. If you only want to run the tests themselves, you can run:</p> <pre><code>$ npm run test\n</code></pre> <p>See the Jasmine documentation for tips on how to write JS behavioral or unit tests. We also use Sinon for creating test spies, stubs and mocks.</p>"},{"location":"testing/#running-functional-tests","title":"Running functional tests","text":"<p>Note</p> <p>Before running the functional tests, please make sure to follow the bedrock installation docs including the database sync that is needed to pull in external data such as event/blog feeds etc. These are required for some of the tests to pass.</p> <p>To run the full functional test suite against your local bedrock instance in Mozorg mode:</p> <pre><code>$ py.test --base-url http://localhost:8000 --driver Firefox --html tests/functional/results.html tests/functional/\n</code></pre> <p>This will run all test suites found in the <code>tests/functional</code> directory and assumes you have bedrock running at <code>localhost</code> on port <code>8000</code>. Results will be reported in <code>tests/functional/results.html</code>.</p> <p>To run the full functional test suite against your local bedrock instance in Pocket mode, things are slightly different, because of the way things are set up in order to allow CI to test both Mozorg Mode and Pocket Mode at the same time. You need to define a temporary environment variable (needed by the [pocket_base_url]{.title-ref} fixture) and scope pytest to only run Pocket tests:</p> <pre><code>$ BASE_POCKET_URL=http://localhost:8000 py.test -m pocket_mode --driver Firefox --html tests/functional/results.html tests/functional/\n</code></pre> <p>This will run all test suites found in the <code>tests/functional</code> directory that have the pytest \"[mark]{.title-ref}\" of [pocket_mode]{.title-ref} and assumes you have bedrock running in Pocket mode at <code>localhost</code> on port <code>8000</code>. Results will be reported in <code>tests/functional/results.html</code>.</p> <p>Note</p> <p>If you omit the <code>--base-url</code> command line option in Mozorg mode (ie, not in Pocket mode) then a local instance of bedrock will be started, however the tests are not currently able to run against bedrock in this way.</p> <p>By default, tests will run one at a time. This is the safest way to ensure predictable results, due to bug 1230105. If you want to run tests in parallel (this should be safe when running against a deployed instance), you can add <code>-n auto</code> to the command line. Replace <code>auto</code> with an integer if you want to set the maximum number of concurrent processes.</p> <p>Note</p> <p>There are some functional tests that do not require a browser. These can take a long time to run, especially if they're not running in parallel. To skip these tests, add <code>-m 'not headless'</code> to your command line.</p> <p>To run a single test file you must tell py.test to execute a specific file e.g. <code>tests/functional/test_newsletter.py</code>:</p> <pre><code>$ py.test --base-url http://localhost:8000 --driver Firefox --html tests/functional/results.html tests/functional/firefox/new/test_download.py\n</code></pre> <p>To run a single test you can filter using the <code>-k</code> argument supplied with a keyword e.g. <code>-k test_download_button_displayed</code>:</p> <pre><code>$ py.test --base-url http://localhost:8000 --driver Firefox --html tests/functional/results.html tests/functional/firefox/new/test_download.py -k test_download_button_displayed\n</code></pre> <p>You can also easily run the tests against any bedrock environment by specifying the <code>--base-url</code> argument. For example, to run all functional tests against dev:</p> <pre><code>$ py.test --base-url https://www-dev.allizom.org --driver Firefox --html tests/functional/results.html tests/functional/\n</code></pre> <p>Note</p> <p>For the above commands to work, Firefox needs to be installed in a predictable location for your operating system. For details on how to specify the location of Firefox, or running the tests against alternative browsers, refer to the pytest-selenium documentation.</p> <p>For more information on command line options, see the pytest documentation.</p>"},{"location":"testing/#running-tests-in-sauce-labs","title":"Running tests in Sauce Labs","text":"<p>You can also run tests in Sauce Labs directly from the command line. This can be useful if you want to run tests against Internet Explorer when you're on Mac OSX, for instance.</p> <ol> <li>Sign up for an account at https://saucelabs.com/opensauce/.</li> <li>Log in and obtain your Remote Access Key from user settings.</li> <li>Run a test specifying <code>SauceLabs</code> as your driver, and pass your     credentials.</li> </ol> <p>For example, to run the home page tests using Internet Explorer via Sauce Labs:</p> <pre><code>$ SAUCELABS_USERNAME=thedude SAUCELABS_API_KEY=123456789 SAUCELABS_W3C=true SELENIUM_EXCLUDE_DEBUG=logs py.test --base-url https://www-dev.allizom.org --driver SauceLabs --capability browserName 'internet explorer' --capability platformName 'Windows 10' --html tests/functional/results.html tests/functional/test_home.py\n</code></pre>"},{"location":"testing/#writing-selenium-tests","title":"Writing Selenium tests","text":"<p>Tests usually consist of interactions and assertions. Selenium provides an API for opening pages, locating elements, interacting with elements, and obtaining state of pages and elements. To improve readability and maintainability of the tests, we use the Page Object model, which means each page we test has an object that represents the actions and states that are needed for testing.</p> <p>Well written page objects should allow your test to contain simple interactions and assertions as shown in the following example:</p> <pre><code>def test_sign_up_for_newsletter(base_url, selenium):\n    page = NewsletterPage(base_url, selenium).open()\n    page.type_email('noreply@mozilla.com')\n    page.accept_privacy_policy()\n    page.click_sign_me_up()\n    assert page.sign_up_successful\n</code></pre> <p>It's important to keep assertions in your tests and not your page objects, and to limit the amount of logic in your page objects. This will ensure your tests all start with a known state, and any deviations from this expected state will be highlighted as potential regressions. Ideally, when tests break due to a change in bedrock, only the page objects will need updating. This can often be due to an element needing to be located in a different way.</p> <p>Please take some time to read over the Selenium documentation for details on the Python client API.</p>"},{"location":"testing/#destructive-tests","title":"Destructive tests","text":"<p>By default all tests are assumed to be destructive, which means they will be skipped if they're run against a sensitive environment. This prevents accidentally running tests that create, modify, or delete data on the application under test. If your test is nondestructive you will need to apply the <code>nondestructive</code> marker to it. A simple example is shown below, however you can also read the pytest markers documentation for more options.</p> <pre><code>import pytest\n\n@pytest.mark.nondestructive\ndef test_newsletter_default_values(base_url, selenium):\n    page = NewsletterPage(base_url, selenium).open()\n    assert '' == page.email\n    assert 'United States' == page.country\n    assert 'English' == page.language\n    assert page.html_format_selected\n    assert not page.text_format_selected\n    assert not page.privacy_policy_accepted\n</code></pre>"},{"location":"testing/#smoke-tests","title":"Smoke tests","text":"<p>Smoke tests are considered to be our most critical tests that must pass in a wide range of web browsers, including Internet Explorer 11. The number of smoke tests we run should be enough to cover our most critical pages where legacy browser support is important.</p> <pre><code>import pytest\n\n@pytest.mark.smoke\n@pytest.mark.nondestructive\ndef test_download_button_displayed(base_url, selenium):\n    page = DownloadPage(selenium, base_url, params='').open()\n    assert page.is_download_button_displayed\n</code></pre> <p>You can run smoke tests only by adding <code>-m smoke</code> when running the test suite on the command line.</p>"},{"location":"testing/#waits-and-expected-conditions","title":"Waits and Expected Conditions","text":"<p>Often an interaction with a page will cause a visible response. While Selenium does its best to wait for any page loads to be complete, it's never going to be as good as you at knowing when to allow the test to continue. For this reason, you will need to write explicit waits in your page objects. These repeatedly execute code (a condition) until the condition returns true. The following example is probably the most commonly used, and will wait until an element is considered displayed:</p> <pre><code>from selenium.webdriver.support import expected_conditions as expected\nfrom selenium.webdriver.support.ui import WebDriverWait as Wait\n\nWait(selenium, timeout=10).until(\n    expected.visibility_of_element_located(By.ID, 'my_element'))\n</code></pre> <p>For convenience, the Selenium project offers some basic expected conditions, which can be used for the most common cases.</p>"},{"location":"testing/#debugging-selenium","title":"Debugging Selenium","text":"<p>Debug information is collected on failure and added to the HTML report referenced by the <code>--html</code> argument. You can enable debug information for all tests by setting the <code>SELENIUM_CAPTURE_DEBUG</code> environment variable to <code>always</code>.</p>"},{"location":"testing/#guidelines-for-writing-functional-tests","title":"Guidelines for writing functional tests","text":"<ul> <li>Try and keep tests organized and cleanly separated. Each page should     have its own page object and test file, and each test should be     responsible for a specific purpose, or component of a page.</li> <li>Avoid using sleeps - always use waits as mentioned above.</li> <li>Don't make tests overly specific. If a test keeps failing because     of generic changes to a page such as an image filename or <code>href</code>     being updated, then the test is probably too specific.</li> <li>Avoid string checking as tests may break if strings are updated, or     could change depending on the page locale.</li> <li>When writing tests, try and run them against a staging or demo     environment in addition to local testing. It's also worth running     tests a few times to identify any intermittent failures that may     need additional waits.</li> </ul> <p>See also the Web QA style guide for Python based testing.</p>"},{"location":"testing/#testing-basket-email-forms","title":"Testing Basket email forms","text":"<p>When writing functional tests for front-end email newsletter forms that submit to Basket, we have some special case email addresses that can be used just for testing:</p> <ol> <li>Any newsletter subscription request using the email address     \"success@example.com\" will always return success from the basket     client.</li> <li>Any newsletter subscription request using the email address     \"failure@example.com\" will always raise an exception from the     basket client.</li> </ol> <p>Using the above email addresses enables newsletter form testing without actually hitting the Basket instance, which reduces automated newsletter spam and improves test reliability due to any potential network flakiness.</p>"},{"location":"testing/#headless-tests","title":"Headless tests","text":"<p>There are targeted headless tests for the download pages. These tests and are run as part of the pipeline to ensure that download links constructed via product details are well formed and return valid 200 responses.</p>"},{"location":"uitour/","title":"Mozilla.UITour","text":""},{"location":"uitour/#introduction","title":"Introduction","text":"<p><code>Mozilla.UITour</code> is a JS library that exposes an event-based Web API for communicating with the Firefox browser chrome. It can be used for tasks such as opening menu panels, highlighting buttons, or querying Mozilla account signed-in state. It is supported in Firefox 29 onward, but some API calls are only supported in later versions.</p> <p>For security reasons <code>Mozilla.UITour</code> will only work on white-listed domains and over a secure connection. The list of allowed origins can be found here: https://searchfox.org/mozilla-central/source/browser/app/permissions</p> <p>The <code>Mozilla.UITour</code> library is maintained on Mozilla Central.</p> <p>Important</p> <p>The API is supported only on the desktop versions of Firefox. It doesn't work on Firefox for Android and iOS.</p>"},{"location":"uitour/#local-development","title":"Local development","text":"<p>To develop or test using Mozilla.UITour locally you need to create some custom preferences in <code>about:config</code>.</p> <ul> <li><code>browser.uitour.testingOrigins</code> (string) (value: local address e.g.     <code>http://127.0.0.1:8000</code>)</li> <li><code>browser.uitour.requireSecure</code> (boolean) (value: <code>false</code>)</li> </ul> <p>Note that <code>browser.uitour.testingOrigins</code> can be a comma separated list of domains, e.g.</p> <p>'http://127.0.0.1:8000, https://www-demo2.allizom.org'</p> <p>Important</p> <p>Prior to Firefox 36, the testing preference was called <code>browser.uitour.whitelist.add.testing</code> (Bug 1081772). This old preference does not accept a comma separated list of domains, and you must also exclude the domain protocol e.g. <code>https://</code>. A browser restart is also required after adding an allowed domain.</p> <p>If you are working on Mozilla accounts integration, you can use the <code>identity.fxaccounts.autoconfig.uri</code> config property to change the Accounts server. For example, to change it to stage environment use this value: <code>https://accounts.stage.mozaws.net/</code>. Restart the browser and make sure the configuration updated. <code>identity.fxaccounts.remote.root</code> preference should now point to <code>https://accounts.stage.mozaws.net</code>. If it has not changed for some reason, update it manually. Ref: https://mozilla-services.readthedocs.io/en/latest/howtos/run-fxa.html</p>"},{"location":"uitour/#javascript-api","title":"JavaScript API","text":"<p>The UITour API documentation can be found in the Mozilla Source Tree Docs.</p>"},{"location":"vpn-subscriptions/","title":"Mozilla VPN Subscriptions","text":"<p>The Mozilla VPN landing page displays both pricing and currency information that is dependant on someone's physical location in the world (using geo-location). If someone is in the United States, they should see pricing in $USD, and if someone is in Germany they should see pricing in Euros. The page is also available in multiple languages, which can be viewed independently of someone's physical location. So someone who lives in Switzerland, but is viewing the page in German, should still see pricing and currency displayed in Swiss Francs (CHF).</p> <p>Additionally, it is important that we render location specific subscription links, as purchasing requires a credit card that is registered to each country where we have a plan available. We are also legally obligated to prevent both purchasing and/or downloading of Mozilla VPN in certain countries. In countries where VPN is not yet available, we also rely on geo-location to hide subscription links, and instead to display a call to action to encourage prospective customers to sign up to the VPN wait list.</p> <p>To facilitate all of the above, we rely on our CDN to return an appropriate country code that relates to where a visitor's request originated from (see Geo Template View). We use that country code in our helpers and view logic for the VPN landing page to decide what to display in the pricing section of the page (see Mozilla VPN links).</p>"},{"location":"vpn-subscriptions/#server-architecture","title":"Server architecture","text":"<p>Bedrock is configured so that when <code>dev=True</code>, VPN subscription links will point to the Mozilla accounts staging environment. When <code>dev=False</code>, they will point to the Fxa production environment.</p> <p>So our different environments are mapped like so:</p> <ul> <li><code>http://localhost:8000</code> -&gt; <code>https://accounts.stage.mozaws.net/</code></li> <li><code>https://www-dev.allizom.org/products/vpn/</code> -&gt;     <code>https://accounts.stage.mozaws.net/</code></li> <li><code>https://www.allizom.or/products/vpn/</code> -&gt;     <code>https://accounts.firefox.com/</code></li> <li><code>https://www.mozilla.org/products/vpn</code> -&gt;     <code>https://accounts.firefox.com/</code></li> </ul> <p>This allows the product and QA teams to routinely test changes and new VPN client releases on https://www-dev.allizom.org/products/vpn/, prior to being available in production.</p>"},{"location":"vpn-subscriptions/#adding-new-countries-for-vpn","title":"Adding new countries for VPN","text":"<p>When launching VPN in new countries there is a set process to follow.</p>"},{"location":"vpn-subscriptions/#launch-steps","title":"Launch steps","text":"<ol> <li>All the code changes below should be added behind a feature     switch.</li> <li>Once the PR is reviewed and merged, the product QA team should be     notified and they can then perform testing on     https://www-dev.allizom.org/products/vpn/. Often the QA team will     request a date for code to be ready for testing to begin.</li> <li>Code can be pushed to production ahead of time (but will be disabled     behind the feature switch by default).</li> <li>Once QA gives the green light on launch day, the feature switch can     then be enabled in production.</li> <li>QA will then do a final round of post-launch QA to verify     subscriptions / purchasing works in the new countries in production.</li> </ol>"},{"location":"vpn-subscriptions/#code-changes","title":"Code changes","text":"<p>Reference: officially assigned list of ISO country codes. Reference: list of ISO 4217 currency codes`</p> <p>The majority of config changes need to happen in <code>bedrock/settings/base.py</code>:</p> <ol> <li> <p>Add new pricing plan configs to <code>VPN_PLAN_ID_MATRIX</code> for any new     countries that require newly created plan IDs (these will be     provided by the VPN team). Separate plan IDs for both dev and prod     are required for each new currency / language combination (this is     because the product QA team need differently configured plans on dev     to routinely test things like renewal and cancellation flows). Meta     data such as price, total price and saving for each plan / currency     should also be provided.</p> <p>Example pricing plan config for $USD / English containing both 12-month and monthly plans:</p> <pre><code>VPN_PLAN_ID_MATRIX = {\n    \"usd\": {\n        \"en\": {\n            \"12-month\": {\n                \"id\": \"price_1J0Y1iKb9q6OnNsLXwdOFgDr\" if DEV else \"price_1Iw85dJNcmPzuWtRyhMDdtM7\",\n                \"price\": \"US$4.99\",\n                \"total\": \"US$59.88\",\n                \"saving\": 50,\n                \"analytics\": {\"brand\": \"vpn\", \"plan\": \"vpn\", \"currency\": \"USD\", \"discount\": \"60.00\", \"price\": \"59.88\", \"period\": \"yearly\"},\n            },\n            \"monthly\": {\n                \"id\": \"price_1J0owvKb9q6OnNsLExNhEDXm\" if DEV else \"price_1Iw7qSJNcmPzuWtRMUZpOwLm\",\n                \"price\": \"US$9.99\",\n                \"total\": None,\n                \"saving\": None,\n                \"analytics\": {\"brand\": \"vpn\", \"plan\": \"vpn\", \"currency\": \"USD\", \"discount\": \"0\", \"price\": \"9.99\", \"period\": \"monthly\"},\n            },\n        }\n    },\n    # repeat for other currency / language configs.\n}\n</code></pre> <p>See the Begin Checkout section of the analytics docs for more a detailed description of what should be in the analytics objects.</p> </li> <li> <p>Map each new country code to one or more applicable pricing plans in     <code>VPN_VARIABLE_PRICING</code>.</p> <p>Example that maps the <code>US</code> country code to the pricing plan config above:</p> <pre><code>VPN_VARIABLE_PRICING = {\n    \"US\": {\n        \"default\": VPN_PLAN_ID_MATRIX[\"usd\"][\"en\"],\n    },\n    # repeat for other country codes.\n}\n</code></pre> </li> <li> <p>Once every new country has a mapping to a pricing plan, add each new     country code to the list of supported countries in     <code>VPN_COUNTRY_CODES</code>. Because new countries need to be added behind a     feature switch, you may want to create a new variable temporarily     for this until launched, such as <code>VPN_COUNTRY_CODES_WAVE_VI</code>. You     can then add these to <code>VPN_COUNTRY_CODES</code> in <code>products/views.py</code>     using a simple function like so:</p> <pre><code>def vpn_available(request):\n    country = get_country_from_request(request)\n    country_list = settings.VPN_COUNTRY_CODES\n\n    if switch(\"vpn-wave-vi\"):\n        country_list = settings.VPN_COUNTRY_CODES + settings.VPN_COUNTRY_CODES_WAVE_VI\n\n    return country in country_list\n</code></pre> <p>The function could then be used in the landing page view like so:</p> <pre><code>vpn_available_in_country = vpn_available(request),\n</code></pre> </li> <li> <p>If you now test the landing page locally, you should hopefully see     the newly added pricing for each new country (add the     <code>?geo=[INSERT_COUNTRY_CODE]</code> param to the page URL to mock each     country). If all is well, this is the perfect time to add new unit     tests     for each new country. This will help give you confidence that the     right plan ID is displayed for each new country / language option.</p> <pre><code>def test_vpn_subscribe_link_variable_12_month_us_en(self):\n\"\"\"Should contain expected 12-month plan ID (US / en-US)\"\"\"\n    markup = self._render(\n        plan=\"12-month\",\n        country_code=\"US\",\n        lang=\"en-US\",\n    )\n    self.assertIn(\"?plan=price_1Iw85dJNcmPzuWtRyhMDdtM7\", markup)\n\ndef test_vpn_subscribe_link_variable_monthly_us_en(self):\n\"\"\"Should contain expected monthly plan ID (US / en-US)\"\"\"\n    markup = self._render(\n        plan=\"monthly\",\n        country_code=\"US\",\n        lang=\"en-US\",\n    )\n    self.assertIn(\"?plan=price_1Iw7qSJNcmPzuWtRMUZpOwLm\", markup)\n</code></pre> </li> <li> <p>Next, update <code>VPN_AVAILABLE_COUNTRIES</code> to the new total number of     countries where VPN is available. Again, because this needs to be     behind a feature switch you may want a new temporary variable that     you can use in <code>products/views.py</code>:</p> <pre><code>available_countries = settings.VPN_AVAILABLE_COUNTRIES\n\nif switch(\"vpn-wave-vi\"):\n    available_countries = settings.VPN_AVAILABLE_COUNTRIES_WAVE_VI\n</code></pre> </li> <li> <p>Finally, there is also a string in <code>l10n/en/products/vpn/shared.ftl</code>     that needs updating to include the new countries. This should be a     new string ID, and behind a feature switch in the template:</p> <pre><code>vpn-shared-available-countries-v6 = We currently offer { -brand-name-mozilla-vpn } in Austria, Belgium, Canada, Finland, France, Germany, Ireland, Italy, Malaysia, the Netherlands, New Zealand, Singapore, Spain, Sweden, Switzerland, the UK, and the US.\n</code></pre> <pre><code>{% if switch('vpn_wave_vi') %}\n{{ ftl('vpn-shared-available-countries-v6', fallback='vpn-shared-available-countries-v5') }}\n{% else %}\n{{ ftl('vpn-shared-available-countries-v5') }}\n{% endif %}\n</code></pre> </li> <li> <p>After things are launched in production and QA has verified that all     is well, don't forget to file an issue to tidy up the temporary     variables and switch logic.</p> </li> </ol>"},{"location":"vpn-subscriptions/#excluded-countries","title":"Excluded countries","text":"<p>For a list of country codes where we are legally obligated to prevent purchasing VPN, see <code>VPN_EXCLUDED_COUNTRY_CODES</code> in <code>bedrock/settings/base.py</code>.</p> <p>For a list of country codes where we are also required to prevent downloading the VPN client, see <code>VPN_BLOCK_DOWNLOAD_COUNTRY_CODES</code>.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/","title":"1. Record architecture decisions","text":"<p>Date: 2019-01-07</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#context","title":"Context","text":"<p>We need to record the architectural decisions made on this project.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#decision","title":"Decision","text":"<p>We will use Architecture Decision Records, as described by Michael Nygard.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#consequences","title":"Consequences","text":"<p>See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools.</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/","title":"2. Move CI/CD Pipelines to Gitlab","text":"<p>Date: 2019-10-09</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#status","title":"Status","text":"<p>Superseded by 0010</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#context","title":"Context","text":"<p>Our current CI/CD pipelines are implemented in Jenkins. We would like to decommission our Jenkins server by the end of this year. We have implemented CI/CD pipelines using Gitlab in other projects, including basket, nucleus and the snippets-service.</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#decision","title":"Decision","text":"<p>We will move our existing CI/CD pipeline implementation from Jenkins to Gitlab.</p>"},{"location":"architecture/decisions/0002-move-ci-cd-pipelines-to-gitlab/#consequences","title":"Consequences","text":"<p>We will continue to use www-config to version control our Kubernetes yaml files, but we will replace the use of git-sync-operator and its branch with self-managed instances of gitlab runner executing jobs defined in a new .gitlab-ci.yml file leveraging what we have learned implementing similar solutions in nucleus-config, basket-config, and snippets-config. We will also eliminate our last dependency on Deis Workflow, which we have been using for dynamic demo deployments based on the branch name, in favor of a fixed number of pre-configured demo deployments, potentially supplemented by Heroku Review Apps.</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/","title":"3. Use Cloudflare Workers and Convert for multi-variant testing","text":"<p>Date: 2019-10-09</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#context","title":"Context","text":"<p>Our current method for implementing multi-variant tests involves frequent, often non-trivial code changes to our most high traffic download pages. Prioritizing and running concurrent experiments on such pages is also often complex, increasing the risk of accidental breakage and making longer-term changes harder to roll out. Our current tool, Traffic Cop, also requires significant custom code to accomodate these types of situations. Accurately measuring and reporting on the outcome of experiments is also a time consuming step of the process for our data science team, often requiring custom instrumentation and analysis.</p> <p>We would like to make our end-to-end experimentation process faster, with increased capacity, whilst also minimizing the performance impact and volume of code churn related to experiments running on our most important web pages.</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#decision","title":"Decision","text":"<p>We will use Cloudflare Workers to redirect a small percentage of traffic to standalone, experimental versions of our download pages. The worker code will live in the www-workers repository. We will implement a (vetted and approved) third-party experimentation tool called Convert for use on those experimental pages.</p>"},{"location":"architecture/decisions/0003-use-cloudflare-workers-and-convert-for-multi-variant-testing/#consequences","title":"Consequences","text":"<p>Convert experiment code will be separated from our main web pages, where the vast majority of our traffic is routed. This will minimize code churn on our most important pages, and also reduce the performance impact and risks involved in using a third-party experimentation tool. Using Cloudflare Workers to redirect traffic to experimental pages also has significant performance benefits over handling redirection client-side.</p> <p>In terms of features, Convert offers a custom dashboard for configuring, prioritizing, and running multi-variant tests. It also has built-in analysis and reporting tools, which are all areas where we hope to see significant savings in time and resources.</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/","title":"4. Use Fluent For Localization","text":"<p>Date: 2019-12-16</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#context","title":"Context","text":"<p>The current localization (l10n) system uses the outdated and unsupported .lang format, which our l10n team would prefer to no longer support. Mozilla's current l10n standard for products and websites is Fluent.</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#decision","title":"Decision","text":"<p>In order to update our l10n practices and technology and support from Mozilla's existing l10n infrastructure and teams we will decomission the .lang system in bedrock and implement one based on Fluent. We will support both during a transition period.</p>"},{"location":"architecture/decisions/0004-use-fluent-for-localization/#consequences","title":"Consequences","text":"<p>Dealing with strings and templates is very different in Fluent (see the updated bedrock docs). There will be a period of developer training and adjustment to the new way of writing and previewing templates. The biggest change is that strings are no longer in the templates at all, and are instead referenced by string IDs which are in Fluent files (.ftl files).</p> <p>The positive side of this change is that the developer has total control over the strings in the translation files and there are no string extraction or merge steps.</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/","title":"5. Use a Single Docker Image For All Deployments","text":"<p>Date: 2020-07-07</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#context","title":"Context","text":"<p>We currently build an individual docker image for each deployment (dev, stage, and prod) that contains the proper data for that environment. It would save time and testing if we only built a single image that could be promoted to each environment and loaded with the proper data at startup.</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#decision","title":"Decision","text":"<p>We will use a Kubernetes DaemonSet to ensure that a data updater pod is running on each node in a cluster. This pod will keep the database and l10n files updated in a volume that will be used by the other bedrock pods to access the data.</p> <p>GitHub issue</p>"},{"location":"architecture/decisions/0005-use-a-single-docker-image-for-all-deployments/#consequences","title":"Consequences","text":"<p>This change means that bedrock will be more simple to run because each pod will no longer need to be responsible for keeping its data updated, and so it will run only the bedrock web process and not also the updater daemon. It also means that there is a risk of a bedrock pod being run on a node that hasn't had the updater pod run yet, so there would be no available data. We will handle this by ensuring that bedrock won't start when the data isn't available, and so k8s will not send traffic to those pods until they're successfully up and responding, and will keep trying to start pods on the node untill they succeed.</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/","title":"6. Revise tooling for Python dependency management","text":"<p>Date: 2022-02-25</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#status","title":"Status","text":"<p>Superseded by 0007, but the context in this ADR is still useful</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#context","title":"Context","text":"<p>At the moment of revisiting our dependency-management approach, Bedrock's Python dependencies were installed from a hand-cut <code>requirements/*.txt</code> files which (sensibly) included hashes so that we could be sure about what our Python package installer, <code>pip</code>, was actually installing.</p> <p>However, this process was onerous: * We had a number of requirements files, <code>base</code>, <code>prod</code>, <code>dev</code>, <code>migration</code> (no longer required but still being processed at installation time) and <code>docs</code> - all of which had to be hand-maintained. * Hashes needed to be generated when adding/updating a dependency. This was done with a specific tool <code>hashin</code> and needed to be done for each requirement. * When <code>pip</code> detects hashes in a requirements file, it automatically requires hashes for all packages it installs, including subdependencies of dependecies mentioned in <code>requirements/*.txt</code>. This in turn meant that adding or updating a new dep often required hashing-in one or more subdeps -- and at worst, a change or niggle with <code>pip</code> would result in a new subdep being implicitly required, which would then fail to install because it was not hashed in to the requirements file.</p> <p>Other projects (both within MEAO and across Mozilla) used more sophisticated dependency management tools, including: * <code>pip-tools</code> - which draws reqs from an input file and generates a requirements.txt complete with hashes * <code>pip-compile-multi</code> - which extends pip-tools' behaviour to support multiple output files and shared input files * <code>poetry</code> - which combines a lockfile approach with a standalone virtual environment * <code>pipenv</code> - which similarly combines a lockfile with a virtual environment * <code>conda</code> - a language-agnostic package manager and environment management system * simply <code>pip</code></p> <p>The ideal solution would support all of the following: * Simple input file format/syntax * Ability to pin dependencies * Support for installing with hash-checking of packages * Automatic hashing of requirements, rather than having to manually do it with <code>hashin</code> et al. * Support for multiple build configurations (eg prod, dev, docs) * Dependabot compatibility, so we still get alerts and updates * An unopinionated approach to virtualenvs \u2013 can work with and without them, so that developers can use the virtualenv tooling they prefer and we don't have to use a virtualenv in our containers if we don't want to * Sufficiently active maintenance of the project * Use/knowledge of the tooling elsewhere in the broader organisation</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#decision","title":"Decision","text":"<p>After evaluating the above, including <code>pip-tools</code>, <code>pip-compile-multi</code> and <code>poetry</code> in greater depth, <code>pip-compile-multi</code> was selected.</p> <p>Significant factors were how allows us to pin our top-level dependencies in a clutter-free input format, supports inheritance between files and miltiple output files with ease, and it automatically generates hashes for subdependencies.</p>"},{"location":"architecture/decisions/0006-revise-tooling-for-python-dependency-management/#consequences","title":"Consequences","text":"<p><code>pip-compile-multi</code> has been easily integrated into the Bedrock workflow, but there is one non-trivial downside: Github's Dependabot service does not play well with the combination of multiple requirements files and inheritance between them. As such, does not currently produce reliable updates (either partial updates or some requirements files seem to be ignored entirely). See https://github.com/dependabot/dependabot-core/issues/536</p> <p>Strictly, though, we don't need the convenience of Dependabot - we have a <code>make</code> command to identify stale deps and recompiling is another, single, <code>make</code> command. Also, we're more likely to compile a bunch of Dependabot PRs into one changeset (eg with <code>paul-mclendahand</code>), than to merge them straight to <code>master</code>/<code>main</code> one at at time. As long as we're getting Github security alerts for vulnerable dependencies, we'll be OK.</p> <p>That said, if we did find we needed Dependabot compatibility, <code>pip-tools</code> and some extra legwork in the Makefile to deal with prod, dev and docs deps separately would likely be a viable alternative.</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/","title":"7. Further revise tooling for Python dependency management","text":"<p>Date: 2022-03-02</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#status","title":"Status","text":"<p>Proposed</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#context","title":"Context","text":"<p>While pip-compile-multi gave us plenty fot benefits (see ADR 0006) the lack of Dependabot support was an annoyance and replacing it with alternatives seemed fairly involved.</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#decision","title":"Decision","text":"<p>We've downgraded to regular <code>pip-compile</code> and instead are doing the extra legwork in the Makefile instead. The input files are indentical, so we do not need to pin sub-dependencies, and we still get automatic hash generation for all packages.</p>"},{"location":"architecture/decisions/0007-further-revise-tooling-for-python-dependency-management/#consequences","title":"Consequences","text":"<p>There should be no downsides to switching away from pip-compile-multi in this context. If Dependabot still does not manage to parse our multiple requirements files, we should look to renaming them in case that tips the balance (as has been suggested by a colleague)</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/","title":"8. Move Demos To GCP","text":"<p>Date: 2022-07-14</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#context","title":"Context","text":"<p>Previously, demos for Bedrock were run on Heroku. This worked fine, but Heroku's recent security incident there meant our integration had to be disabled, prompting discussion of self-managed demo instances.</p> <p>In addition, while it was possible to demo Bedrock in Pocket Mode on Heroku, by amending the settings via the Heroku web UI, the domains set up (www-demoX.allizom.org) were originally set up for Mozorg, and as such may be confusing for colleagues reviewing Pocket changes. Flipping and un-flipping settings in Heroku to enable Mozorg Mode or Pocket Mode was also extra legwork that we ideally would do without, too.</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#decision","title":"Decision","text":"<p>We have implemented a new, self-managed, approach to running demos, using a handful of Google Cloud Platform services. Cloud Build and Cloud Run are the most significant ones.</p> <p>Cloud Build has triggers which monitor pushes to specific branches, then builds a Bedrock container from the branch, using the appropriate env vars for Pocket or Mozorg use, including the SITE_MODE env var that specifies the mode Bedrock runs in.</p> <p>Cloud Run then deploys the built container as a 'serverless' webapp. By default, supervisord runs in the container, so it updates DB and L10N files automatically.</p> <p>This process is triggered by a simple push to a specific target branch. e.g. pushing code to mozorg-demo-2 will result in the relevant code being deployed in Mozorg mode to www-demo2.allizom.org, while pushing to pocket-demo-4 will deploy it to www-demo4.tekcopteg.com in Pocket mode.</p> <p>Environment variables can also be configured by developers, via two dedicated env files in the Bedrock codebase, which are only used for demo services. Clashes are unlikely, and can still be managed with common sense.</p>"},{"location":"architecture/decisions/0008-move-demos-to-gcp/#consequences","title":"Consequences","text":"<p>Upsides:</p> <p>It is now easier to stand up Pocket demos in addition to existing Mozorg demos, plus we have full control over the infrastructure our demos are run on.</p> <p>We will no longer need to use Heroku for demos. In the future, we may also be able to support ad-hoc 'review apps', which we have also used Heroku for in the past.</p> <p>Downsides:</p> <p>1) If a new secret value is required on a demo instance, and so that value cannot go into the demo env vars file because our codebase is public, some SRE-like devops is needed to add that secret value to GCP's Secret Manager Service. This can be quick, but requires understanding how that side fits together, plus access, so may need a backender to add them.</p> <p>2) At the moment, only the MEAO Backend team have GCP access, which is handy to monitor whether a demo has successfull be pushed out, or to amend secrets, etc. Both of these issues can be addressed without a lot of work.</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/","title":"9. Manage Contentful schema state via migrations","text":"<p>Date: 2022-09-09</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#context","title":"Context","text":"<p>Our chosen CMS Contentful is powerful and can be configured via its UI  quite easily. However, wanted to bring this under control using migrations so that changes are explicit, reviewable, repeatable and stored. This would be a key part of moving to a \"CMS-as-Code\" approach to using Contentful, where content-type changes and data migrations (outside of regular content entry) are managed via code.</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#decision","title":"Decision","text":"<p>We wanted to have as close as possible to the experience provided by the excellent Django Migrations framework, where we would: * be able to script migrations, rather than resort to \"clickops\" * be able to apply them individually or en masse * be able to store the state of which migrations have/have not been applied in a central datastore (and ideally Contentful)</p> <p>We experimented with hand-cutting our own framework, which was looking viable, but then we came across https://github.com/jungvonmatt/contentful-migrations which does all of the above. We've evaluated it and it seems fit for purpose, even if it has some gaps, so we've adopted it as our current way to manage and apply migrations to our Contentful setup.</p>"},{"location":"architecture/decisions/0009-use-manage-contentful-migrations/#consequences","title":"Consequences","text":"<p>We've gained a tool that enables code-based changes to Contentful, which helps in two ways: 1) It enables and eases the initial work to migrate from Legacy Compose to new Compose (these are both ways of structuring pages in Contentful) 2) It lays tracks for moving to CMS-as-Code</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/","title":"10. Move CI to Github Actions for Unit and Integration tests","text":"<p>Date: 2023-04-06</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#context","title":"Context","text":"<p>Prior to this work, Bedrock's CI/CD pipeline involved Github, Gitlab and CircleCI. We were mirroring from Github to Gitlab to benefit from Gitlab's CI tooling for our functional integration tests, including private (i.e. Mozilla-managed) runners.</p> <p>Additionally, we were using a third party (CircleCI) to run our Python and JS unit tests.</p> <p>Since then, two things have changed:</p> <ol> <li>Github Actions (GHA) have arrived</li> <li>We are now able to use private runners with GHA</li> </ol>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#decision","title":"Decision","text":"<p>We will move our CI/CD pipeline from being a combination of Github + Gitlab + CircleCI to just Github, using GHA.</p> <p>This will mean:</p> <ol> <li>The mirroring to Gitlab will no longer be necessary.</li> <li>Unit tests move from CircleCI to GHA. They will continue to be run on every PR raised against <code>mozilla/bedrock</code>.</li> <li>Functional/integration tests move from Gitlab to GHA. They will still be triggered by a successful deployment to dev/test/stage/prod.</li> </ol> <p>This work will be carried out in parallel with changes to how our deployment pipeline works, as that side is also being moved out of Gitlab and into GHA + GCP. When a deployment succeeds, a GHA in the deployment repo will trigger a GHA in <code>mozilla/bedrock</code>, which will then run the functional integration tests.</p>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#consequences","title":"Consequences","text":""},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#pros","title":"Pros","text":"<ul> <li>We're no longer mirroring from Github to Gitlab, which will make understanding the deployment pipeline easier for new (and current) developers</li> <li>We will no longer have Gitlab in our pipeline, removing a potential point of failure that could block releases</li> <li>We can still use private runners for our functional integration tests and more (just via GHA instead of Gitlab), giving us control over security and machine resource spec</li> </ul>"},{"location":"architecture/decisions/0010-move-ci-cd-to-github-actions/#cons","title":"Cons","text":"<ul> <li>There's a risk that there will still be new race conditions or CI kick-off failures if the webhook from the deployment repo to mozilla/bedrock fails.</li> <li>We will not all get visibility of a failed webhook ping from the deployment repo's GHA, because that's locked down to be private. We can mitigate this risk with a sensible pattern of Slack notifications (e.g. Start, Success, Failure), so a missing notification will itself be a significant thing.</li> </ul>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/","title":"11. Use StatsD for metrics collection","text":"<p>Date: 2023-05-19</p>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#context","title":"Context","text":"<p>We need to implement a metrics collection solution to gain insights into the performance and behavior of bedrock. Metrics play a crucial role in understanding system health, identifying bottlenecks, and making informed decisions for optimization and troubleshooting.</p>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#decision","title":"Decision","text":"<p>StatsD is a proven open-source solution that provides a lightweight and scalable approach to capturing, aggregating, and visualizing application metrics. It offers numerous benefits that align with bedrock's needs:</p> <ol> <li> <p>Simplicity and Ease of Integration: StatsD is easy to install and integrate into our existing Python codebase. It provides a simple API that allows us to instrument our code and send metrics with minimal effort.</p> </li> <li> <p>Aggregation and Sampling: StatsD supports various aggregation methods, such as sum, average, maximum, and minimum, which can be applied to collected metrics. Additionally, it provides built-in support for sampling, allowing us to reduce the volume of metrics collected while still maintaining statistical significance.</p> </li> <li> <p>Scalability: StatsD is designed to handle high volumes of metrics and can easily scale horizontally to accommodate increasing demands. It relies on a fire-and-forget mechanism, where the metrics are sent asynchronously, ensuring minimal impact on the performance of our application.</p> </li> <li> <p>Integration with Monitoring and Visualization Tools: At Mozilla we already have a stack available and configured by SRE that uses StatsD along with Telegraf to send metrics to Grafana for visualization and monitoring. This integration will enable us to analyze and visualize our metrics, create dashboards, and set up alerts for critical system thresholds.</p> </li> </ol>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#overview-of-how-statsd-telegraf-and-grafana-work-together","title":"Overview of how StatsD, Telegraf, and Grafana work together.","text":"<p>Here's an overview of how these tools fit into the workflow:</p> <ul> <li>StatsD:   StatsD is responsible for collecting and aggregating metrics data within the application.  It   provides a simple API that allows us to instrument our code and send metrics to a StatsD server.   StatsD operates over UDP and uses a lightweight protocol for sending metrics.</li> <li>Telegraf:   Telegraf is an agent-based data collection tool that can receive metrics from various sources,   including StatsD. Telegraf acts as an intermediary between the data source (StatsD) and the data   visualization tool (Grafana). It can collect, process, and forward metrics data to different   destinations.</li> <li>Grafana:   Grafana is a popular open-source data visualization and monitoring tool. It provides a rich set of   features for creating dashboards, visualizing metrics, and setting up alerts. Grafana can connect   to Telegraf to retrieve metrics data and display it in a user-friendly and customizable manner.</li> </ul>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#consequences","title":"Consequences","text":"<ol> <li> <p>Metrics Design and Instrumentation: Proper metrics design and instrumentation are crucial to deriving meaningful insights. We need to invest time and effort in identifying the key metrics to capture and strategically instrument our codebase to provide actionable data for analysis.</p> </li> <li> <p>Operational Overhead: Introducing a new tool requires additional operational effort for monitoring, maintaining, and scaling the StatsD infrastructure. However, since this infrastructure is in use currently by other projects within Mozilla, this overhead is already being assumed and is spread out across projects.</p> </li> <li> <p>Integration Effort: While integrating StatsD into bedrock is relatively straightforward, we will need to allocate development time to instrument our codebase and ensure that metrics are captured at relevant points within the application.</p> </li> </ol>"},{"location":"architecture/decisions/0011-use-statsd-for-metrics-collection/#considerations-and-best-practices-for-metrics-design","title":"Considerations and best practices for metrics design","text":"<ul> <li>Identify Key Metrics:   Identify the key aspects of our website that we want to monitor and measure. These could include   response times, error rates, database query performance, and cache hit ratios.</li> <li>Granularity and Context:   Determine the appropriate level of granularity for our metrics. We can choose to measure metrics   at the application level, specific Django views, individual API endpoints, or even down to   specific functions or code blocks within bedrock.</li> <li>Define Consistent Metric Names:   Choose meaningful and consistent names for our metrics. This helps in easily understanding and   interpreting the collected data.</li> <li>Timing Metrics:   Use timing metrics to measure the duration of specific operations. This can include measuring the   time taken to render a template, execute a database query, or process a request.  StatsD provides   a timing metric type that captures the duration and calculates statistics such as average,   maximum, and minimum durations.</li> <li>Counting Metrics:   Use counting metrics to track occurrences of specific events. This can include counting the number   of requests received or the number of errors encountered. StatsD supports counting metric types   that increments a value each time an event occurs.</li> <li>Sampling:   Consider implementing sampling to reduce the number of metrics collected while still maintaining   statistical significance. We can selectively sample a subset of requests or events to ensure a   representative sample of data for analysis if a particular metric is of high volume.</li> <li>Re-evaluate often:   Continuously evaluate our metrics and refine them based on changing requirements and insights   gained from analysis.</li> </ul>"},{"location":"attribution/0001-analytics/","title":"Mozorg analytics","text":""},{"location":"attribution/0001-analytics/#google-tag-manager-gtm","title":"Google Tag Manager (GTM)","text":"<p>In mozorg mode, bedrock uses Google Tag Manager (GTM) to manage and organize its Google Analytics solution.</p> <p>GTM is a tag management system that allows for easy implementation of Google Analytics (GA) tags and other 3rd party marketing tags in a nice GUI experience. Tags can be added, updated, or removed directly from the GUI. GTM allows for a \"one source of truth\" approach to managing an analytics solution in that all analytics tracking can be inside GTM.</p> <p>Bedrock's GTM solution is CSP compliant and does not allow for the injection of custom HTML or JavaScript but all tags use built in templates to minimize any chance of introducing a bug into Bedrock.</p>"},{"location":"attribution/0001-analytics/#the-gtm-datalayer","title":"The GTM DataLayer","text":"<p>How an application communicates with GTM is via the <code>dataLayer</code> object, which is a simple JavaScript array GTM instantiates on the page. Bedrock will send messages to the <code>dataLayer</code> object by means of pushing an object literal onto the <code>dataLayer</code>. GTM creates an abstract data model from these pushed objects that consists of the most recent value for all keys that have been pushed to the <code>dataLayer</code>.</p> <p>The only reserved key in an object pushed to the <code>dataLayer</code> is <code>event</code> which will cause GTM to evaluate the firing conditions for all tag triggers.</p>"},{"location":"attribution/0001-analytics/#datalayer-push-example","title":"DataLayer push example","text":"<p>If we wanted to track clicks on a carousel and capture what the image was that was clicked, we might write a dataLayer push like this:</p> <pre><code>dataLayer.push({\n'event': 'carousel-click',\n'image': 'house'\n});\n</code></pre> <p>In the dataLayer push there is an event value to have GTM evaluate the firing conditions for tag triggers, making it possible to fire a tag off the dataLayer push. The event value is descriptive to the user action so it's clear to someone coming in later what the dataLayer push signifies. There is also an image property to capture the image that is clicked, in this example it's the house picture.</p> <p>In GTM, a tag could be setup to fire when the event <code>carousel-click</code> is pushed to the dataLayer and could consume the image value to pass on what image was clicked.</p>"},{"location":"attribution/0001-analytics/#the-core-datalayer-object","title":"The Core DataLayer object","text":"<p>For the passing of contextual data on the user and page to GTM, we've created what we call the Core DataLayer Object. This object passes as soon as all required API calls for contextual data have completed. Unless there is a significant delay to when data will be available, please pass all contextual or meta data on the user or page here that you want to make available to GTM.</p>"},{"location":"attribution/0001-analytics/#conditional-banners","title":"Conditional banners","text":"<p>When a banner is shown:</p> <pre><code>dataLayer.push({\n'eLabel': 'Banner Impression',\n'data-banner-name': '&lt;banner name&gt;', //ex. Fb-Video-Compat\n'data-banner-impression': '1',\n'event': 'non-interaction'\n});\n</code></pre> <p>When an element in the banner is clicked:</p> <pre><code>dataLayer.push({\n'eLabel': 'Banner Clickthrough',\n'data-banner-name': '&lt;banner name&gt;', //ex. Fb-Video-Compat\n'data-banner-click': '1',\n'event': 'in-page-interaction'\n});\n</code></pre> <p>When a banner is dismissed:</p> <pre><code>dataLayer.push({\n'eLabel': 'Banner Dismissal',\n'data-banner-name': '&lt;banner name&gt;', //ex. Fb-Video-Compat\n'data-banner-dismissal': '1',\n'event': 'in-page-interaction'\n});\n</code></pre>"},{"location":"attribution/0001-analytics/#ab-tests","title":"A/B tests","text":"<pre><code>if(href.indexOf('v=a') !== -1) {\nwindow.dataLayer.push({\n'data-ex-variant': 'de-page',\n'data-ex-name': 'Berlin-Campaign-Landing-Page'\n});\n} else if (href.indexOf('v=b') !== -1) {\nwindow.dataLayer.push({\n'data-ex-variant': 'campaign-page',\n'data-ex-name': 'Berlin-Campaign-Landing-Page'\n});\n}\n</code></pre>"},{"location":"attribution/0001-analytics/#gtm-listeners-data-attributes","title":"GTM listeners &amp; data attributes","text":"<p>GTM also uses click and form submit listeners to gather context on what is happening on the page. Listeners push to the dataLayer data on the specific element that triggered the event, along with the element object itself.</p> <p>Since GTM listeners pass the interacted element object to the dataLayer, the use of data attributes works very well when trying to identify key elements that you want to be tracked and for storing data on that element to be passed into Google Analytics. We use data attributes to track clicks on all downloads, buttons elements, and nav, footer, and CTA/button link elements.</p> <p>Important</p> <p>When adding any new elements to a Bedrock page, please follow the below guidelines to ensure accurate analytics tracking.</p> <p>For all generic CTA links and <code>&lt;button&gt;</code> elements, add these data attributes (* indicates a required attribute):</p> <p>Data Attribute        Expected Value (lowercase)</p> <p><code>data-cta-type</code> *    Link type (e.g. <code>navigation</code>, <code>footer</code>, or <code>button</code>)</p> <p><code>data-cta-text</code>       name or text of the link</p> <p><code>data-cta-position</code>   Location of CTA on the page (e.g. <code>primary</code>,                         <code>secondary</code>, <code>header</code>)</p> <p>For Firefox download buttons, add these data attributes (* indicates a required attribute). Note that <code>data-download-name</code> and <code>data-download-version</code> should be included for download buttons that serve multiple platforms. For mobile specific store badges, they are not strictly required.</p> <p>Data Attribute             Expected Value</p> <p><code>data-link-type</code> *        <code>download</code></p> <p><code>data-download-os</code> *      <code>Desktop</code>, <code>Android</code>, <code>iOS</code></p> <p><code>data-download-name</code> <code>Windows 32-bit</code>, <code>Windows 64-bit</code>, <code>macOS</code>,                              <code>Linux 32-bit</code>, <code>Linux 64-bit</code>, <code>iOS</code>, <code>Android</code></p> <p><code>data-download-version</code> <code>win</code>, <code>win64</code>, <code>osx</code>, <code>linux</code>, <code>linux64</code>, <code>ios</code>,                              <code>android</code></p> <p><code>data-download-location</code> <code>primary</code>, <code>secondary</code>, <code>nav</code>, <code>other</code></p> <p>For all links to accounts.firefox.com use these data attributes (* indicates a required attribute):</p> <p>Data Attribute        Expected Value</p> <p><code>data-cta-type</code> *    fxa-servicename (e.g. <code>fxa-sync</code>, <code>fxa-monitor</code>)</p> <p><code>data-cta-text</code>       Name or text of the link (e.g. <code>Sign Up</code>, <code>Join Now</code>,                         <code>Start Here</code>). We use this when the link text is not useful, as                         is the case with many account forms that say, <code>Continue</code>. We                         replace <code>Continue</code> with <code>Register</code>.</p> <p><code>data-cta-position</code>   Location of CTA on the page (e.g. <code>primary</code>, <code>secondary</code>,                         <code>header</code>)</p> <p>Old data-cta structure</p> <p>Do not use. Included here because some old pages still use it.</p> <p><code>data-cta-type=\"\"</code> and <code>data-cta-name=\"\"</code> trigger a generic link / button click with the following structure:</p> <ul> <li>Event Category: <code>{{page ID}} Interactions</code></li> <li>Event Action: <code>{{data-cta-type}} click</code></li> <li>Event Label: <code>{{data-cta-name}}</code></li> </ul>"},{"location":"attribution/0001-analytics/#ga4","title":"GA4","text":"<p>Info</p> <p>The migration to GA4 has begun but is incomplete.</p>"},{"location":"attribution/0001-analytics/#enhanced-event-measurement","title":"Enhanced Event Measurement","text":"<p>Pageviews, video events, and external link clicks are being collected using GA4's enhanced event measurement.</p> <p>Some form submissions are also being collected but newsletter signups are not. (See Bug #13348)</p>"},{"location":"attribution/0001-analytics/#begin-checkout","title":"Begin Checkout","text":"<p>We are using GA4's recommended eCommerce event begin_checkout for VPN and Relay referrals to the FxA Subscription Platform with purchase intent.</p> <p>Note</p> <p>Any link to Mozilla accounts should also be using mozilla accounts attribution</p> <p><code>datalayer-begincheckout.es6.js</code> contains generic functions that can be called on to push the appropriate information to the dataLayer. The script is expecting the following values:</p> <ul> <li>item_id: Stripe Plan ID</li> <li>brand: <code>relay</code>, <code>vpn</code>, or <code>monitor</code></li> <li>plan:<ul> <li><code>vpn-monthly</code></li> <li><code>vpn-yearly</code></li> <li><code>vpn-relay-yearly</code></li> <li><code>relay-email-monthly</code></li> <li><code>relay-email-yearly</code></li> <li><code>relay-phone-monthly</code></li> <li><code>relay-phone-yearly</code></li> <li><code>monitor-monthly</code></li> <li><code>monitor-yearly</code></li> </ul> </li> <li>period: <code>monthly</code> or <code>yearly</code></li> <li>price: cost displayed at checkout, pre tax (example: 119.88)</li> <li>currency: in 3-letter ISO 4217     format     (examples: USD, EUR)</li> <li>discount: value of the discount in the same currency as price     (example: 60.00)</li> </ul> <p>There are two ways to use TrackBeginCheckout:</p> <p>1)  Call the function passing the values directly.</p> <pre><code>TrackBeginCheckout.getEventObjectAndSend(item_id, brand, plan, period, price, currency, discount)\n</code></pre> <p>2)  Pass the values as a data attribute.</p> <p>The <code>vpn_subscribe_link</code> and <code>relay_subscribe_link</code> will automatically generate a <code>data-ga-item</code> object and add the <code>ga-begin-checkout</code> class to links they create -- as long as there is analytics information associated with the plan in its lookup table.</p> <p>To use this method you will need to include <code>datalayer-begincheckout-init.es6.js</code> in the page bundle.</p> <pre><code>&lt;a href=\"{{ fxa link }}\"\n    class=\"ga-begin-checkout\"\n    data-ga-item=\"{\n        'id' : 'price_1Iw7qSJNcmPzuWtRMUZpOwLm',\n        'brand' : 'vpn',\n        'plan' : 'vpn',\n        'period' : 'monthly',\n        'price' : '9.99',\n        'discount' : '0',\n        'currency' : 'USD'\n    }\"\n&gt;\n    Get monthly plan\n&lt;/a&gt;\n</code></pre>"},{"location":"attribution/0001-analytics/#product-download","title":"Product Download","text":"<p>Important</p> <p>Only Firefox and Pocket are currently supported. VPN support has not been added.</p> <p>We are using a the custom event [product_download]{.title-ref} to track product downloads and app store referrals for Firefox, Pocket, and VPN. We are not using the default GA4 event file_download for a combination of reasons: it does not trigger for the Firefox file types, we would like to collect more information than is included with the default events, and we would like to treat product downloads as goals but not all file downloads are goals.</p> <p>Note</p> <p>Most apps listed in appstores.py are supported but you may still want to check that the URL you are tracking is identified as valid in <code>isValidDownloadURL and will be recognized by</code>getEventFromUrl`.</p> <p>Properties for use with [product_download]{.title-ref} (not all products will have all options):</p> <ul> <li>product (example: firefox)</li> <li>platform (example: win64)</li> <li>method (store, site, or adjust)</li> <li>release_channel (example: nightly)</li> <li>download_language (example: en-CA)</li> </ul> <p>There are two ways to use TrackProductDownload:</p> <p>1)  Call the function, passing it the same URL you are sending the user     to:</p> <pre><code>TrackProductDownload.sendEventFromURL(downloadURL);\n</code></pre> <p>2)  Add a class to the link:</p> <pre><code>&lt;a href=\"{{ link }}\" class=\"ga-product-download\"&gt;Link text&lt;/a&gt;\n</code></pre> <p>You do NOT need to include <code>datalayer-productdownload-init.es6.js</code> in the page bundle, it is already included in the site bundle.</p>"},{"location":"attribution/0001-analytics/#how-can-visitors-opt-out-of-ga","title":"How can visitors opt out of GA?","text":"<p>Visitors to the website can opt-out of loading Google Analytics on our website by enabling Do Not Track (DNT) in their web browser. We facilitate this by using a DNT helper that our team maintains.</p>"},{"location":"attribution/0001-analytics/#glean","title":"Glean","text":"<p>Currently in an evaluation phase, bedrock is now capable of running a parallel first-party analytics implementation alongside GTM, using Mozilla's own Glean telemetry SDK. See the Glean Book for more developer reference documentation.</p> <p>Glean is currently behind a feature switch called <code>SWITCH_GLEAN_ANALYTICS</code>. When the switch is enabled pages will load the Glean JavaScript bundle, which will do things like record page hits and link click events that we want to measure.</p>"},{"location":"attribution/0001-analytics/#debugging-pings","title":"Debugging pings","text":"<p>For all non-production environments, bedrock will automatically set a debug view tag for all pings. This means that when running on localhost, on a demo, or on a staging environment, ping data will be viewable in the Glean debug dashboard which can be used to test that pings are working correctly. All bedrock debug pings will register in the debug dashboard with the tag name <code>bedrock</code>.</p>"},{"location":"attribution/0001-analytics/#filtering-out-non-production-pings","title":"Filtering out non-production pings","text":"<p>Bedrock will also set an <code>app_channel</code> tag with a value of either <code>prod</code> or <code>non-prod</code>, depending on the environment. This is present in all pings in the <code>client_info</code> section, and is useful for filtering out non-production data in telemetry dashboards.</p>"},{"location":"attribution/0001-analytics/#logging-pings-in-the-console","title":"Logging pings in the console","text":"<p>When running bedrock locally, you can also set the following environment variable in your <code>.env</code>` file to automatically log pings in the browser's web console. This can be especially useful when making updates to analytics code.</p> <pre><code>GLEAN_LOG_PINGS=True\n</code></pre>"},{"location":"attribution/0001-analytics/#defining-metrics-and-pings","title":"Defining metrics and pings","text":"<p>All of the data we send to the Glean pipeline is defined in YAML schema files in the <code>./glean/</code> project root directory. The <code>metrics.yaml</code> file defines all the different metrics types and events we record.</p> <p>Note</p> <p>Before running any Glean commands locally, always make sure you have first activated your virtual environment by running <code>pyenv activate bedrock</code>.</p> <p>When bedrock starts, we automatically run <code>npm run glean</code> which parses these schema files and then generates some JavaScript library code in <code>./media/js/libs/glean/</code>. This library code is not committed to the repository on purpose, in order to avoid people altering it and becoming out of sync with the schema. This library code is then imported into our Glean analytics code in <code>./media/js/glean/</code>, which is where we initiate page views and capture click events.</p> <p>Running <code>npm run glean</code> can also be performed independently of starting bedrock. It will also first lint the schema files.</p> <p>Important</p> <p>All metrics and events we record using Glean must first undergo a data review before being made active in production. Therefore anytime we make new additions to these files, those changes should also undergo review.</p>"},{"location":"attribution/0001-analytics/#using-glean-events-in-individual-page-bundles","title":"Using Glean events in individual page bundles","text":"<p>Our analytics code for Glean lives in a single bundle in the base template, which is intended to be shared across all web pages. This bundle automatically initializes Glean and records page hit events. It also creates some helpers that can be used across different page bundles to record interaction events such as link clicks and form submissions.</p> <p>The <code>Mozilla.Glean.pageEvent()</code> helper can be used to record events that are specific to a page, such as successful form completions:</p> <pre><code>if (typeof window.Mozilla.Glean !== 'undefined') {\nwindow.Mozilla.Glean.pageEvent({\nlabel: 'newsletter-sign-up-success',\ntype: 'mozilla-and-you' // type is optional\n});\n}\n</code></pre> <p>It can also be used to record non-interaction events that are not directly initiated by a visitor:</p> <pre><code>if (typeof window.Mozilla.Glean !== 'undefined') {\nwindow.Mozilla.Glean.pageEvent({\nlabel: 'firefox-default',\nnonInteraction: true\n});\n}\n</code></pre> <p>The <code>Mozilla.Glean.clickEvent()</code> helper can be used to record click events that are specific to an element in a page, such as a link or button.</p> <pre><code>if (typeof window.Mozilla.Glean !== 'undefined') {\nwindow.Mozilla.Glean.clickEvent({\nlabel: 'firefox-download',\ntype: 'macOS, release, en-US', // type is optional\nposition: 'primary' // position is optional\n});\n}\n</code></pre>"},{"location":"attribution/0001-analytics/#how-can-visitors-opt-out-of-glean","title":"How can visitors opt out of Glean?","text":"<p>Website visitors can opt out of Glean by visiting the first party data preferences page, which is linked to in the websites privacy notice. Clicking opt-out will set a cookie which Glean checks for before initializing on page load. In production, the cookie that is set applies for all <code>.mozilla.org</code> domains, so other sites such as <code>developer.mozilla.org</code> can also make use of the opt-out mechanism.</p>"},{"location":"attribution/0002-firefox-desktop/","title":"Firefox desktop attribution","text":"<p>Firefox Desktop Attribution (often referred to as Stub Attribution) is a system that enables Mozilla to link website attributable referral data (including Google Analytics data) to a user's Firefox profile. When a website visitor lands on www.mozilla.org and clicks to download Firefox, we pass attribution data about their visit to the Firefox installer for inclusion in Telemetry. This is to enable Mozilla to better understand how things like changes to our website and different marketing campaigns can affect installation rates, as well as overall product retention. The data also gives us an insight into how many installations originate from www.mozilla.org, as opposed to elsewhere on the internet.</p>"},{"location":"attribution/0002-firefox-desktop/#scope-and-requirements","title":"Scope and requirements","text":"<ul> <li>Attribution was originally only possible via the Firefox stub     installer on Windows (hence the name stub attribution), however it     now also works on full installer links, and across all Windows     desktop release channels.</li> <li>Attribution is still limited to devices running a Windows OS. The     flow does not yet work for macOS and Linux users. It also does not     work for Android or iOS devices.</li> <li>Attribution will only be passed if a website visitor has their Do     Not Track     (DNT)     preference disabled in their browser. Visitors can opt-out by     enabling DNT. This is covered in our privacy     policy.</li> </ul>"},{"location":"attribution/0002-firefox-desktop/#how-does-attribution-work","title":"How does attribution work?","text":"<p>See the Application Logic Flow Chart for a more detailed visual representation of the steps below (Mozilla access only).</p> <ol> <li>A user visits a page on www.mozilla.org. On page load, a JavaScript     function     collects referral and analytics data about from where their visit     originated (see the table below for a full list of attribution data     we collect).</li> <li>Once the attribution data is validated, bedrock then generates an     attribution session ID. This ID is included in the user's     attribution data, and is also sent to Google Analytics as a     non-interaction event.</li> <li>Next we send the attribution data to an authentication service that     is part of bedrock's back-end server. The data is validated again,     then base64 encoded and returned to the client together with an     signed, encrypted signature to prove that the data came from     www.mozilla.org.</li> <li>The encoded attribution data and signature are then stored as     cookies in the user's web browser. The cookies have the IDs     <code>moz-stub-attribution-code</code> (the attribution code) and     <code>moz-stub-attribution-sig</code> (the encrypted signature). Both cookies     have a 24 hour expiry.</li> <li>Once the user reaches a Firefox download page, bedrock then checks     if both attribution cookies exist, and if so appends the     authenticated data to the Firefox download link. The query     parameters are labelled <code>attribution_code</code> and <code>attribution_sig</code>.</li> <li>When the user clicks the Firefox download link, another attribution     service hosted at <code>download.mozilla.org</code> then decrypts and validates     the attribution signature. If the secret matches, a unique download     token is generated. The service then stores both the attribution     data (including the Google Analytics client ID) and the download     token in Mozilla's private server logs.</li> <li>The service then passes the download token and attribution data     (excluding the GA client ID) into the installer being served to the     user.</li> <li>Once the user installs Firefox, the data that was passed to the     installer is then stored in the users' Telemetry profile.</li> <li>During analysis, the download token can be used to join Telemetry     data with the corresponding GA data in the server logs.</li> </ol>"},{"location":"attribution/0002-firefox-desktop/#attribution-data","title":"Attribution data","text":"<p>Name             Description                                   Example</p> <p><code>utm_source</code>     Query param identifying the referring site    <code>utm_source=google</code>                    which sent the visitor.</p> <p><code>utm_medium</code>     Query param identifying the type of link,     <code>utm_medium=cpc</code>                    such as referral, cost per click, or email.</p> <p><code>utm_campaign</code>   Query param identifying the specific          <code>utm_campaign=fast</code>                    marketing campaign that was seen.</p> <p><code>utm_content</code>    Query param identifying the specific element  <code>utm_content=getfirefox</code>                    that was clicked.</p> <p><code>referrer</code>       The domain of the referring site when the     <code>google.com</code>                    link was clicked.</p> <p><code>ua</code>             Simplified browser name parsed from the       <code>chrome</code>                    visitor's User Agent string.</p> <p><code>experiment</code>     Query param identifying an experiment name    <code>taskbar</code>                    that visitor was a cohort of.</p> <p><code>variation</code>      Query param identifying the experiment                    variation that was seen by the visitor.</p> <p><code>client_id</code>      Google Analytics Client ID.                   <code>1715265578.1681917481</code></p> <p><code>session_id</code>     A random 10 digit string identifier used to   <code>9770365798</code>                    associate attribution data with GA session.</p> <p><code>dlsource</code>       A hard-coded string ID used to distinguish    <code>mozorg</code>                    mozorg downloads from archive downloads</p> <p>Note</p> <p>If any of the above values are not present then a default value of <code>(not set)</code> will be used.</p>"},{"location":"attribution/0002-firefox-desktop/#cookies","title":"Cookies","text":"<p>The cookies created during the attribution flow are as follows:</p> <p>Name                          Value                    Domain              Path   Expiry</p> <p><code>moz-stub-attribution-code</code>   Base64 encoded           <code>www.mozilla.org</code> <code>/</code>    24 hours                                 attribution string</p> <p><code>moz-stub-attribution-sig</code>    Base64 encoded signature <code>www.mozilla.org</code> <code>/</code>    24 hours</p>"},{"location":"attribution/0002-firefox-desktop/#measuring-campaigns-and-experiments","title":"Measuring campaigns and experiments","text":"<p>Firefox Desktop Attribution was originally designed for measuring the effectiveness of marketing campaigns where the top of the funnel was outside the remit of www.mozilla.org. For these types of campaigns, stub attribution requires zero configuration. It just works in the background and passes along any attribution data that exists.</p> <p>It is also possible to measure the effectiveness of experiments on installation rates and retention. This is achieved by adding optional <code>experiment</code> and <code>variation</code> parameters to a page URL. Additionally, these values can also be set via JavaScript using:</p> <pre><code>Mozilla.StubAttribution.experimentName = 'experiment-name';\nMozilla.StubAttribution.experimentVariation = 'v1';\n</code></pre> <p>Note</p> <p>When setting a experiment parameters using JavaScript like in the example above, it must be done prior to calling <code>Mozilla.StubAttribution.init()</code>.</p>"},{"location":"attribution/0002-firefox-desktop/#return-to-addonsmozillaorg-rtamo","title":"Return to addons.mozilla.org (RTAMO)","text":"<p>Return to AMO (RTAMO) is a Firefox feature whereby a first-time installation onboarding flow is initiated, that redirects a user to install the extension they have chosen whilst browsing AMO using a different browser. RTAMO works by leveraging the existing stub attribution flow, and checking for specific <code>utm_</code> parameters that were passed if the referrer is from AMO.</p> <p>Specifically, the RTAMO feature looks for a <code>utm_content</code> parameter that starts with <code>rta:</code>, followed by an ID specific to an extension. For example: <code>utm_content=rta:dUJsb2NrMEByYXltb25kaGlsbC5uZXQ</code>. The stub attribution code in bedrock also checks the referrer before passing this on, to make sure the links originate from AMO. If RTAMO data comes from a domain other than AMO, then the attribution data is dropped.</p> <p>RTAMO initially worked for only a limited subset of addons recommended by Mozilla. This functionality was recently expanded by the AMO team to cover all publically listed addons, under a project called [Extended RTAMO (ERTAMO)]{.title-ref}.</p>"},{"location":"attribution/0002-firefox-desktop/#how-can-visitors-opt-out","title":"How can visitors opt out?","text":"<p>Visitors to the website can opt-out of desktop attribution on our website by enabling Do Not Track (DNT) in their web browser. We facilitate this by using a DNT helper that our team maintains.</p>"},{"location":"attribution/0002-firefox-desktop/#local-testing","title":"Local testing","text":"<p>For stub attribution to work locally or on a demo instance, a value for the HMAC key that is used to sign the attribution code must be set via an environment variable e.g.</p> <pre><code>STUB_ATTRIBUTION_HMAC_KEY=thedude\n</code></pre> <p>Note</p> <p>This value can be anything if all you need to do is test the bedrock functionality. It only needs to match the value used to verify data passed to the stub installer for full end-to-end testing via Telemetry.</p>"},{"location":"attribution/0003-firefox-mobile/","title":"Firefox mobile attribution","text":"<p>For Firefox mobile app store referrals we use Adjust, a third-party attribution system for mobile apps that is designed to measure, optimize and scale app growth. We use Adjust tracking links across www.mozilla.org when we link to app stores for both Firefox and Firefox Focus on Android and iOS. We also often embed Adjust links in QR codes that we display to desktop visitors.</p> <p>To find out more about Adjust, see the following links:</p> <ul> <li>What is mobile ad     attribution?</li> <li>Attribution     methods</li> </ul>"},{"location":"attribution/0003-firefox-mobile/#adjust-link-helpers","title":"Adjust link helpers","text":"<p>Whilst they are not used routinely in our pages, bedrock does have a series of Adjust link helpers that can be used to create Adjust links for different products.</p>"},{"location":"attribution/0004-mozilla-accounts/","title":"Mozilla accounts attribution","text":"<p>For products such as Mozilla VPN, Relay, and Monitor, we use Mozilla account as an authentication and subscription service. In addition to Google Analytics for basic conversion tracking, we attribute web page visits and clicks and through to actual subscriptions and installs by passing a specific allow-list of known query parameters through to the subscription platform. This is accomplished by adding referral data as parameters to sign up links on product landing pages.</p>"},{"location":"attribution/0004-mozilla-accounts/#how-does-attribution-work","title":"How does attribution work?","text":"<p>When using any of the mozilla accounts helpers in bedrock, a default set of attribution parameters are added to each account sign-in / subscription link on a product landing page. Here's what we set for Mozilla VPN, as an example:</p> Name Description Example value <code>utm_source</code> Query param identifying the referring site which sent the visitor. <code>www.mozilla.org-vpn-product-page</code> <code>utm_medium</code> Query param identifying the type of link, such as referral, cost per click, or email. <code>referral</code> <code>utm_campaign</code> Query param identifying the specific marketing campaign that was seen. <code>vpn-product-page</code> <code>entrypoint</code> ID for which page of the website the request originates from (used for funnel analysis). <code>www.mozilla.org-vpn-product-page</code> <code>device_id</code> ID that correlates to the active device being used (used for funnel analysis). Alpha numeric string <code>flow_id</code> The flow identifier. A randomly-generated opaque ID (used for funnel analysis). Alpha numeric string <code>flow_begin_time</code> The time at which a flow event occurred (used for funnel analysis). Timestamp <code>service</code> Product ID used for data analysis in BigQuery (optional). Alpha numeric string <p>When performing data analysis, the default UTM values above are what we equate to \"direct\" traffic (i.e. someone came to the landing page directly then subscribed. They did not arrive from a specific marketing campaign or other channel).</p> <p>If we do detect that someone came from a marketing campaign or other form of referral, then we have logic in place that will replace the default UTM parameters on each link with more specific referral data, so that we can attribute subscriptions to individual campaigns.</p> <p>We also support passing several other optional referral parameters:</p> Name Description Example value <code>coupon</code> A coupon code that can be automatically applied at checkout (case sensitive). <code>VPN20</code> <code>entrypoint_experiment</code> Experiment name ID. Alpha numeric string <code>entrypoint_variation</code> Experiment variation ID Alpha numeric string"},{"location":"attribution/0004-mozilla-accounts/#attribution-logic","title":"Attribution logic","text":"<p>See the Application Logic Flow Chart for a visual representation of the steps below (Mozilla access only).</p> <ol> <li>A website visitor loads a product landing page in their web browser.</li> <li>A JavaScript     function     then checks for and validates attribution data via a list of known     URL parameters (see tables above).</li> <li>If there are UTM parameters in the referral data, then those are     used to replace the default values in each sign up link.     Additionally if <code>coupon</code> or <code>entrypoint_experiment</code> params found,     those are also appended.</li> <li>If no UTM params exist, but there is a referrer cookie set, then the     cookie value is used for <code>utm_campaign</code> and <code>utm_source</code> is set to     <code>www.mozilla.org</code>. This cookie is often set when we display a \"Get     Mozilla VPN\" promo on another mozorg page, such as <code>/whatsnew</code>.</li> <li>If there's no referrer cookie, we next look at <code>document.referrer</code>     to see if the visitor came from a search engine. If found, we set     <code>utm_medium</code> as <code>organic</code> and <code>utm_source</code> as the search engine     name.</li> <li>Next, an metrics     function     makes a flow API request to the Mozilla accounts authentication     server. The request returns a series of metrics parameters that are     used to track progress through the sign-up process. These \"flow\"     parameters are also appended to each sign up link in addition to the     existing attribution data.</li> <li>When someone clicks through and completes the sign up process,     attribution data we passed through is emitted as event logs. This     data is then joined to a person's Mozilla account data during the     Data Science team's ETL process (Extract, Transform, Load), where     data is then brought together in Big Query.</li> </ol> <p>Note</p> <p>UTM parameters on sign up links will only be replaced if the page URL contains both a valid <code>utm_source</code> and <code>utm_campaign</code> parameter. All other UTM parameters are considered optional, but will still be passed through, as long as the required parameters exist. This is to avoid mixing referral data from different campaigns.</p>"},{"location":"attribution/0004-mozilla-accounts/#attribution-referrer-cookie","title":"Attribution referrer cookie","text":"<p>In situations where we want to try and track a visitor's first entry point, say if someone lands on a <code>/whatsnew</code> page and then clicks on a \"Get Mozilla VPN\" promo link, then we can set a referral cookie in someone's browser when they click a same-site link (step 4 in the list above).</p> <p>The cookie can be set simply by adding the class name <code>js-fxa-product-referral-link</code> to a same-site link, along with a <code>data-referral-id</code> attribute. When clicked, our attribution logic will use the value of <code>data-referral-id</code> to augment <code>utm_campaign</code> when someone click through to the product page.</p> <p>For example, a referral with <code>data-referral-id=\"navigation\"</code> would result in the following utm parameters being set on sign up links in the product landing page:</p> <ul> <li><code>utm_source=www.mozilla.org</code>.</li> <li><code>utm_campaign=navigation</code>.</li> <li><code>utm_medium=referral</code>.</li> </ul>"},{"location":"attribution/0004-mozilla-accounts/#mozilla-vpn-referral-link-helper","title":"Mozilla VPN referral link helper","text":"<p>For Mozilla VPN, there's a <code>vpn_product_referral_link</code> helper built specifically to help implement account referral links to the VPN landing page:</p> <pre><code>{{ vpn_product_referral_link(\n    referral_id='navigation',\n    link_to_pricing_page=True,\n    link_text='Get Mozilla VPN',\n    class_name='mzp-t-secondary mzp-t-md',\n    page_anchor='#pricing',\n    optional_attributes= {\n        'data-cta-text' : 'Get Mozilla VPN',\n        'data-cta-type' : 'button',\n        'data-cta-position' : 'navigation',\n    }\n) }}\n</code></pre> <p>The helper supports the following parameters:</p> Parameter name Definition Format Example <code>referral_id</code> The ID for the referring page / component. This serves as a value for \u2018utm_campaign\u2019. String \u2018navigation\u2019 <code>link_to_pricing_page</code> Link to the pricing page instead of the landing page (defaults to <code>False</code>). Boolean True <code>link_text</code> The link copy to be used in the call to action. Localized string \u2018Get Mozilla VPN\u2019 <code>class_name</code> A class name to be applied to the link (typically for styling with CSS). String of one or more class names \u2018mzp-t-secondary mzp-t-md\u2019 <code>page_anchor</code> An optional page anchor for the link destination. String \u2018#pricing\u2019 <code>optional_attributes</code> An dictionary of key value pairs containing additional data attributes to include in the button. Dictionary {\u2018data-cta-text\u2019: \u2018Get Mozilla VPN\u2019, \u2018data-cta-type\u2019: \u2018button\u2019, \u2018data-cta-position\u2019: \u2018navigation\u2019} <p>The cookie has the following configuration:</p> Cookie name Value Domain Expiry <code>fxa-product-referral-id</code> Campaign identifier <code>www.mozilla.org</code> 1 hour"},{"location":"attribution/0004-mozilla-accounts/#flow-metrics","title":"Flow metrics","text":"<p>Whilst UTM parameters are passed through to sign up links automatically for any page of the website, in order for flow metrics to be added to links, a specific JavaScript bundle needs to be manually run in the page that requires it. The reason why it's separate is that depending on the situation, flow metrics need to get queried and added at specific times and conditions (more on that below).</p> <p>To add flow metrics to links, a page's respective JavaScript bundle should import and initialize the <code>FxaProductButton</code> script.</p> <pre><code>import FxaProductButton from './path/to/fxa-product-button.es6.js';\n\nFxaProductButton.init();\n</code></pre> <p>The above JS is also available as a pre-compiled bundle, which can be included directly in a template:</p> <pre><code>{{ js_bundle('fxa_product_button') }}\n</code></pre> <p>When [init()]{.title-ref} is called, flow metrics will automatically be added to add account sign up links on a page.</p> <p>Important</p> <p>Requests to metrics API endpoints should only be made when an associated CTA is visibly displayed on a page. For example, if a page contains both a Mozilla accounts sign-up form and a Mozilla Monitor button, but only one CTA is displayed at any one time, then only the metrics request associated with the visible CTA should occur.</p> <p>Note</p> <p>For links generated using the <code>fxa_link_fragment</code> helper, you will also need to manually add a CSS class of <code>js-fxa-product-button</code> to trigger the script.</p>"},{"location":"attribution/0004-mozilla-accounts/#google-analytics-guidelines","title":"Google Analytics guidelines","text":"<p>For GTM <code>datalayer</code> attribute values in Mozilla account links, please use the analytics documentation.</p>"},{"location":"attribution/0005-affiliate-marketing/","title":"Mozilla CJMS affiliate attribution","text":"<p>The CJMS affiliate attribution flow comprises an integration between the Commission Junction (CJ) affiliate marketing event system, bedrock, and the Security and Privacy team's CJ micro service (CJMS).</p> <p>The system allows individuals who partner with Mozilla, via CJ, to share referral links for Mozilla with their audiences. When people subscribe using an affiliate link, the partner can be attributed appropriately in CJ's system.</p>"},{"location":"attribution/0005-affiliate-marketing/#how-does-attribution-work","title":"How does attribution work?","text":"<p>For a more detailed breakdown you can view the full flow diagram (Mozilla access only), but at a high level the logic that bedrock is responsible for is as follows:</p> <ol> <li>On pages which include the script, on page load, a JavaScript     function     looks for a <code>cjevent</code> query parameterin the page URL.</li> <li>If found, we validate the query param value and then <code>POST</code> it     together with a Firefox Account <code>flow_id</code> to the CJMS.</li> <li>The CJMS responds with an affiliate marketing ID and expiry time,     which we then set as a first-party cookie. This cookie is used to     maintain a relationship between the <code>cjevent</code> value and an     individual <code>flow_id</code>, so that successful subscriptions can be     properly attributed to CJ.</li> <li>If a website visitor later returns to the page with an affiliate     marketing cookie already set, then we update the <code>flow_id</code> and     <code>cjevent</code> value (if a new one exists) via <code>PUT</code> on their repeat     visit. This ensures that the most recent CJ referral is attributed     if/when someone decides to purchase a subscription.</li> <li>The CJMS then responds with an updated ID / expiry time for the     affiliate marketing cookie.</li> </ol>"},{"location":"attribution/0005-affiliate-marketing/#how-can-visitors-opt-out","title":"How can visitors opt out?","text":"<ol> <li>To facilitate an opt-out of attribution, we display a cookie     notification with an opt-out button at the top of the page when the     flow initiates.</li> <li>If someone clicks \"Reject\" to opt-out, we generate a new <code>flow_id</code>     (invalidating the existing <code>flow_id</code> in the CJMS database) and then     delete the affiliate marketing cookie, replacing it with a     \"reject\" preference cookie that will prevent attribution from     initiating on repeat visits. This preference cookie will expire     after 1 month.</li> <li>If someone clicks \"OK\" or closes the opt-out notification by     clicking the \"X\" icon, here we assume the website visitor is OK     with attribution. We set an \"accept\" preference cookie that will     prevent displaying the opt-out notification on future visits (again     with a 1 month expiry) and allow attribution to flow.</li> </ol>"},{"location":"attribution/0005-affiliate-marketing/#cookies","title":"Cookies","text":"<p>The affiliate cookie has the following configuration:</p> <p>Cookie name            Value          Domain                Expiry</p> <p><code>moz-cj-affiliate</code>     Affiliate ID   <code>www.mozilla.org</code>     30 days</p> <p>Note</p> <p>To query what version of CJMS is currently deployed at the endpoint bedrock points to, you can add <code>__version__</code> at the end of the base URL to see the release number and commit hash. For example: https://stage.cjms.nonprod.cloudops.mozgcp.net/__version__</p>"},{"location":"attribution/0006-pocket-analytics/","title":"Pocket mode","text":""},{"location":"attribution/0006-pocket-analytics/#google-tag-manager-gtm","title":"Google Tag Manager (GTM)","text":"<p>In pocket mode, bedrock also uses Google Tag Manager (GTM) to manage and organize its Google Analytics (GA4) solution. This is mostly for marketing's own use, and is not used by the Pocket organization.</p> <p>In contrast to mozorg mode, GA in Pocket is mostly used for measuring a few key events, such as sign ups and logged-in / logged-out page views. Most of this event and triggering logic exists entirely inside GTM, as opposed to in bedrock code.</p>"},{"location":"attribution/0006-pocket-analytics/#snowplow","title":"Snowplow","text":"<p>Snowplow is the analytics tool used by the Pocket organization, which is something marketing has limited access to. Snowplow is mostly used for tracking events in the Pocket web application, although we do also load it on the logged-out marketing pages that are hosted by bedrock.</p>"},{"location":"attribution/0006-pocket-analytics/#how-can-visitors-opt-out-of-pocket-analytics","title":"How can visitors opt out of Pocket analytics?","text":"<p>Pocket website visitors can opt-out of both GA and Snowplow by changing their preferences in the One Trust Cookie Banner we display on page load. If someone opts-out of analytics cookies, we do not load GA, however we do still load Snowplow in a more privacy reserved mode.</p> <p>Snowplow configuration with cookie consent (default):</p> <pre><code>{\nappId: SNOWPLOW_APP_ID,\nplatform: 'web',\neventMethod: 'beacon',\nrespectDoNotTrack: false,\nstateStorageStrategy: 'cookieAndLocalStorage',\ncontexts: {\nwebPage: true,\nperformanceTiming: true\n},\nanonymousTracking: false\n}\n</code></pre> <p>Snowplow configuration without cookie consent:</p> <pre><code>{\nappId: SNOWPLOW_APP_ID,\nplatform: 'web',\neventMethod: 'post',\nrespectDoNotTrack: false,\nstateStorageStrategy: 'none',\ncontexts: {\nwebPage: true,\nperformanceTiming: true\n},\nanonymousTracking: {\nwithServerAnonymisation: true\n}\n}\n</code></pre> <p>See our Pocket analytics code for more details.</p>"}]}